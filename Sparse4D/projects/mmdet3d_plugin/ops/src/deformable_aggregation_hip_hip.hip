// !!! This is a file automatically generated by hipify!!!
#include <ATen/ATen.h>
#include <ATen/hip/HIPContext.h>
#include <hip/hip_runtime.h>
#include <hip/hip_fp16.h>

#include <iostream>
#include <stdlib.h>
#include <cmath>


__device__ float bilinear_sampling(
    const float *&bottom_data, const int &height, const int &width,
    const int &num_embeds, const float &h_im, const float &w_im,
    const int &base_ptr
) {
  const int h_low = floorf(h_im);
  const int w_low = floorf(w_im);
  const int h_high = h_low + 1;
  const int w_high = w_low + 1;

  const float lh = h_im - h_low;
  const float lw = w_im - w_low;
  const float hh = 1 - lh, hw = 1 - lw;

  const int w_stride = num_embeds;
  const int h_stride = width * w_stride;
  const int h_low_ptr_offset = h_low * h_stride;
  const int h_high_ptr_offset = h_low_ptr_offset + h_stride;
  const int w_low_ptr_offset = w_low * w_stride;
  const int w_high_ptr_offset = w_low_ptr_offset + w_stride;

  float v1 = 0;
  if (h_low >= 0 && w_low >= 0) {
    const int ptr1 = h_low_ptr_offset + w_low_ptr_offset + base_ptr;
    v1 = bottom_data[ptr1];
  }
  float v2 = 0;
  if (h_low >= 0 && w_high <= width - 1) {
    const int ptr2 = h_low_ptr_offset + w_high_ptr_offset + base_ptr;
    v2 = bottom_data[ptr2];
  }
  float v3 = 0;
  if (h_high <= height - 1 && w_low >= 0) {
    const int ptr3 = h_high_ptr_offset + w_low_ptr_offset + base_ptr;
    v3 = bottom_data[ptr3];
  }
  float v4 = 0;
  if (h_high <= height - 1 && w_high <= width - 1) {
    const int ptr4 = h_high_ptr_offset + w_high_ptr_offset + base_ptr;
    v4 = bottom_data[ptr4];
  }

  const float w1 = hh * hw, w2 = hh * lw, w3 = lh * hw, w4 = lh * lw;

  const float val = (w1 * v1 + w2 * v2 + w3 * v3 + w4 * v4);
  return val;
}

__device__ void compute_bilinear_grad(
    const float *bottom_data,
    const float &weight_val,
    const int &height, const int &width,
    const int &num_embeds_for_stride,
    const float &h_im, const float &w_im,
    const int &base_ptr,
    const float &grad_output_val,
    float &out_g_v1, float &out_g_v2, float &out_g_v3, float &out_g_v4,
    int &out_ptr1, int &out_ptr2, int &out_ptr3, int &out_ptr4,
    bool &v1_ok, bool &v2_ok, bool &v3_ok, bool &v4_ok,
    float &out_grad_loc_h_contrib,
    float &out_grad_loc_w_contrib,
    float &out_grad_weight_contrib) {

  const int h_low = floorf(h_im);
  const int w_low = floorf(w_im);
  const int h_high = h_low + 1;
  const int w_high = w_low + 1;

  const float lh = h_im - h_low;
  const float lw = w_im - w_low;
  const float hh = 1.0f - lh;
  const float hw = 1.0f - lw;

  const int w_stride_eff = num_embeds_for_stride;
  const int h_stride_eff = width * w_stride_eff;
  const int h_low_ptr_offset = h_low * h_stride_eff;
  const int h_high_ptr_offset = h_high * h_stride_eff;
  const int w_low_ptr_offset = w_low * w_stride_eff;
  const int w_high_ptr_offset = w_high * w_stride_eff;

  float v1 = 0, v2 = 0, v3 = 0, v4 = 0;

  v1_ok = (h_low >= 0 && w_low >= 0 && h_low < height && w_low < width);
  if (v1_ok) {
    out_ptr1 = h_low_ptr_offset + w_low_ptr_offset + base_ptr;
    v1 = bottom_data[out_ptr1];
  }

  v2_ok = (h_low >= 0 && w_high < width && h_low < height && w_high >=0);
  if (v2_ok) {
    out_ptr2 = h_low_ptr_offset + w_high_ptr_offset + base_ptr;
    v2 = bottom_data[out_ptr2];
  }

  v3_ok = (h_high < height && w_low >= 0 && h_high >=0 && w_low < width);
  if (v3_ok) {
    out_ptr3 = h_high_ptr_offset + w_low_ptr_offset + base_ptr;
    v3 = bottom_data[out_ptr3];
  }

  v4_ok = (h_high < height && w_high < width && h_high >=0 && w_high >=0);
  if (v4_ok) {
    out_ptr4 = h_high_ptr_offset + w_high_ptr_offset + base_ptr;
    v4 = bottom_data[out_ptr4];
  }

  const float w_bilinear1 = hh * hw;
  const float w_bilinear2 = hh * lw;
  const float w_bilinear3 = lh * hw;
  const float w_bilinear4 = lh * lw;

  const float interpolated_val = (w_bilinear1 * v1 + w_bilinear2 * v2 + w_bilinear3 * v3 + w_bilinear4 * v4);
  const float top_grad_scaled_by_weight = grad_output_val * weight_val;

  if (v1_ok) out_g_v1 = w_bilinear1 * top_grad_scaled_by_weight; else out_g_v1 = 0;
  if (v2_ok) out_g_v2 = w_bilinear2 * top_grad_scaled_by_weight; else out_g_v2 = 0;
  if (v3_ok) out_g_v3 = w_bilinear3 * top_grad_scaled_by_weight; else out_g_v3 = 0;
  if (v4_ok) out_g_v4 = w_bilinear4 * top_grad_scaled_by_weight; else out_g_v4 = 0;

  float grad_h_im_factor = 0, grad_w_im_factor = 0;
  if (v1_ok) { grad_h_im_factor -= hw * v1; grad_w_im_factor -= hh * v1; }
  if (v2_ok) { grad_h_im_factor -= lw * v2; grad_w_im_factor += hh * v2; }
  if (v3_ok) { grad_h_im_factor += hw * v3; grad_w_im_factor -= lh * v3; }
  if (v4_ok) { grad_h_im_factor += lw * v4; grad_w_im_factor += lh * v4; }

  out_grad_loc_h_contrib = grad_h_im_factor * top_grad_scaled_by_weight * height;
  out_grad_loc_w_contrib = grad_w_im_factor * top_grad_scaled_by_weight * width;
  out_grad_weight_contrib = grad_output_val * interpolated_val;
}


__global__ void deformable_aggregation_kernel(
    const int num_kernels,
    float* output,
    const float* mc_ms_feat,
    const int* spatial_shape,
    const int* scale_start_index,
    const float* sample_location,
    const float* weights,
    int batch_size,
    int num_cams,
    int num_feat,
    int num_embeds,
    int num_scale,
    int num_anchors,
    int num_pts,
    int num_groups
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx >= num_kernels) return;

    const float weight = *(weights + idx / (num_embeds / num_groups));
    const int channel_index = idx % num_embeds;
    idx /= num_embeds;
    const int scale_index = idx % num_scale;
    idx /= num_scale;

    const int cam_index = idx % num_cams;
    idx /= num_cams;
    const int pts_index = idx % num_pts;
    idx /= num_pts;

    int anchor_index = idx % num_anchors;
    idx /= num_anchors;
    const int batch_index = idx % batch_size;
    idx /= batch_size;

    anchor_index = batch_index * num_anchors + anchor_index;
    const int loc_offset = ((anchor_index * num_pts + pts_index) * num_cams + cam_index) << 1;

    const float loc_w = sample_location[loc_offset];
    if (loc_w <= 0 || loc_w >= 1) return;
    const float loc_h = sample_location[loc_offset + 1];
    if (loc_h <= 0 || loc_h >= 1) return;

    int cam_scale_index = cam_index * num_scale + scale_index;
    const int value_offset = (batch_index * num_feat + scale_start_index[cam_scale_index]) * num_embeds + channel_index;

    cam_scale_index = cam_scale_index << 1;
    const int h = spatial_shape[cam_scale_index];
    const int w = spatial_shape[cam_scale_index + 1];

    const float h_im = loc_h * h - 0.5;
    const float w_im = loc_w * w - 0.5;

    atomicAdd(
        output + anchor_index * num_embeds + channel_index,
        bilinear_sampling(mc_ms_feat, h, w, num_embeds, h_im, w_im, value_offset) * weight
    );
}


__global__ void deformable_aggregation_grad_kernel(
    const int num_total_threads,
    const float* mc_ms_feat,
    const int* spatial_shape,
    const int* scale_start_index,
    const float* sample_location,
    const float* weights,
    const float* grad_output,
    float* grad_mc_ms_feat,
    float* grad_sampling_location,
    float* grad_weights,
    int batch_size,
    int num_cams,
    int num_feat,
    int num_embeds,
    int num_scale,
    int num_anchors,
    int num_pts,
    int num_groups) {

    extern __shared__ float s_reduce_cache[];

    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx >= num_total_threads) return;

    int current_idx_val = idx;
    const int channel_index = current_idx_val % num_embeds;
    current_idx_val /= num_embeds;
    const int scale_index = current_idx_val % num_scale;
    current_idx_val /= num_scale;
    const int cam_index = current_idx_val % num_cams;
    current_idx_val /= num_cams;
    const int pts_index = current_idx_val % num_pts;
    current_idx_val /= num_pts;
    int anchor_index_orig = current_idx_val % num_anchors;
    const int batch_index = current_idx_val / num_anchors;

    const int anchor_index = batch_index * num_anchors + anchor_index_orig;
    const int loc_offset = ((anchor_index * num_pts + pts_index) * num_cams + cam_index) << 1;

    const float loc_w_val = sample_location[loc_offset];
    if (loc_w_val <= 0 || loc_w_val >= 1) return;
    const float loc_h_val = sample_location[loc_offset + 1];
    if (loc_h_val <= 0 || loc_h_val >= 1) return;

    const int channels_per_weight_group = (num_groups > 0) ? (num_embeds / num_groups) : 0; // Avoid division by zero
    const int weight_target_idx = (channels_per_weight_group > 0) ? (idx / channels_per_weight_group) : 0; // Avoid division by zero
    const float current_weight_val = weights[weight_target_idx]; // Assuming weight_target_idx is valid
    const float current_grad_output_val = grad_output[anchor_index * num_embeds + channel_index];

    int cam_scale_idx = cam_index * num_scale + scale_index;
    const int feat_value_offset = (batch_index * num_feat + scale_start_index[cam_scale_idx]) * num_embeds + channel_index;

    const int h_feat = spatial_shape[cam_scale_idx << 1];
    const int w_feat = spatial_shape[(cam_scale_idx << 1) + 1];

    const float h_im_coord = loc_h_val * h_feat - 0.5f;
    const float w_im_coord = loc_w_val * w_feat - 0.5f;

    float g_v1, g_v2, g_v3, g_v4;
    int ptr1, ptr2, ptr3, ptr4;
    bool v1_ok, v2_ok, v3_ok, v4_ok;
    float grad_loc_h_contrib, grad_loc_w_contrib, grad_weight_contrib;

    compute_bilinear_grad(
        mc_ms_feat, current_weight_val, h_feat, w_feat, num_embeds,
        h_im_coord, w_im_coord, feat_value_offset, current_grad_output_val,
        g_v1, g_v2, g_v3, g_v4, ptr1, ptr2, ptr3, ptr4, v1_ok, v2_ok, v3_ok, v4_ok,
        grad_loc_h_contrib, grad_loc_w_contrib, grad_weight_contrib);

    if (v1_ok) atomicAdd(grad_mc_ms_feat + ptr1, g_v1);
    if (v2_ok) atomicAdd(grad_mc_ms_feat + ptr2, g_v2);
    if (v3_ok) atomicAdd(grad_mc_ms_feat + ptr3, g_v3);
    if (v4_ok) atomicAdd(grad_mc_ms_feat + ptr4, g_v4);

    const int loc_reduction_group_size = num_scale * num_embeds;
    const int loc_group_lane_id = scale_index * num_embeds + channel_index;

    if (loc_reduction_group_size <= blockDim.x && loc_reduction_group_size > 0) {
        float* s_cache_loc_h = s_reduce_cache;
        float* s_cache_loc_w = s_reduce_cache + loc_reduction_group_size;

        if (loc_group_lane_id < loc_reduction_group_size) {
             s_cache_loc_h[loc_group_lane_id] = grad_loc_h_contrib;
             s_cache_loc_w[loc_group_lane_id] = grad_loc_w_contrib;
        } else {
             s_cache_loc_h[loc_group_lane_id] = 0.0f;
             s_cache_loc_w[loc_group_lane_id] = 0.0f;
        }
        __syncthreads();

        for (int s = loc_reduction_group_size / 2; s > 0; s >>= 1) {
            if (loc_group_lane_id < s) {
                s_cache_loc_h[loc_group_lane_id] += s_cache_loc_h[loc_group_lane_id + s];
                s_cache_loc_w[loc_group_lane_id] += s_cache_loc_w[loc_group_lane_id + s];
            }
            __syncthreads();
        }
        if (loc_group_lane_id == 0) {
            atomicAdd(grad_sampling_location + loc_offset + 1, s_cache_loc_h[0]);
            atomicAdd(grad_sampling_location + loc_offset, s_cache_loc_w[0]);
        }
    } else if (loc_reduction_group_size > 0) {
        float warp_sum_loc_h = grad_loc_h_contrib;
        float warp_sum_loc_w = grad_loc_w_contrib;
        for (int offset = warpSize / 2; offset > 0; offset >>= 1) { // Assuming warpSize is defined (e.g. hipWarpSize)
            warp_sum_loc_h += __shfl_down(warp_sum_loc_h, offset, warpSize);
            warp_sum_loc_w += __shfl_down(warp_sum_loc_w, offset, warpSize);
        }
        if ((loc_group_lane_id % warpSize) == 0) {
            atomicAdd(grad_sampling_location + loc_offset + 1, warp_sum_loc_h);
            atomicAdd(grad_sampling_location + loc_offset, warp_sum_loc_w);
        }
    }

    const int weight_reduction_group_size = channels_per_weight_group; // Already calculated, checked for num_groups > 0
    const int weight_group_lane_id = (weight_reduction_group_size > 0) ? (idx % weight_reduction_group_size) : 0;

    if (weight_reduction_group_size <= blockDim.x && weight_reduction_group_size > 0) {
        float* s_cache_weight = s_reduce_cache;
        if (weight_group_lane_id < weight_reduction_group_size) {
            s_cache_weight[weight_group_lane_id] = grad_weight_contrib;
        } else {
            s_cache_weight[weight_group_lane_id] = 0.0f;
        }
        __syncthreads();

        for (int s = weight_reduction_group_size / 2; s > 0; s >>= 1) {
            if (weight_group_lane_id < s) {
                s_cache_weight[weight_group_lane_id] += s_cache_weight[weight_group_lane_id + s];
            }
            __syncthreads();
        }
        if (weight_group_lane_id == 0) {
            atomicAdd(grad_weights + weight_target_idx, s_cache_weight[0]);
        }
    } else if (weight_reduction_group_size > 0) {
        float warp_sum_weight = grad_weight_contrib;
        for (int offset = warpSize / 2; offset > 0; offset >>= 1) { // Assuming warpSize is defined
            warp_sum_weight += __shfl_down(warp_sum_weight, offset, warpSize);
        }
        if ((weight_group_lane_id % warpSize) == 0) {
            atomicAdd(grad_weights + weight_target_idx, warp_sum_weight);
        }
    }
}

void deformable_aggregation(
    float* output,
    const float* mc_ms_feat,
    const int* spatial_shape,
    const int* scale_start_index,
    const float* sample_location,
    const float* weights,
    int batch_size,
    int num_cams,
    int num_feat,
    int num_embeds,
    int num_scale,
    int num_anchors,
    int num_pts,
    int num_groups
) {
    const int num_kernels = batch_size * num_pts * num_embeds * num_anchors * num_cams * num_scale;
   hipLaunchKernelGGL(( deformable_aggregation_kernel)
        , dim3((int)ceil(((double)num_kernels/128))), dim3(128), 0, 0, 
        num_kernels, output,
        mc_ms_feat, spatial_shape, scale_start_index, sample_location, weights,
        batch_size, num_cams, num_feat, num_embeds, num_scale, num_anchors, num_pts, num_groups
    );
}


void deformable_aggregation_grad(
  const float* mc_ms_feat,
  const int* spatial_shape,
  const int* scale_start_index,
  const float* sample_location,
  const float* weights,
  const float* grad_output,
  float* grad_mc_ms_feat,
  float* grad_sampling_location,
  float* grad_weights,
  int batch_size,
  int num_cams,
  int num_feat,
  int num_embeds,
  int num_scale,
  int num_anchors,
  int num_pts,
  int num_groups
) {
    const int num_total_threads = batch_size * num_pts * num_embeds * num_anchors * num_cams * num_scale;
    if (num_total_threads == 0) return;

    unsigned int block_threads = 128;

    size_t shmem_size_loc = 0;
    if (num_scale * num_embeds <= block_threads && num_scale * num_embeds > 0) {
        shmem_size_loc = (num_scale * num_embeds) * 2 * sizeof(float);
    }

    size_t shmem_size_weights = 0;
    if (num_groups > 0 && (num_embeds / num_groups) <= block_threads && (num_embeds / num_groups) > 0) {
         shmem_size_weights = (num_embeds / num_groups) * sizeof(float);
    }

    size_t shmem_size = (shmem_size_loc > shmem_size_weights) ? shmem_size_loc : shmem_size_weights;

    int grid_dim = (num_total_threads + block_threads - 1) / block_threads;

   hipLaunchKernelGGL(( deformable_aggregation_grad_kernel)
        , dim3(grid_dim), dim3(block_threads), shmem_size, 0, 
        num_total_threads,
        mc_ms_feat, spatial_shape, scale_start_index, sample_location, weights,
        grad_output, grad_mc_ms_feat, grad_sampling_location, grad_weights,
        batch_size, num_cams, num_feat, num_embeds, num_scale, num_anchors, num_pts, num_groups
    );
}
