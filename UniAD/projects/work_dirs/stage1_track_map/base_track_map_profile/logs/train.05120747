/mmopenlab/mmcv/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
projects.mmdet3d_plugin
[2025-05-12 07:47:42,972] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/bin/sh: 1: /opt/rocm/hip/bin/hipcc: not found
fatal: detected dubious ownership in repository at '/mnt/raid0/liuji/UniAD'
To add an exception for this directory, call:

	git config --global --add safe.directory /mnt/raid0/liuji/UniAD
2025-05-12 07:47:44,821 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.10.15 (main, Oct  3 2024, 07:27:34) [GCC 11.2.0]
CUDA available: True
GPU 0: AMD Radeon Graphics
CUDA_HOME: /opt/rocm
NVCC: Not Available
GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
PyTorch: 2.7.0a0+git6374332
PyTorch compiling details: PyTorch built with:
  - GCC 11.4
  - C++ Version: 201703
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - HIP Runtime 6.3.42131
  - MIOpen 3.3.0
  - Magma 2.7.2
  - Build settings: BLAS_INFO=open, BUILD_TYPE=Release, COMMIT_SHA=6374332d33953766af2359a66027dc4f90c66e07, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, FORCE_FALLBACK_CUDA_MPI=1, LAPACK_INFO=open, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.7.0, USE_CUDA=OFF, USE_CUDNN=OFF, USE_CUSPARSELT=OFF, USE_EIGEN_FOR_BLAS=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=OFF, USE_MKLDNN=ON, USE_MPI=ON, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=ON, USE_ROCM_KERNEL_ASSERT=OFF, 

TorchVision: 0.22.0a0+867521e
OpenCV: 4.11.0
MMCV: 1.7.1
MMCV Compiler: GCC 11.4
MMCV CUDA Compiler: 60342131
MMDetection: 2.26.0
MMSegmentation: 0.25.0
MMDetection3D: 1.0.0rc4+
spconv2.0: False
------------------------------------------------------------

2025-05-12 07:47:46,116 - mmdet - INFO - Distributed training: True
2025-05-12 07:47:48,110 - mmdet - INFO - Config:
point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
class_names = [
    'car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier',
    'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
]
dataset_type = 'NuScenesE2EDataset'
data_root = 'data/nuscenes/'
input_modality = dict(
    use_lidar=False,
    use_camera=True,
    use_radar=False,
    use_map=False,
    use_external=True)
file_client_args = dict(backend='disk')
train_pipeline = [
    dict(
        type='LoadMultiViewImageFromFilesInCeph',
        to_float32=True,
        file_client_args=dict(backend='disk'),
        img_root='data/nuscenes/'),
    dict(type='PhotoMetricDistortionMultiViewImage'),
    dict(
        type='LoadAnnotations3D_E2E',
        with_bbox_3d=True,
        with_label_3d=True,
        with_attr_label=False,
        with_future_anns=True,
        with_ins_inds_3d=True,
        ins_inds_add_1=True),
    dict(
        type='GenerateOccFlowLabels',
        grid_conf=dict(
            xbound=[-50.0, 50.0, 0.5],
            ybound=[-50.0, 50.0, 0.5],
            zbound=[-10.0, 10.0, 20.0]),
        ignore_index=255,
        only_vehicle=True,
        filter_invisible=False),
    dict(
        type='ObjectRangeFilterTrack',
        point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
    dict(
        type='ObjectNameFilterTrack',
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(
        type='NormalizeMultiviewImage',
        mean=[103.53, 116.28, 123.675],
        std=[1.0, 1.0, 1.0],
        to_rgb=False),
    dict(type='PadMultiViewImage', size_divisor=32),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ]),
    dict(
        type='CustomCollect3D',
        keys=[
            'gt_bboxes_3d', 'gt_labels_3d', 'gt_inds', 'img', 'timestamp',
            'l2g_r_mat', 'l2g_t', 'gt_fut_traj', 'gt_fut_traj_mask',
            'gt_past_traj', 'gt_past_traj_mask', 'gt_sdc_bbox', 'gt_sdc_label',
            'gt_sdc_fut_traj', 'gt_sdc_fut_traj_mask', 'gt_lane_labels',
            'gt_lane_bboxes', 'gt_lane_masks', 'gt_segmentation',
            'gt_instance', 'gt_centerness', 'gt_offset', 'gt_flow',
            'gt_backward_flow', 'gt_occ_has_invalid_frame',
            'gt_occ_img_is_valid', 'gt_future_boxes', 'gt_future_labels',
            'sdc_planning', 'sdc_planning_mask', 'command'
        ])
]
test_pipeline = [
    dict(
        type='LoadMultiViewImageFromFilesInCeph',
        to_float32=True,
        file_client_args=dict(backend='disk'),
        img_root='data/nuscenes/'),
    dict(
        type='NormalizeMultiviewImage',
        mean=[103.53, 116.28, 123.675],
        std=[1.0, 1.0, 1.0],
        to_rgb=False),
    dict(type='PadMultiViewImage', size_divisor=32),
    dict(
        type='LoadAnnotations3D_E2E',
        with_bbox_3d=False,
        with_label_3d=False,
        with_attr_label=False,
        with_future_anns=True,
        with_ins_inds_3d=False,
        ins_inds_add_1=True),
    dict(
        type='GenerateOccFlowLabels',
        grid_conf=dict(
            xbound=[-50.0, 50.0, 0.5],
            ybound=[-50.0, 50.0, 0.5],
            zbound=[-10.0, 10.0, 20.0]),
        ignore_index=255,
        only_vehicle=True,
        filter_invisible=False),
    dict(
        type='MultiScaleFlipAug3D',
        img_scale=(1600, 900),
        pts_scale_ratio=1,
        flip=False,
        transforms=[
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ],
                with_label=False),
            dict(
                type='CustomCollect3D',
                keys=[
                    'img', 'timestamp', 'l2g_r_mat', 'l2g_t', 'gt_lane_labels',
                    'gt_lane_bboxes', 'gt_lane_masks', 'gt_segmentation',
                    'gt_instance', 'gt_centerness', 'gt_offset', 'gt_flow',
                    'gt_backward_flow', 'gt_occ_has_invalid_frame',
                    'gt_occ_img_is_valid', 'sdc_planning', 'sdc_planning_mask',
                    'command'
                ])
        ])
]
eval_pipeline = [
    dict(
        type='LoadPointsFromFile',
        coord_type='LIDAR',
        load_dim=5,
        use_dim=5,
        file_client_args=dict(backend='disk')),
    dict(
        type='LoadPointsFromMultiSweeps',
        sweeps_num=10,
        file_client_args=dict(backend='disk')),
    dict(
        type='DefaultFormatBundle3D',
        class_names=[
            'car', 'truck', 'trailer', 'bus', 'construction_vehicle',
            'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone', 'barrier'
        ],
        with_label=False),
    dict(type='Collect3D', keys=['points'])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=8,
    train=dict(
        type='NuScenesE2EDataset',
        data_root='data/nuscenes/',
        ann_file='data/infos/nuscenes_infos_temporal_train.pkl',
        pipeline=[
            dict(
                type='LoadMultiViewImageFromFilesInCeph',
                to_float32=True,
                file_client_args=dict(backend='disk'),
                img_root='data/nuscenes/'),
            dict(type='PhotoMetricDistortionMultiViewImage'),
            dict(
                type='LoadAnnotations3D_E2E',
                with_bbox_3d=True,
                with_label_3d=True,
                with_attr_label=False,
                with_future_anns=True,
                with_ins_inds_3d=True,
                ins_inds_add_1=True),
            dict(
                type='GenerateOccFlowLabels',
                grid_conf=dict(
                    xbound=[-50.0, 50.0, 0.5],
                    ybound=[-50.0, 50.0, 0.5],
                    zbound=[-10.0, 10.0, 20.0]),
                ignore_index=255,
                only_vehicle=True,
                filter_invisible=False),
            dict(
                type='ObjectRangeFilterTrack',
                point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
            dict(
                type='ObjectNameFilterTrack',
                classes=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ]),
            dict(
                type='NormalizeMultiviewImage',
                mean=[103.53, 116.28, 123.675],
                std=[1.0, 1.0, 1.0],
                to_rgb=False),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='DefaultFormatBundle3D',
                class_names=[
                    'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
                    'barrier', 'motorcycle', 'bicycle', 'pedestrian',
                    'traffic_cone'
                ]),
            dict(
                type='CustomCollect3D',
                keys=[
                    'gt_bboxes_3d', 'gt_labels_3d', 'gt_inds', 'img',
                    'timestamp', 'l2g_r_mat', 'l2g_t', 'gt_fut_traj',
                    'gt_fut_traj_mask', 'gt_past_traj', 'gt_past_traj_mask',
                    'gt_sdc_bbox', 'gt_sdc_label', 'gt_sdc_fut_traj',
                    'gt_sdc_fut_traj_mask', 'gt_lane_labels', 'gt_lane_bboxes',
                    'gt_lane_masks', 'gt_segmentation', 'gt_instance',
                    'gt_centerness', 'gt_offset', 'gt_flow',
                    'gt_backward_flow', 'gt_occ_has_invalid_frame',
                    'gt_occ_img_is_valid', 'gt_future_boxes',
                    'gt_future_labels', 'sdc_planning', 'sdc_planning_mask',
                    'command'
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=False,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=True),
        test_mode=False,
        box_type_3d='LiDAR',
        file_client_args=dict(backend='disk'),
        use_valid_flag=True,
        patch_size=[102.4, 102.4],
        canvas_size=(200, 200),
        bev_size=(200, 200),
        queue_length=5,
        predict_steps=12,
        past_steps=4,
        fut_steps=4,
        use_nonlinear_optimizer=True,
        occ_receptive_field=3,
        occ_n_future=6,
        occ_filter_invalid_sample=False),
    val=dict(
        type='NuScenesE2EDataset',
        data_root='data/nuscenes/',
        ann_file='data/infos/nuscenes_infos_temporal_val.pkl',
        pipeline=[
            dict(
                type='LoadMultiViewImageFromFilesInCeph',
                to_float32=True,
                file_client_args=dict(backend='disk'),
                img_root='data/nuscenes/'),
            dict(
                type='NormalizeMultiviewImage',
                mean=[103.53, 116.28, 123.675],
                std=[1.0, 1.0, 1.0],
                to_rgb=False),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='LoadAnnotations3D_E2E',
                with_bbox_3d=False,
                with_label_3d=False,
                with_attr_label=False,
                with_future_anns=True,
                with_ins_inds_3d=False,
                ins_inds_add_1=True),
            dict(
                type='GenerateOccFlowLabels',
                grid_conf=dict(
                    xbound=[-50.0, 50.0, 0.5],
                    ybound=[-50.0, 50.0, 0.5],
                    zbound=[-10.0, 10.0, 20.0]),
                ignore_index=255,
                only_vehicle=True,
                filter_invisible=False),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1600, 900),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(
                        type='CustomCollect3D',
                        keys=[
                            'img', 'timestamp', 'l2g_r_mat', 'l2g_t',
                            'gt_lane_labels', 'gt_lane_bboxes',
                            'gt_lane_masks', 'gt_segmentation', 'gt_instance',
                            'gt_centerness', 'gt_offset', 'gt_flow',
                            'gt_backward_flow', 'gt_occ_has_invalid_frame',
                            'gt_occ_img_is_valid', 'sdc_planning',
                            'sdc_planning_mask', 'command'
                        ])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=False,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=True),
        test_mode=True,
        box_type_3d='LiDAR',
        file_client_args=dict(backend='disk'),
        patch_size=[102.4, 102.4],
        canvas_size=(200, 200),
        bev_size=(200, 200),
        predict_steps=12,
        past_steps=4,
        fut_steps=4,
        use_nonlinear_optimizer=True,
        samples_per_gpu=1,
        eval_mod=['det', 'track', 'map'],
        occ_receptive_field=3,
        occ_n_future=6,
        occ_filter_invalid_sample=False),
    test=dict(
        type='NuScenesE2EDataset',
        data_root='data/nuscenes/',
        ann_file='data/infos/nuscenes_infos_temporal_val.pkl',
        pipeline=[
            dict(
                type='LoadMultiViewImageFromFilesInCeph',
                to_float32=True,
                file_client_args=dict(backend='disk'),
                img_root='data/nuscenes/'),
            dict(
                type='NormalizeMultiviewImage',
                mean=[103.53, 116.28, 123.675],
                std=[1.0, 1.0, 1.0],
                to_rgb=False),
            dict(type='PadMultiViewImage', size_divisor=32),
            dict(
                type='LoadAnnotations3D_E2E',
                with_bbox_3d=False,
                with_label_3d=False,
                with_attr_label=False,
                with_future_anns=True,
                with_ins_inds_3d=False,
                ins_inds_add_1=True),
            dict(
                type='GenerateOccFlowLabels',
                grid_conf=dict(
                    xbound=[-50.0, 50.0, 0.5],
                    ybound=[-50.0, 50.0, 0.5],
                    zbound=[-10.0, 10.0, 20.0]),
                ignore_index=255,
                only_vehicle=True,
                filter_invisible=False),
            dict(
                type='MultiScaleFlipAug3D',
                img_scale=(1600, 900),
                pts_scale_ratio=1,
                flip=False,
                transforms=[
                    dict(
                        type='DefaultFormatBundle3D',
                        class_names=[
                            'car', 'truck', 'construction_vehicle', 'bus',
                            'trailer', 'barrier', 'motorcycle', 'bicycle',
                            'pedestrian', 'traffic_cone'
                        ],
                        with_label=False),
                    dict(
                        type='CustomCollect3D',
                        keys=[
                            'img', 'timestamp', 'l2g_r_mat', 'l2g_t',
                            'gt_lane_labels', 'gt_lane_bboxes',
                            'gt_lane_masks', 'gt_segmentation', 'gt_instance',
                            'gt_centerness', 'gt_offset', 'gt_flow',
                            'gt_backward_flow', 'gt_occ_has_invalid_frame',
                            'gt_occ_img_is_valid', 'sdc_planning',
                            'sdc_planning_mask', 'command'
                        ])
                ])
        ],
        classes=[
            'car', 'truck', 'construction_vehicle', 'bus', 'trailer',
            'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone'
        ],
        modality=dict(
            use_lidar=False,
            use_camera=True,
            use_radar=False,
            use_map=False,
            use_external=True),
        test_mode=True,
        box_type_3d='LiDAR',
        file_client_args=dict(backend='disk'),
        patch_size=[102.4, 102.4],
        canvas_size=(200, 200),
        bev_size=(200, 200),
        predict_steps=12,
        past_steps=4,
        fut_steps=4,
        occ_n_future=6,
        use_nonlinear_optimizer=True,
        eval_mod=['det', 'map', 'track']),
    shuffler_sampler=dict(type='DistributedGroupSampler'),
    nonshuffler_sampler=dict(type='DistributedSampler'))
evaluation = dict(
    interval=6,
    pipeline=[
        dict(
            type='LoadMultiViewImageFromFilesInCeph',
            to_float32=True,
            file_client_args=dict(backend='disk'),
            img_root='data/nuscenes/'),
        dict(
            type='NormalizeMultiviewImage',
            mean=[103.53, 116.28, 123.675],
            std=[1.0, 1.0, 1.0],
            to_rgb=False),
        dict(type='PadMultiViewImage', size_divisor=32),
        dict(
            type='LoadAnnotations3D_E2E',
            with_bbox_3d=False,
            with_label_3d=False,
            with_attr_label=False,
            with_future_anns=True,
            with_ins_inds_3d=False,
            ins_inds_add_1=True),
        dict(
            type='GenerateOccFlowLabels',
            grid_conf=dict(
                xbound=[-50.0, 50.0, 0.5],
                ybound=[-50.0, 50.0, 0.5],
                zbound=[-10.0, 10.0, 20.0]),
            ignore_index=255,
            only_vehicle=True,
            filter_invisible=False),
        dict(
            type='MultiScaleFlipAug3D',
            img_scale=(1600, 900),
            pts_scale_ratio=1,
            flip=False,
            transforms=[
                dict(
                    type='DefaultFormatBundle3D',
                    class_names=[
                        'car', 'truck', 'construction_vehicle', 'bus',
                        'trailer', 'barrier', 'motorcycle', 'bicycle',
                        'pedestrian', 'traffic_cone'
                    ],
                    with_label=False),
                dict(
                    type='CustomCollect3D',
                    keys=[
                        'img', 'timestamp', 'l2g_r_mat', 'l2g_t',
                        'gt_lane_labels', 'gt_lane_bboxes', 'gt_lane_masks',
                        'gt_segmentation', 'gt_instance', 'gt_centerness',
                        'gt_offset', 'gt_flow', 'gt_backward_flow',
                        'gt_occ_has_invalid_frame', 'gt_occ_img_is_valid',
                        'sdc_planning', 'sdc_planning_mask', 'command'
                    ])
            ])
    ],
    planning_evaluation_strategy='uniad')
checkpoint_config = dict(interval=1)
log_config = dict(
    interval=10,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
work_dir = './projects/work_dirs/stage1_track_map/base_track_map_profile/'
load_from = 'ckpts/bevformer_r101_dcn_24ep.pth'
resume_from = None
workflow = [('train', 1)]
plugin = True
plugin_dir = 'projects/mmdet3d_plugin/'
voxel_size = [0.2, 0.2, 8]
patch_size = [102.4, 102.4]
img_norm_cfg = dict(
    mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)
_dim_ = 256
_pos_dim_ = 128
_ffn_dim_ = 512
_num_levels_ = 4
bev_h_ = 200
bev_w_ = 200
_feed_dim_ = 512
_dim_half_ = 128
canvas_size = (200, 200)
queue_length = 5
predict_steps = 12
predict_modes = 6
fut_steps = 4
past_steps = 4
use_nonlinear_optimizer = True
occ_n_future = 4
occ_n_future_plan = 6
occ_n_future_max = 6
planning_steps = 6
use_col_optim = True
planning_evaluation_strategy = 'uniad'
occflow_grid_conf = dict(
    xbound=[-50.0, 50.0, 0.5],
    ybound=[-50.0, 50.0, 0.5],
    zbound=[-10.0, 10.0, 20.0])
train_gt_iou_threshold = 0.3
model = dict(
    type='UniAD',
    gt_iou_threshold=0.3,
    queue_length=5,
    use_grid_mask=True,
    video_test_mode=True,
    num_query=900,
    num_classes=10,
    pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
    img_backbone=dict(
        type='ResNet',
        depth=101,
        num_stages=4,
        out_indices=(1, 2, 3),
        frozen_stages=4,
        norm_cfg=dict(type='BN2d', requires_grad=False),
        norm_eval=True,
        style='caffe',
        dcn=dict(type='DCNv2', deform_groups=1, fallback_on_stride=False),
        stage_with_dcn=(False, False, True, True)),
    img_neck=dict(
        type='FPN',
        in_channels=[512, 1024, 2048],
        out_channels=256,
        start_level=0,
        add_extra_convs='on_output',
        num_outs=4,
        relu_before_extra_convs=True),
    freeze_img_backbone=True,
    freeze_img_neck=False,
    freeze_bn=False,
    score_thresh=0.4,
    filter_score_thresh=0.35,
    qim_args=dict(
        qim_type='QIMBase',
        merger_dropout=0,
        update_query_pos=True,
        fp_ratio=0.3,
        random_drop=0.1),
    mem_args=dict(
        memory_bank_type='MemoryBank',
        memory_bank_score_thresh=0.0,
        memory_bank_len=4),
    loss_cfg=dict(
        type='ClipMatcher',
        num_classes=10,
        weight_dict=None,
        code_weights=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.2],
        assigner=dict(
            type='HungarianAssigner3DTrack',
            cls_cost=dict(type='FocalLossCost', weight=2.0),
            reg_cost=dict(type='BBox3DL1Cost', weight=0.25),
            pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=2.0),
        loss_bbox=dict(type='L1Loss', loss_weight=0.25),
        loss_past_traj_weight=0.0),
    pts_bbox_head=dict(
        type='BEVFormerTrackHead',
        bev_h=200,
        bev_w=200,
        num_query=900,
        num_classes=10,
        in_channels=256,
        sync_cls_avg_factor=True,
        with_box_refine=True,
        as_two_stage=False,
        past_steps=4,
        fut_steps=4,
        transformer=dict(
            type='PerceptionTransformer',
            rotate_prev_bev=True,
            use_shift=True,
            use_can_bus=True,
            embed_dims=256,
            encoder=dict(
                type='BEVFormerEncoder',
                num_layers=6,
                pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
                num_points_in_pillar=4,
                return_intermediate=False,
                transformerlayers=dict(
                    type='BEVFormerLayer',
                    attn_cfgs=[
                        dict(
                            type='TemporalSelfAttention',
                            embed_dims=256,
                            num_levels=1),
                        dict(
                            type='SpatialCrossAttention',
                            pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
                            deformable_attention=dict(
                                type='MSDeformableAttention3D',
                                embed_dims=256,
                                num_points=8,
                                num_levels=4),
                            embed_dims=256)
                    ],
                    feedforward_channels=512,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm'))),
            decoder=dict(
                type='DetectionTransformerDecoder',
                num_layers=6,
                return_intermediate=True,
                transformerlayers=dict(
                    type='DetrTransformerDecoderLayer',
                    attn_cfgs=[
                        dict(
                            type='MultiheadAttention',
                            embed_dims=256,
                            num_heads=8,
                            dropout=0.1),
                        dict(
                            type='CustomMSDeformableAttention',
                            embed_dims=256,
                            num_levels=1)
                    ],
                    feedforward_channels=512,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm')))),
        bbox_coder=dict(
            type='NMSFreeCoder',
            post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
            pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
            max_num=300,
            voxel_size=[0.2, 0.2, 8],
            num_classes=10),
        positional_encoding=dict(
            type='LearnedPositionalEncoding',
            num_feats=128,
            row_num_embed=200,
            col_num_embed=200),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=2.0),
        loss_bbox=dict(type='L1Loss', loss_weight=0.25),
        loss_iou=dict(type='GIoULoss', loss_weight=0.0)),
    seg_head=dict(
        type='PansegformerHead',
        bev_h=200,
        bev_w=200,
        canvas_size=(200, 200),
        pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
        num_query=300,
        num_classes=4,
        num_things_classes=3,
        num_stuff_classes=1,
        in_channels=2048,
        sync_cls_avg_factor=True,
        as_two_stage=False,
        with_box_refine=True,
        transformer=dict(
            type='SegDeformableTransformer',
            encoder=dict(
                type='DetrTransformerEncoder',
                num_layers=6,
                transformerlayers=dict(
                    type='BaseTransformerLayer',
                    attn_cfgs=dict(
                        type='MultiScaleDeformableAttention',
                        embed_dims=256,
                        num_levels=4),
                    feedforward_channels=512,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'ffn', 'norm'))),
            decoder=dict(
                type='DeformableDetrTransformerDecoder',
                num_layers=6,
                return_intermediate=True,
                transformerlayers=dict(
                    type='DetrTransformerDecoderLayer',
                    attn_cfgs=[
                        dict(
                            type='MultiheadAttention',
                            embed_dims=256,
                            num_heads=8,
                            dropout=0.1),
                        dict(
                            type='MultiScaleDeformableAttention',
                            embed_dims=256,
                            num_levels=4)
                    ],
                    feedforward_channels=512,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm')))),
        positional_encoding=dict(
            type='SinePositionalEncoding',
            num_feats=128,
            normalize=True,
            offset=-0.5),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=2.0),
        loss_bbox=dict(type='L1Loss', loss_weight=5.0),
        loss_iou=dict(type='GIoULoss', loss_weight=2.0),
        loss_mask=dict(type='DiceLoss', loss_weight=2.0),
        thing_transformer_head=dict(
            type='SegMaskHead', d_model=256, nhead=8, num_decoder_layers=4),
        stuff_transformer_head=dict(
            type='SegMaskHead',
            d_model=256,
            nhead=8,
            num_decoder_layers=6,
            self_attn=True),
        train_cfg=dict(
            assigner=dict(
                type='HungarianAssigner',
                cls_cost=dict(type='FocalLossCost', weight=2.0),
                reg_cost=dict(
                    type='BBoxL1Cost', weight=5.0, box_format='xywh'),
                iou_cost=dict(type='IoUCost', iou_mode='giou', weight=2.0)),
            assigner_with_mask=dict(
                type='HungarianAssigner_multi_info',
                cls_cost=dict(type='FocalLossCost', weight=2.0),
                reg_cost=dict(
                    type='BBoxL1Cost', weight=5.0, box_format='xywh'),
                iou_cost=dict(type='IoUCost', iou_mode='giou', weight=2.0),
                mask_cost=dict(type='DiceCost', weight=2.0)),
            sampler=dict(type='PseudoSampler'),
            sampler_with_mask=dict(type='PseudoSampler_segformer'))),
    train_cfg=dict(
        pts=dict(
            grid_size=[512, 512, 1],
            voxel_size=[0.2, 0.2, 8],
            point_cloud_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0],
            out_size_factor=4,
            assigner=dict(
                type='HungarianAssigner3D',
                cls_cost=dict(type='FocalLossCost', weight=2.0),
                reg_cost=dict(type='BBox3DL1Cost', weight=0.25),
                iou_cost=dict(type='IoUCost', weight=0.0),
                pc_range=[-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]))))
info_root = 'data/infos/'
ann_file_train = 'data/infos/nuscenes_infos_temporal_train.pkl'
ann_file_val = 'data/infos/nuscenes_infos_temporal_val.pkl'
ann_file_test = 'data/infos/nuscenes_infos_temporal_val.pkl'
optimizer = dict(
    type='AdamW',
    lr=0.0002,
    paramwise_cfg=dict(custom_keys=dict(img_backbone=dict(lr_mult=0.1))),
    weight_decay=0.01)
optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))
lr_config = dict(
    policy='CosineAnnealing',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.3333333333333333,
    min_lr_ratio=0.001)
total_epochs = 6
runner = dict(type='EpochBasedRunner', max_epochs=6)
find_unused_parameters = True
custom_imports = dict(
    imports=['my_hooks.profiler_hook'], allow_failed_imports=False)
custom_hooks = [
    dict(
        type='MyProfilerHook',
        log_dir='./profiler_logs',
        profile_step_start=20,
        profile_step_end=22,
        priority='NORMAL')
]
gpu_ids = range(0, 1)

2025-05-12 07:47:48,111 - mmdet - INFO - Set random seed to 0, deterministic: True
2025-05-12 07:47:59,780 - mmcv - INFO - initialize ResNet with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2025-05-12 07:48:02,861 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:02,884 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:02,906 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:02,972 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:03,057 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:03,127 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:03,210 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:03,450 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:03,614 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:03,748 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:03,886 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:04,057 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:04,200 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:04,345 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:04,474 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:04,613 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:04,735 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:04,868 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:04,998 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:05,137 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:05,269 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:05,403 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:05,538 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:05,681 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:05,815 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:05,939 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:06,079 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:06,213 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:06,349 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:06,483 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:07,742 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:07,904 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:08,064 - mmcv - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2025-05-12 07:48:09,975 - mmcv - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2025-05-12 07:48:12,582 - mmcv - INFO - 
pts_bbox_head.code_weights - torch.Size([10]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,582 - mmcv - INFO - 
pts_bbox_head.positional_encoding.row_embed.weight - torch.Size([200, 128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,582 - mmcv - INFO - 
pts_bbox_head.positional_encoding.col_embed.weight - torch.Size([200, 128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,582 - mmcv - INFO - 
pts_bbox_head.transformer.level_embeds - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,582 - mmcv - INFO - 
pts_bbox_head.transformer.cams_embeds - torch.Size([6, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.weight - torch.Size([128, 512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.attentions.0.attention_weights.weight - torch.Size([64, 512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.attentions.0.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.sampling_offsets.weight - torch.Size([512, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.sampling_offsets.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.attention_weights.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.attention_weights.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.attentions.1.deformable_attention.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.weight - torch.Size([128, 512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.attentions.0.attention_weights.weight - torch.Size([64, 512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.attentions.0.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.sampling_offsets.weight - torch.Size([512, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.sampling_offsets.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.attention_weights.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.attention_weights.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,583 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.attentions.1.deformable_attention.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.weight - torch.Size([128, 512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.attentions.0.attention_weights.weight - torch.Size([64, 512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.attentions.0.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.sampling_offsets.weight - torch.Size([512, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.sampling_offsets.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.attention_weights.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.attention_weights.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.attentions.1.deformable_attention.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.weight - torch.Size([128, 512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.attentions.0.attention_weights.weight - torch.Size([64, 512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.attentions.0.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,584 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.attentions.1.deformable_attention.sampling_offsets.weight - torch.Size([512, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.attentions.1.deformable_attention.sampling_offsets.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.attentions.1.deformable_attention.attention_weights.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.attentions.1.deformable_attention.attention_weights.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.attentions.1.deformable_attention.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.attentions.1.deformable_attention.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.weight - torch.Size([128, 512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.attentions.0.attention_weights.weight - torch.Size([64, 512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.attentions.0.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.attentions.1.deformable_attention.sampling_offsets.weight - torch.Size([512, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.attentions.1.deformable_attention.sampling_offsets.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.attentions.1.deformable_attention.attention_weights.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.attentions.1.deformable_attention.attention_weights.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.attentions.1.deformable_attention.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.attentions.1.deformable_attention.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.weight - torch.Size([128, 512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,585 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.attentions.0.attention_weights.weight - torch.Size([64, 512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.attentions.0.attention_weights.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.attentions.1.deformable_attention.sampling_offsets.weight - torch.Size([512, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.attentions.1.deformable_attention.sampling_offsets.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.attentions.1.deformable_attention.attention_weights.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.attentions.1.deformable_attention.attention_weights.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.attentions.1.deformable_attention.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.attentions.1.deformable_attention.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.encoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.attentions.1.attention_weights.weight - torch.Size([32, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.attentions.1.attention_weights.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,586 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.attentions.1.attention_weights.weight - torch.Size([32, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.attentions.1.attention_weights.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.attentions.1.attention_weights.weight - torch.Size([32, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.attentions.1.attention_weights.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,587 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.attentions.1.attention_weights.weight - torch.Size([32, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.attentions.1.attention_weights.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.attentions.1.attention_weights.weight - torch.Size([32, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.attentions.1.attention_weights.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.weight - torch.Size([64, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.attentions.1.attention_weights.weight - torch.Size([32, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.attentions.1.attention_weights.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,588 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.can_bus_mlp.0.weight - torch.Size([128, 18]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.can_bus_mlp.0.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.can_bus_mlp.2.weight - torch.Size([256, 128]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.can_bus_mlp.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.can_bus_mlp.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.transformer.can_bus_mlp.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.0.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.0.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.0.3.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.0.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.0.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.0.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.0.6.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.0.6.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.1.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.1.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.1.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.1.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.1.3.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.1.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.1.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.1.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.1.6.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.1.6.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.2.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.2.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.2.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.2.3.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.2.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.2.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.2.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.2.6.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.2.6.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,589 - mmcv - INFO - 
pts_bbox_head.cls_branches.3.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.3.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.3.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.3.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.3.3.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.3.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.3.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.3.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.3.6.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.3.6.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.4.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.4.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.4.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.4.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.4.3.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.4.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.4.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.4.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.4.6.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.4.6.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.5.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.5.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.5.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.5.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.5.3.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.5.3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.5.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.5.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.5.6.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.cls_branches.5.6.bias - torch.Size([10]): 
Initialized by user-defined `init_weights` in BEVFormerTrackHead  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.0.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.0.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.0.4.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.0.4.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.1.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.1.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.1.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.1.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.1.4.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.1.4.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.2.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.2.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.2.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.2.4.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.2.4.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.3.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.3.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,590 - mmcv - INFO - 
pts_bbox_head.reg_branches.3.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.reg_branches.3.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.reg_branches.3.4.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.reg_branches.3.4.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.reg_branches.4.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.reg_branches.4.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.reg_branches.4.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.reg_branches.4.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.reg_branches.4.4.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.reg_branches.4.4.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.reg_branches.5.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.reg_branches.5.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.reg_branches.5.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.reg_branches.5.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.reg_branches.5.4.weight - torch.Size([10, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.reg_branches.5.4.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.0.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.0.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.0.4.weight - torch.Size([16, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.0.4.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.1.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.1.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.1.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.1.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.1.4.weight - torch.Size([16, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.1.4.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.2.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.2.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.2.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.2.4.weight - torch.Size([16, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.2.4.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.3.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.3.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.3.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.3.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.3.4.weight - torch.Size([16, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.3.4.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.4.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.4.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.4.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.4.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.4.4.weight - torch.Size([16, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.4.4.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.5.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.5.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.5.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.5.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.5.4.weight - torch.Size([16, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,591 - mmcv - INFO - 
pts_bbox_head.past_traj_reg_branches.5.4.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
pts_bbox_head.bev_embedding.weight - torch.Size([40000, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.0.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.0.bn3.weight - torch.Size([256]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.0.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.1.bn3.weight - torch.Size([256]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.1.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.2.bn3.weight - torch.Size([256]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer1.2.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer2.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer2.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer2.0.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer2.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer2.0.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer2.0.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer2.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer2.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,592 - mmcv - INFO - 
img_backbone.layer2.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.1.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.1.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.2.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.2.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.3.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.3.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.3.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.3.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.3.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer2.3.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.0.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.0.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.0.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.0.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.1.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.1.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.1.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.1.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.2.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.2.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.2.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.2.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,593 - mmcv - INFO - 
img_backbone.layer3.2.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.2.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.2.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.2.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.3.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.3.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.3.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.3.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.3.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.3.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.3.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.3.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.4.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.4.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.4.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.4.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.4.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.4.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.4.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.4.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.5.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.5.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.5.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.5.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.5.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.5.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.5.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.5.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.6.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.6.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.6.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.6.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.6.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.6.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.6.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.6.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.6.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.6.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.6.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.7.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.7.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.7.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.7.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,594 - mmcv - INFO - 
img_backbone.layer3.7.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.7.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.7.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.7.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.7.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.7.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.7.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.8.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.8.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.8.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.8.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.8.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.8.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.8.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.8.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.8.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.8.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.8.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.9.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.9.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.9.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.9.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.9.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.9.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.9.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.9.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.9.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.9.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.9.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.10.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.10.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.10.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.10.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.10.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.10.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.10.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.10.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.10.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.10.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.10.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.11.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.11.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.11.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.11.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.11.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.11.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.11.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.11.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.11.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.11.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.11.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.12.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.12.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.12.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.12.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,595 - mmcv - INFO - 
img_backbone.layer3.12.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.12.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.12.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.12.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.12.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.12.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.12.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.13.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.13.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.13.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.13.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.13.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.13.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.13.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.13.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.13.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.13.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.13.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.14.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.14.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.14.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.14.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.14.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.14.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.14.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.14.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.14.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.14.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.14.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.15.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.15.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.15.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.15.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.15.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.15.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.15.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.15.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.15.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.15.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.15.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.16.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.16.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.16.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.16.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.16.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.16.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.16.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.16.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.16.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.16.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.16.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.17.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.17.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.17.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.17.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.17.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,596 - mmcv - INFO - 
img_backbone.layer3.17.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.17.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.17.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.17.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.17.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.17.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.18.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.18.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.18.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.18.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.18.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.18.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.18.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.18.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.18.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.18.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.18.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.19.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.19.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.19.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.19.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.19.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.19.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.19.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.19.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.19.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.19.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.19.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.20.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.20.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.20.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.20.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.20.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.20.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.20.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.20.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.20.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.20.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.20.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.21.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.21.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.21.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.21.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.21.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.21.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.21.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.21.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.21.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.21.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.21.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.22.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.22.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.22.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.22.conv2.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.22.conv2.conv_offset.weight - torch.Size([27, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,597 - mmcv - INFO - 
img_backbone.layer3.22.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer3.22.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer3.22.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer3.22.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer3.22.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer3.22.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.0.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.0.conv2.conv_offset.weight - torch.Size([27, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.0.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.0.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.0.bn3.weight - torch.Size([2048]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.0.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.1.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.1.conv2.conv_offset.weight - torch.Size([27, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.1.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.1.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.1.bn3.weight - torch.Size([2048]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.1.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.2.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.2.conv2.conv_offset.weight - torch.Size([27, 512, 3, 3]): 
Initialized by user-defined `init_weights` in ModulatedDeformConv2dPack  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.2.conv2.conv_offset.bias - torch.Size([27]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.2.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.2.bn3.weight - torch.Size([2048]): 
ConstantInit: val=0, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_backbone.layer4.2.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_neck.lateral_convs.0.conv.weight - torch.Size([256, 512, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_neck.lateral_convs.1.conv.weight - torch.Size([256, 1024, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_neck.lateral_convs.2.conv.weight - torch.Size([256, 2048, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,598 - mmcv - INFO - 
img_neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
img_neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_embedding.weight - torch.Size([901, 512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
reference_points.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
reference_points.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.self_attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.self_attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.self_attn.out_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.self_attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.linear1.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.linear1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.linear2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.linear2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.linear_pos1.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.linear_pos1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.linear_pos2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.linear_pos2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.norm_pos.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.norm_pos.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.linear_feat1.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.linear_feat1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.linear_feat2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.linear_feat2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.norm_feat.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.norm_feat.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
query_interact.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
memory_bank.save_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
memory_bank.save_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
memory_bank.temporal_attn.in_proj_weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
memory_bank.temporal_attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
memory_bank.temporal_attn.out_proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
memory_bank.temporal_attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
memory_bank.temporal_fc1.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
memory_bank.temporal_fc1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
memory_bank.temporal_fc2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
memory_bank.temporal_fc2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
memory_bank.temporal_norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
memory_bank.temporal_norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
memory_bank.temporal_norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
memory_bank.temporal_norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
seg_head.transformer.level_embeds - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
seg_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
seg_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
seg_head.transformer.encoder.layers.0.attentions.0.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
seg_head.transformer.encoder.layers.0.attentions.0.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
seg_head.transformer.encoder.layers.0.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
seg_head.transformer.encoder.layers.0.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,599 - mmcv - INFO - 
seg_head.transformer.encoder.layers.0.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.0.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.1.attentions.0.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.1.attentions.0.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.1.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.1.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.1.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.1.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.2.attentions.0.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.2.attentions.0.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.2.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.2.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.2.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.2.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.3.attentions.0.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.3.attentions.0.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.3.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.3.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.3.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.3.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,600 - mmcv - INFO - 
seg_head.transformer.encoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.4.attentions.0.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.4.attentions.0.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.4.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.4.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.4.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.4.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.5.attentions.0.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.5.attentions.0.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.5.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.5.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.5.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.5.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,601 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,602 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,603 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([512, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.transformer.decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.transformer.reference_points.weight - torch.Size([2, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.transformer.reference_points.bias - torch.Size([2]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.bev_embedding.weight - torch.Size([40000, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.cls_branches.0.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.cls_branches.0.bias - torch.Size([3]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.cls_branches.1.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.cls_branches.1.bias - torch.Size([3]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.cls_branches.2.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.cls_branches.2.bias - torch.Size([3]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.cls_branches.3.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.cls_branches.3.bias - torch.Size([3]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.cls_branches.4.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.cls_branches.4.bias - torch.Size([3]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.cls_branches.5.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.cls_branches.5.bias - torch.Size([3]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.0.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.0.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.0.4.weight - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.0.4.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.1.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.1.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.1.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.1.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.1.4.weight - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.1.4.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.2.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.2.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.2.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.2.4.weight - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.2.4.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.3.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.3.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.3.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.3.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.3.4.weight - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.3.4.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.4.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.4.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.4.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.4.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.4.4.weight - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,604 - mmcv - INFO - 
seg_head.reg_branches.4.4.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches.5.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches.5.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches.5.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches.5.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches.5.4.weight - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches.5.4.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.query_embedding.weight - torch.Size([300, 512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.stuff_query.weight - torch.Size([1, 512]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.0.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.0.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.0.4.weight - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.0.4.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.1.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.1.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.1.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.1.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.1.4.weight - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.1.4.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.2.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.2.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.2.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.2.4.weight - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.2.4.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.3.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.3.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.3.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.3.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.3.4.weight - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.reg_branches2.3.4.bias - torch.Size([4]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_thing_branches.0.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_thing_branches.0.bias - torch.Size([3]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_thing_branches.1.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_thing_branches.1.bias - torch.Size([3]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_thing_branches.2.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_thing_branches.2.bias - torch.Size([3]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_thing_branches.3.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_thing_branches.3.bias - torch.Size([3]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_stuff_branches.0.weight - torch.Size([1, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_stuff_branches.0.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_stuff_branches.1.weight - torch.Size([1, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_stuff_branches.1.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_stuff_branches.2.weight - torch.Size([1, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_stuff_branches.2.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_stuff_branches.3.weight - torch.Size([1, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_stuff_branches.3.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_stuff_branches.4.weight - torch.Size([1, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_stuff_branches.4.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_stuff_branches.5.weight - torch.Size([1, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.cls_stuff_branches.5.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in PansegformerHead  
 
2025-05-12 07:48:12,605 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.head_norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.head_norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.attn.q.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.attn.q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.attn.k.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.attn.k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.attn.v.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.attn.v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.attn.linear_l1.0.weight - torch.Size([8, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.attn.linear_l1.0.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.attn.linear.0.weight - torch.Size([1, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.attn.linear.0.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.head_norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.head_norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.mlp.fc1.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.mlp.fc1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.mlp.fc2.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.0.mlp.fc2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.head_norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.head_norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.attn.q.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.attn.q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.attn.k.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.attn.k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.attn.v.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.attn.v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.attn.linear_l1.0.weight - torch.Size([8, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.attn.linear_l1.0.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.attn.linear.0.weight - torch.Size([1, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.attn.linear.0.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.head_norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.head_norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.mlp.fc1.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.mlp.fc1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.mlp.fc2.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.1.mlp.fc2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.head_norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.head_norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.attn.q.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.attn.q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.attn.k.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.attn.k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.attn.v.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.attn.v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,606 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.attn.linear_l1.0.weight - torch.Size([8, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.attn.linear_l1.0.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.attn.linear.0.weight - torch.Size([1, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.attn.linear.0.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.head_norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.head_norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.mlp.fc1.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.mlp.fc1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.mlp.fc2.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.2.mlp.fc2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.head_norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.head_norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.attn.q.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.attn.q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.attn.k.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.attn.k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.attn.v.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.attn.v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.attn.linear_l1.0.weight - torch.Size([8, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.attn.linear_l1.0.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.attn.linear.0.weight - torch.Size([1, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.attn.linear.0.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.head_norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.head_norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.mlp.fc1.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.mlp.fc1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.mlp.fc2.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.blocks.3.mlp.fc2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.attnen.q.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.attnen.q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.attnen.k.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.attnen.k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.attnen.linear_l1.0.weight - torch.Size([8, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.attnen.linear_l1.0.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.attnen.linear.0.weight - torch.Size([1, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.things_mask_head.attnen.linear.0.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.head_norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.head_norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.attn.q.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.attn.q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.attn.k.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.attn.k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.attn.v.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.attn.v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.attn.linear_l1.0.weight - torch.Size([8, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.attn.linear_l1.0.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.attn.linear.0.weight - torch.Size([1, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.attn.linear.0.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.head_norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.head_norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.mlp.fc1.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,607 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.mlp.fc1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.mlp.fc2.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.mlp.fc2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.self_attention.qkv.weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.self_attention.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.self_attention.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.self_attention.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.0.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.head_norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.head_norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.attn.q.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.attn.q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.attn.k.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.attn.k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.attn.v.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.attn.v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.attn.linear_l1.0.weight - torch.Size([8, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.attn.linear_l1.0.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.attn.linear.0.weight - torch.Size([1, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.attn.linear.0.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.head_norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.head_norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.mlp.fc1.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.mlp.fc1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.mlp.fc2.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.mlp.fc2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.self_attention.qkv.weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.self_attention.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.self_attention.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.self_attention.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.1.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.head_norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.head_norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.attn.q.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.attn.q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.attn.k.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.attn.k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.attn.v.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.attn.v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.attn.linear_l1.0.weight - torch.Size([8, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.attn.linear_l1.0.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.attn.linear.0.weight - torch.Size([1, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.attn.linear.0.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.head_norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.head_norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.mlp.fc1.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.mlp.fc1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.mlp.fc2.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.mlp.fc2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,608 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.self_attention.qkv.weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.self_attention.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.self_attention.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.self_attention.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.2.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.head_norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.head_norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.attn.q.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.attn.q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.attn.k.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.attn.k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.attn.v.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.attn.v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.attn.linear_l1.0.weight - torch.Size([8, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.attn.linear_l1.0.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.attn.linear.0.weight - torch.Size([1, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.attn.linear.0.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.head_norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.head_norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.mlp.fc1.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.mlp.fc1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.mlp.fc2.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.mlp.fc2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.self_attention.qkv.weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.self_attention.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.self_attention.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.self_attention.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.3.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.head_norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.head_norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.attn.q.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.attn.q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.attn.k.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.attn.k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.attn.v.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.attn.v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.attn.linear_l1.0.weight - torch.Size([8, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.attn.linear_l1.0.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.attn.linear.0.weight - torch.Size([1, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.attn.linear.0.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.head_norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.head_norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.mlp.fc1.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.mlp.fc1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.mlp.fc2.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.mlp.fc2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.self_attention.qkv.weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.self_attention.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.self_attention.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.self_attention.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,609 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.4.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.head_norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.head_norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.attn.q.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.attn.q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.attn.k.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.attn.k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.attn.v.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.attn.v.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.attn.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.attn.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.attn.linear_l1.0.weight - torch.Size([8, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.attn.linear_l1.0.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.attn.linear.0.weight - torch.Size([1, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.attn.linear.0.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.head_norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.head_norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.mlp.fc1.weight - torch.Size([1024, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.mlp.fc1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.mlp.fc2.weight - torch.Size([256, 1024]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.mlp.fc2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.self_attention.qkv.weight - torch.Size([768, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.self_attention.qkv.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.self_attention.proj.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.self_attention.proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.norm3.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.blocks.5.norm3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.attnen.q.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.attnen.q.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.attnen.k.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.attnen.k.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.attnen.linear_l1.0.weight - torch.Size([8, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.attnen.linear_l1.0.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.attnen.linear.0.weight - torch.Size([1, 8]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,610 - mmcv - INFO - 
seg_head.stuff_mask_head.attnen.linear.0.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of UniAD  
 
2025-05-12 07:48:12,620 - mmdet - INFO - Model:
UniAD(
  (pts_bbox_head): BEVFormerTrackHead(
    (loss_cls): FocalLoss()
    (loss_bbox): L1Loss()
    (loss_iou): GIoULoss()
    (activate): ReLU(inplace=True)
    (positional_encoding): LearnedPositionalEncoding(num_feats=128, row_num_embed=200, col_num_embed=200)
    (transformer): PerceptionTransformer(
      (encoder): BEVFormerEncoder(
        (layers): ModuleList(
          (0-5): 6 x BEVFormerLayer(
            (attentions): ModuleList(
              (0): TemporalSelfAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=512, out_features=128, bias=True)
                (attention_weights): Linear(in_features=512, out_features=64, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
              (1): SpatialCrossAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (deformable_attention): MSDeformableAttention3D(
                  (sampling_offsets): Linear(in_features=256, out_features=512, bias=True)
                  (attention_weights): Linear(in_features=256, out_features=256, bias=True)
                  (value_proj): Linear(in_features=256, out_features=256, bias=True)
                )
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0-2): 3 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (decoder): DetectionTransformerDecoder(
        (layers): ModuleList(
          (0-5): 6 x DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): CustomMSDeformableAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=64, bias=True)
                (attention_weights): Linear(in_features=256, out_features=32, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0-2): 3 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (can_bus_mlp): Sequential(
        (0): Linear(in_features=18, out_features=128, bias=True)
        (1): ReLU(inplace=True)
        (2): Linear(in_features=128, out_features=256, bias=True)
        (3): ReLU(inplace=True)
        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (cls_branches): ModuleList(
      (0-5): 6 x Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (2): ReLU(inplace=True)
        (3): Linear(in_features=256, out_features=256, bias=True)
        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=10, bias=True)
      )
    )
    (reg_branches): ModuleList(
      (0-5): 6 x Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=10, bias=True)
      )
    )
    (past_traj_reg_branches): ModuleList(
      (0-5): 6 x Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=16, bias=True)
      )
    )
    (bev_embedding): Embedding(40000, 256)
  )
  (img_backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer2): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer3): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (6): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (7): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (8): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (9): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (10): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (11): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (12): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (13): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (14): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (15): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (16): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (17): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (18): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (19): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (20): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (21): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (22): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
    (layer4): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): ModulatedDeformConv2dPack(
          (conv_offset): Conv2d(512, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      init_cfg={'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
    )
  )
  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
  (img_neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fpn_convs): ModuleList(
      (0-2): 3 x ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (grid_mask): GridMask()
  (query_embedding): Embedding(901, 512)
  (reference_points): Linear(in_features=256, out_features=3, bias=True)
  (query_interact): QueryInteractionModule(
    (self_attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
    )
    (linear1): Linear(in_features=256, out_features=256, bias=True)
    (dropout): Dropout(p=0, inplace=False)
    (linear2): Linear(in_features=256, out_features=256, bias=True)
    (linear_pos1): Linear(in_features=256, out_features=256, bias=True)
    (linear_pos2): Linear(in_features=256, out_features=256, bias=True)
    (dropout_pos1): Dropout(p=0, inplace=False)
    (dropout_pos2): Dropout(p=0, inplace=False)
    (norm_pos): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (linear_feat1): Linear(in_features=256, out_features=256, bias=True)
    (linear_feat2): Linear(in_features=256, out_features=256, bias=True)
    (dropout_feat1): Dropout(p=0, inplace=False)
    (dropout_feat2): Dropout(p=0, inplace=False)
    (norm_feat): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (dropout1): Dropout(p=0, inplace=False)
    (dropout2): Dropout(p=0, inplace=False)
  )
  (memory_bank): MemoryBank(
    (save_proj): Linear(in_features=256, out_features=256, bias=True)
    (temporal_attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
    )
    (temporal_fc1): Linear(in_features=256, out_features=256, bias=True)
    (temporal_fc2): Linear(in_features=256, out_features=256, bias=True)
    (temporal_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (temporal_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (criterion): ClipMatcher(
    (loss_cls): FocalLoss()
    (loss_bboxes): L1Loss()
    (loss_predictions): SmoothL1Loss()
  )
  (seg_head): PansegformerHead(
    (loss_cls): FocalLoss()
    (loss_bbox): L1Loss()
    (loss_iou): GIoULoss()
    (activate): ReLU(inplace=True)
    (positional_encoding): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
    (transformer): SegDeformableTransformer(
      (encoder): DetrTransformerEncoder(
        (layers): ModuleList(
          (0-5): 6 x BaseTransformerLayer(
            (attentions): ModuleList(
              (0): MultiScaleDeformableAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (decoder): DeformableDetrTransformerDecoder(
        (layers): ModuleList(
          (0-5): 6 x DetrTransformerDecoderLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
                (dropout_layer): Dropout(p=0.1, inplace=False)
              )
              (1): MultiScaleDeformableAttention(
                (dropout): Dropout(p=0.1, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
                (attention_weights): Linear(in_features=256, out_features=128, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activate): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=512, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.1, inplace=False)
                  )
                  (1): Linear(in_features=512, out_features=256, bias=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (dropout_layer): Identity()
              )
            )
            (norms): ModuleList(
              (0-2): 3 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
      )
      (reference_points): Linear(in_features=256, out_features=2, bias=True)
    )
    (bev_embedding): Embedding(40000, 256)
    (cls_branches): ModuleList(
      (0-5): 6 x Linear(in_features=256, out_features=3, bias=True)
    )
    (reg_branches): ModuleList(
      (0-5): 6 x Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (query_embedding): Embedding(300, 512)
    (stuff_query): Embedding(1, 512)
    (reg_branches2): ModuleList(
      (0-3): 4 x Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=256, bias=True)
        (3): ReLU()
        (4): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (cls_thing_branches): ModuleList(
      (0-3): 4 x Linear(in_features=256, out_features=3, bias=True)
    )
    (cls_stuff_branches): ModuleList(
      (0-5): 6 x Linear(in_features=256, out_features=1, bias=True)
    )
    (loss_mask): DiceLoss()
    (things_mask_head): SegMaskHead(
      (blocks): ModuleList(
        (0-3): 4 x Block(
          (head_norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=256, out_features=256, bias=True)
            (k): Linear(in_features=256, out_features=256, bias=True)
            (v): Linear(in_features=256, out_features=256, bias=True)
            (attn_drop): Dropout(p=0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0, inplace=False)
            (linear_l1): Sequential(
              (0): Linear(in_features=8, out_features=8, bias=True)
              (1): ReLU()
            )
            (linear): Sequential(
              (0): Linear(in_features=8, out_features=1, bias=True)
              (1): ReLU()
            )
          )
          (drop_path): Identity()
          (head_norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0, inplace=False)
          )
        )
      )
      (attnen): AttentionTail(
        (q): Linear(in_features=256, out_features=256, bias=True)
        (k): Linear(in_features=256, out_features=256, bias=True)
        (linear_l1): Sequential(
          (0): Linear(in_features=8, out_features=8, bias=True)
          (1): ReLU()
        )
        (linear): Sequential(
          (0): Linear(in_features=8, out_features=1, bias=True)
          (1): ReLU()
        )
      )
    )
    (stuff_mask_head): SegMaskHead(
      (blocks): ModuleList(
        (0-5): 6 x Block(
          (head_norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=256, out_features=256, bias=True)
            (k): Linear(in_features=256, out_features=256, bias=True)
            (v): Linear(in_features=256, out_features=256, bias=True)
            (attn_drop): Dropout(p=0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0, inplace=False)
            (linear_l1): Sequential(
              (0): Linear(in_features=8, out_features=8, bias=True)
              (1): ReLU()
            )
            (linear): Sequential(
              (0): Linear(in_features=8, out_features=1, bias=True)
              (1): ReLU()
            )
          )
          (drop_path): Identity()
          (head_norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0, inplace=False)
          )
          (self_attention): SelfAttention(
            (qkv): Linear(in_features=256, out_features=768, bias=True)
            (attn_drop): Dropout(p=0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0, inplace=False)
          )
          (norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
        )
      )
      (attnen): AttentionTail(
        (q): Linear(in_features=256, out_features=256, bias=True)
        (k): Linear(in_features=256, out_features=256, bias=True)
        (linear_l1): Sequential(
          (0): Linear(in_features=8, out_features=8, bias=True)
          (1): ReLU()
        )
        (linear): Sequential(
          (0): Linear(in_features=8, out_features=1, bias=True)
          (1): ReLU()
        )
      )
    )
  )
)
======
Loading NuScenes tables for version v1.0-trainval...
23 category,
8 attribute,
4 visibility,
64386 instance,
12 sensor,
10200 calibrated_sensor,
2631083 ego_pose,
68 log,
850 scene,
34149 sample,
2631083 sample_data,
1166187 sample_annotation,
4 map,
Done loading in 36.491 seconds.
======
Reverse indexing ...
Done reverse indexing in 6.6 seconds.
======
======
Loading NuScenes tables for version v1.0-trainval...
23 category,
8 attribute,
4 visibility,
64386 instance,
12 sensor,
10200 calibrated_sensor,
2631083 ego_pose,
68 log,
850 scene,
34149 sample,
2631083 sample_data,
1166187 sample_annotation,
4 map,
Done loading in 35.249 seconds.
======
Reverse indexing ...
Done reverse indexing in 6.5 seconds.
======
2025-05-12 07:49:50,760 - mmdet - INFO - load checkpoint from local path: ckpts/bevformer_r101_dcn_24ep.pth
2025-05-12 07:49:51,022 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.0.conv2 is upgraded to version 2.
2025-05-12 07:49:51,025 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.1.conv2 is upgraded to version 2.
2025-05-12 07:49:51,027 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.2.conv2 is upgraded to version 2.
2025-05-12 07:49:51,029 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.3.conv2 is upgraded to version 2.
2025-05-12 07:49:51,031 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.4.conv2 is upgraded to version 2.
2025-05-12 07:49:51,033 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.5.conv2 is upgraded to version 2.
2025-05-12 07:49:51,034 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.6.conv2 is upgraded to version 2.
2025-05-12 07:49:51,036 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.7.conv2 is upgraded to version 2.
2025-05-12 07:49:51,038 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.8.conv2 is upgraded to version 2.
2025-05-12 07:49:51,040 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.9.conv2 is upgraded to version 2.
2025-05-12 07:49:51,042 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.10.conv2 is upgraded to version 2.
2025-05-12 07:49:51,044 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.11.conv2 is upgraded to version 2.
2025-05-12 07:49:51,046 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.12.conv2 is upgraded to version 2.
2025-05-12 07:49:51,048 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.13.conv2 is upgraded to version 2.
2025-05-12 07:49:51,049 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.14.conv2 is upgraded to version 2.
2025-05-12 07:49:51,051 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.15.conv2 is upgraded to version 2.
2025-05-12 07:49:51,053 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.16.conv2 is upgraded to version 2.
2025-05-12 07:49:51,055 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.17.conv2 is upgraded to version 2.
2025-05-12 07:49:51,057 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.18.conv2 is upgraded to version 2.
2025-05-12 07:49:51,059 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.19.conv2 is upgraded to version 2.
2025-05-12 07:49:51,061 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.20.conv2 is upgraded to version 2.
2025-05-12 07:49:51,063 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.21.conv2 is upgraded to version 2.
2025-05-12 07:49:51,065 - root - INFO - ModulatedDeformConvPack img_backbone.layer3.22.conv2 is upgraded to version 2.
2025-05-12 07:49:51,066 - root - INFO - ModulatedDeformConvPack img_backbone.layer4.0.conv2 is upgraded to version 2.
2025-05-12 07:49:51,069 - root - INFO - ModulatedDeformConvPack img_backbone.layer4.1.conv2 is upgraded to version 2.
2025-05-12 07:49:51,071 - root - INFO - ModulatedDeformConvPack img_backbone.layer4.2.conv2 is upgraded to version 2.
2025-05-12 07:49:51,132 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: pts_bbox_head.query_embedding.weight, pts_bbox_head.transformer.reference_points.weight, pts_bbox_head.transformer.reference_points.bias

missing keys in source state_dict: pts_bbox_head.past_traj_reg_branches.0.0.weight, pts_bbox_head.past_traj_reg_branches.0.0.bias, pts_bbox_head.past_traj_reg_branches.0.2.weight, pts_bbox_head.past_traj_reg_branches.0.2.bias, pts_bbox_head.past_traj_reg_branches.0.4.weight, pts_bbox_head.past_traj_reg_branches.0.4.bias, pts_bbox_head.past_traj_reg_branches.1.0.weight, pts_bbox_head.past_traj_reg_branches.1.0.bias, pts_bbox_head.past_traj_reg_branches.1.2.weight, pts_bbox_head.past_traj_reg_branches.1.2.bias, pts_bbox_head.past_traj_reg_branches.1.4.weight, pts_bbox_head.past_traj_reg_branches.1.4.bias, pts_bbox_head.past_traj_reg_branches.2.0.weight, pts_bbox_head.past_traj_reg_branches.2.0.bias, pts_bbox_head.past_traj_reg_branches.2.2.weight, pts_bbox_head.past_traj_reg_branches.2.2.bias, pts_bbox_head.past_traj_reg_branches.2.4.weight, pts_bbox_head.past_traj_reg_branches.2.4.bias, pts_bbox_head.past_traj_reg_branches.3.0.weight, pts_bbox_head.past_traj_reg_branches.3.0.bias, pts_bbox_head.past_traj_reg_branches.3.2.weight, pts_bbox_head.past_traj_reg_branches.3.2.bias, pts_bbox_head.past_traj_reg_branches.3.4.weight, pts_bbox_head.past_traj_reg_branches.3.4.bias, pts_bbox_head.past_traj_reg_branches.4.0.weight, pts_bbox_head.past_traj_reg_branches.4.0.bias, pts_bbox_head.past_traj_reg_branches.4.2.weight, pts_bbox_head.past_traj_reg_branches.4.2.bias, pts_bbox_head.past_traj_reg_branches.4.4.weight, pts_bbox_head.past_traj_reg_branches.4.4.bias, pts_bbox_head.past_traj_reg_branches.5.0.weight, pts_bbox_head.past_traj_reg_branches.5.0.bias, pts_bbox_head.past_traj_reg_branches.5.2.weight, pts_bbox_head.past_traj_reg_branches.5.2.bias, pts_bbox_head.past_traj_reg_branches.5.4.weight, pts_bbox_head.past_traj_reg_branches.5.4.bias, query_embedding.weight, reference_points.weight, reference_points.bias, query_interact.self_attn.in_proj_weight, query_interact.self_attn.in_proj_bias, query_interact.self_attn.out_proj.weight, query_interact.self_attn.out_proj.bias, query_interact.linear1.weight, query_interact.linear1.bias, query_interact.linear2.weight, query_interact.linear2.bias, query_interact.linear_pos1.weight, query_interact.linear_pos1.bias, query_interact.linear_pos2.weight, query_interact.linear_pos2.bias, query_interact.norm_pos.weight, query_interact.norm_pos.bias, query_interact.linear_feat1.weight, query_interact.linear_feat1.bias, query_interact.linear_feat2.weight, query_interact.linear_feat2.bias, query_interact.norm_feat.weight, query_interact.norm_feat.bias, query_interact.norm1.weight, query_interact.norm1.bias, query_interact.norm2.weight, query_interact.norm2.bias, memory_bank.save_proj.weight, memory_bank.save_proj.bias, memory_bank.temporal_attn.in_proj_weight, memory_bank.temporal_attn.in_proj_bias, memory_bank.temporal_attn.out_proj.weight, memory_bank.temporal_attn.out_proj.bias, memory_bank.temporal_fc1.weight, memory_bank.temporal_fc1.bias, memory_bank.temporal_fc2.weight, memory_bank.temporal_fc2.bias, memory_bank.temporal_norm1.weight, memory_bank.temporal_norm1.bias, memory_bank.temporal_norm2.weight, memory_bank.temporal_norm2.bias, criterion.code_weights, seg_head.transformer.level_embeds, seg_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.0.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.0.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.0.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.0.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.0.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.0.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.0.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.0.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.0.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.0.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.0.norms.0.weight, seg_head.transformer.encoder.layers.0.norms.0.bias, seg_head.transformer.encoder.layers.0.norms.1.weight, seg_head.transformer.encoder.layers.0.norms.1.bias, seg_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.1.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.1.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.1.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.1.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.1.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.1.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.1.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.1.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.1.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.1.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.1.norms.0.weight, seg_head.transformer.encoder.layers.1.norms.0.bias, seg_head.transformer.encoder.layers.1.norms.1.weight, seg_head.transformer.encoder.layers.1.norms.1.bias, seg_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.2.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.2.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.2.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.2.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.2.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.2.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.2.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.2.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.2.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.2.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.2.norms.0.weight, seg_head.transformer.encoder.layers.2.norms.0.bias, seg_head.transformer.encoder.layers.2.norms.1.weight, seg_head.transformer.encoder.layers.2.norms.1.bias, seg_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.3.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.3.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.3.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.3.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.3.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.3.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.3.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.3.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.3.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.3.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.3.norms.0.weight, seg_head.transformer.encoder.layers.3.norms.0.bias, seg_head.transformer.encoder.layers.3.norms.1.weight, seg_head.transformer.encoder.layers.3.norms.1.bias, seg_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.4.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.4.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.4.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.4.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.4.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.4.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.4.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.4.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.4.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.4.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.4.norms.0.weight, seg_head.transformer.encoder.layers.4.norms.0.bias, seg_head.transformer.encoder.layers.4.norms.1.weight, seg_head.transformer.encoder.layers.4.norms.1.bias, seg_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.5.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.5.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.5.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.5.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.5.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.5.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.5.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.5.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.5.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.5.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.5.norms.0.weight, seg_head.transformer.encoder.layers.5.norms.0.bias, seg_head.transformer.encoder.layers.5.norms.1.weight, seg_head.transformer.encoder.layers.5.norms.1.bias, seg_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.0.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.0.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.0.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.0.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.0.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.0.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.0.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.0.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.0.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.0.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.0.norms.0.weight, seg_head.transformer.decoder.layers.0.norms.0.bias, seg_head.transformer.decoder.layers.0.norms.1.weight, seg_head.transformer.decoder.layers.0.norms.1.bias, seg_head.transformer.decoder.layers.0.norms.2.weight, seg_head.transformer.decoder.layers.0.norms.2.bias, seg_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.1.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.1.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.1.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.1.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.1.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.1.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.1.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.1.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.1.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.1.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.1.norms.0.weight, seg_head.transformer.decoder.layers.1.norms.0.bias, seg_head.transformer.decoder.layers.1.norms.1.weight, seg_head.transformer.decoder.layers.1.norms.1.bias, seg_head.transformer.decoder.layers.1.norms.2.weight, seg_head.transformer.decoder.layers.1.norms.2.bias, seg_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.2.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.2.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.2.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.2.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.2.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.2.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.2.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.2.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.2.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.2.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.2.norms.0.weight, seg_head.transformer.decoder.layers.2.norms.0.bias, seg_head.transformer.decoder.layers.2.norms.1.weight, seg_head.transformer.decoder.layers.2.norms.1.bias, seg_head.transformer.decoder.layers.2.norms.2.weight, seg_head.transformer.decoder.layers.2.norms.2.bias, seg_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.3.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.3.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.3.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.3.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.3.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.3.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.3.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.3.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.3.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.3.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.3.norms.0.weight, seg_head.transformer.decoder.layers.3.norms.0.bias, seg_head.transformer.decoder.layers.3.norms.1.weight, seg_head.transformer.decoder.layers.3.norms.1.bias, seg_head.transformer.decoder.layers.3.norms.2.weight, seg_head.transformer.decoder.layers.3.norms.2.bias, seg_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.4.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.4.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.4.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.4.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.4.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.4.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.4.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.4.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.4.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.4.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.4.norms.0.weight, seg_head.transformer.decoder.layers.4.norms.0.bias, seg_head.transformer.decoder.layers.4.norms.1.weight, seg_head.transformer.decoder.layers.4.norms.1.bias, seg_head.transformer.decoder.layers.4.norms.2.weight, seg_head.transformer.decoder.layers.4.norms.2.bias, seg_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.5.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.5.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.5.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.5.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.5.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.5.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.5.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.5.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.5.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.5.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.5.norms.0.weight, seg_head.transformer.decoder.layers.5.norms.0.bias, seg_head.transformer.decoder.layers.5.norms.1.weight, seg_head.transformer.decoder.layers.5.norms.1.bias, seg_head.transformer.decoder.layers.5.norms.2.weight, seg_head.transformer.decoder.layers.5.norms.2.bias, seg_head.transformer.reference_points.weight, seg_head.transformer.reference_points.bias, seg_head.bev_embedding.weight, seg_head.cls_branches.0.weight, seg_head.cls_branches.0.bias, seg_head.cls_branches.1.weight, seg_head.cls_branches.1.bias, seg_head.cls_branches.2.weight, seg_head.cls_branches.2.bias, seg_head.cls_branches.3.weight, seg_head.cls_branches.3.bias, seg_head.cls_branches.4.weight, seg_head.cls_branches.4.bias, seg_head.cls_branches.5.weight, seg_head.cls_branches.5.bias, seg_head.reg_branches.0.0.weight, seg_head.reg_branches.0.0.bias, seg_head.reg_branches.0.2.weight, seg_head.reg_branches.0.2.bias, seg_head.reg_branches.0.4.weight, seg_head.reg_branches.0.4.bias, seg_head.reg_branches.1.0.weight, seg_head.reg_branches.1.0.bias, seg_head.reg_branches.1.2.weight, seg_head.reg_branches.1.2.bias, seg_head.reg_branches.1.4.weight, seg_head.reg_branches.1.4.bias, seg_head.reg_branches.2.0.weight, seg_head.reg_branches.2.0.bias, seg_head.reg_branches.2.2.weight, seg_head.reg_branches.2.2.bias, seg_head.reg_branches.2.4.weight, seg_head.reg_branches.2.4.bias, seg_head.reg_branches.3.0.weight, seg_head.reg_branches.3.0.bias, seg_head.reg_branches.3.2.weight, seg_head.reg_branches.3.2.bias, seg_head.reg_branches.3.4.weight, seg_head.reg_branches.3.4.bias, seg_head.reg_branches.4.0.weight, seg_head.reg_branches.4.0.bias, seg_head.reg_branches.4.2.weight, seg_head.reg_branches.4.2.bias, seg_head.reg_branches.4.4.weight, seg_head.reg_branches.4.4.bias, seg_head.reg_branches.5.0.weight, seg_head.reg_branches.5.0.bias, seg_head.reg_branches.5.2.weight, seg_head.reg_branches.5.2.bias, seg_head.reg_branches.5.4.weight, seg_head.reg_branches.5.4.bias, seg_head.query_embedding.weight, seg_head.stuff_query.weight, seg_head.reg_branches2.0.0.weight, seg_head.reg_branches2.0.0.bias, seg_head.reg_branches2.0.2.weight, seg_head.reg_branches2.0.2.bias, seg_head.reg_branches2.0.4.weight, seg_head.reg_branches2.0.4.bias, seg_head.reg_branches2.1.0.weight, seg_head.reg_branches2.1.0.bias, seg_head.reg_branches2.1.2.weight, seg_head.reg_branches2.1.2.bias, seg_head.reg_branches2.1.4.weight, seg_head.reg_branches2.1.4.bias, seg_head.reg_branches2.2.0.weight, seg_head.reg_branches2.2.0.bias, seg_head.reg_branches2.2.2.weight, seg_head.reg_branches2.2.2.bias, seg_head.reg_branches2.2.4.weight, seg_head.reg_branches2.2.4.bias, seg_head.reg_branches2.3.0.weight, seg_head.reg_branches2.3.0.bias, seg_head.reg_branches2.3.2.weight, seg_head.reg_branches2.3.2.bias, seg_head.reg_branches2.3.4.weight, seg_head.reg_branches2.3.4.bias, seg_head.cls_thing_branches.0.weight, seg_head.cls_thing_branches.0.bias, seg_head.cls_thing_branches.1.weight, seg_head.cls_thing_branches.1.bias, seg_head.cls_thing_branches.2.weight, seg_head.cls_thing_branches.2.bias, seg_head.cls_thing_branches.3.weight, seg_head.cls_thing_branches.3.bias, seg_head.cls_stuff_branches.0.weight, seg_head.cls_stuff_branches.0.bias, seg_head.cls_stuff_branches.1.weight, seg_head.cls_stuff_branches.1.bias, seg_head.cls_stuff_branches.2.weight, seg_head.cls_stuff_branches.2.bias, seg_head.cls_stuff_branches.3.weight, seg_head.cls_stuff_branches.3.bias, seg_head.cls_stuff_branches.4.weight, seg_head.cls_stuff_branches.4.bias, seg_head.cls_stuff_branches.5.weight, seg_head.cls_stuff_branches.5.bias, seg_head.things_mask_head.blocks.0.head_norm1.weight, seg_head.things_mask_head.blocks.0.head_norm1.bias, seg_head.things_mask_head.blocks.0.attn.q.weight, seg_head.things_mask_head.blocks.0.attn.q.bias, seg_head.things_mask_head.blocks.0.attn.k.weight, seg_head.things_mask_head.blocks.0.attn.k.bias, seg_head.things_mask_head.blocks.0.attn.v.weight, seg_head.things_mask_head.blocks.0.attn.v.bias, seg_head.things_mask_head.blocks.0.attn.proj.weight, seg_head.things_mask_head.blocks.0.attn.proj.bias, seg_head.things_mask_head.blocks.0.attn.linear_l1.0.weight, seg_head.things_mask_head.blocks.0.attn.linear_l1.0.bias, seg_head.things_mask_head.blocks.0.attn.linear.0.weight, seg_head.things_mask_head.blocks.0.attn.linear.0.bias, seg_head.things_mask_head.blocks.0.head_norm2.weight, seg_head.things_mask_head.blocks.0.head_norm2.bias, seg_head.things_mask_head.blocks.0.mlp.fc1.weight, seg_head.things_mask_head.blocks.0.mlp.fc1.bias, seg_head.things_mask_head.blocks.0.mlp.fc2.weight, seg_head.things_mask_head.blocks.0.mlp.fc2.bias, seg_head.things_mask_head.blocks.1.head_norm1.weight, seg_head.things_mask_head.blocks.1.head_norm1.bias, seg_head.things_mask_head.blocks.1.attn.q.weight, seg_head.things_mask_head.blocks.1.attn.q.bias, seg_head.things_mask_head.blocks.1.attn.k.weight, seg_head.things_mask_head.blocks.1.attn.k.bias, seg_head.things_mask_head.blocks.1.attn.v.weight, seg_head.things_mask_head.blocks.1.attn.v.bias, seg_head.things_mask_head.blocks.1.attn.proj.weight, seg_head.things_mask_head.blocks.1.attn.proj.bias, seg_head.things_mask_head.blocks.1.attn.linear_l1.0.weight, seg_head.things_mask_head.blocks.1.attn.linear_l1.0.bias, seg_head.things_mask_head.blocks.1.attn.linear.0.weight, seg_head.things_mask_head.blocks.1.attn.linear.0.bias, seg_head.things_mask_head.blocks.1.head_norm2.weight, seg_head.things_mask_head.blocks.1.head_norm2.bias, seg_head.things_mask_head.blocks.1.mlp.fc1.weight, seg_head.things_mask_head.blocks.1.mlp.fc1.bias, seg_head.things_mask_head.blocks.1.mlp.fc2.weight, seg_head.things_mask_head.blocks.1.mlp.fc2.bias, seg_head.things_mask_head.blocks.2.head_norm1.weight, seg_head.things_mask_head.blocks.2.head_norm1.bias, seg_head.things_mask_head.blocks.2.attn.q.weight, seg_head.things_mask_head.blocks.2.attn.q.bias, seg_head.things_mask_head.blocks.2.attn.k.weight, seg_head.things_mask_head.blocks.2.attn.k.bias, seg_head.things_mask_head.blocks.2.attn.v.weight, seg_head.things_mask_head.blocks.2.attn.v.bias, seg_head.things_mask_head.blocks.2.attn.proj.weight, seg_head.things_mask_head.blocks.2.attn.proj.bias, seg_head.things_mask_head.blocks.2.attn.linear_l1.0.weight, seg_head.things_mask_head.blocks.2.attn.linear_l1.0.bias, seg_head.things_mask_head.blocks.2.attn.linear.0.weight, seg_head.things_mask_head.blocks.2.attn.linear.0.bias, seg_head.things_mask_head.blocks.2.head_norm2.weight, seg_head.things_mask_head.blocks.2.head_norm2.bias, seg_head.things_mask_head.blocks.2.mlp.fc1.weight, seg_head.things_mask_head.blocks.2.mlp.fc1.bias, seg_head.things_mask_head.blocks.2.mlp.fc2.weight, seg_head.things_mask_head.blocks.2.mlp.fc2.bias, seg_head.things_mask_head.blocks.3.head_norm1.weight, seg_head.things_mask_head.blocks.3.head_norm1.bias, seg_head.things_mask_head.blocks.3.attn.q.weight, seg_head.things_mask_head.blocks.3.attn.q.bias, seg_head.things_mask_head.blocks.3.attn.k.weight, seg_head.things_mask_head.blocks.3.attn.k.bias, seg_head.things_mask_head.blocks.3.attn.v.weight, seg_head.things_mask_head.blocks.3.attn.v.bias, seg_head.things_mask_head.blocks.3.attn.proj.weight, seg_head.things_mask_head.blocks.3.attn.proj.bias, seg_head.things_mask_head.blocks.3.attn.linear_l1.0.weight, seg_head.things_mask_head.blocks.3.attn.linear_l1.0.bias, seg_head.things_mask_head.blocks.3.attn.linear.0.weight, seg_head.things_mask_head.blocks.3.attn.linear.0.bias, seg_head.things_mask_head.blocks.3.head_norm2.weight, seg_head.things_mask_head.blocks.3.head_norm2.bias, seg_head.things_mask_head.blocks.3.mlp.fc1.weight, seg_head.things_mask_head.blocks.3.mlp.fc1.bias, seg_head.things_mask_head.blocks.3.mlp.fc2.weight, seg_head.things_mask_head.blocks.3.mlp.fc2.bias, seg_head.things_mask_head.attnen.q.weight, seg_head.things_mask_head.attnen.q.bias, seg_head.things_mask_head.attnen.k.weight, seg_head.things_mask_head.attnen.k.bias, seg_head.things_mask_head.attnen.linear_l1.0.weight, seg_head.things_mask_head.attnen.linear_l1.0.bias, seg_head.things_mask_head.attnen.linear.0.weight, seg_head.things_mask_head.attnen.linear.0.bias, seg_head.stuff_mask_head.blocks.0.head_norm1.weight, seg_head.stuff_mask_head.blocks.0.head_norm1.bias, seg_head.stuff_mask_head.blocks.0.attn.q.weight, seg_head.stuff_mask_head.blocks.0.attn.q.bias, seg_head.stuff_mask_head.blocks.0.attn.k.weight, seg_head.stuff_mask_head.blocks.0.attn.k.bias, seg_head.stuff_mask_head.blocks.0.attn.v.weight, seg_head.stuff_mask_head.blocks.0.attn.v.bias, seg_head.stuff_mask_head.blocks.0.attn.proj.weight, seg_head.stuff_mask_head.blocks.0.attn.proj.bias, seg_head.stuff_mask_head.blocks.0.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.0.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.0.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.0.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.0.head_norm2.weight, seg_head.stuff_mask_head.blocks.0.head_norm2.bias, seg_head.stuff_mask_head.blocks.0.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.0.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.0.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.0.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.0.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.0.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.0.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.0.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.0.norm3.weight, seg_head.stuff_mask_head.blocks.0.norm3.bias, seg_head.stuff_mask_head.blocks.1.head_norm1.weight, seg_head.stuff_mask_head.blocks.1.head_norm1.bias, seg_head.stuff_mask_head.blocks.1.attn.q.weight, seg_head.stuff_mask_head.blocks.1.attn.q.bias, seg_head.stuff_mask_head.blocks.1.attn.k.weight, seg_head.stuff_mask_head.blocks.1.attn.k.bias, seg_head.stuff_mask_head.blocks.1.attn.v.weight, seg_head.stuff_mask_head.blocks.1.attn.v.bias, seg_head.stuff_mask_head.blocks.1.attn.proj.weight, seg_head.stuff_mask_head.blocks.1.attn.proj.bias, seg_head.stuff_mask_head.blocks.1.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.1.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.1.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.1.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.1.head_norm2.weight, seg_head.stuff_mask_head.blocks.1.head_norm2.bias, seg_head.stuff_mask_head.blocks.1.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.1.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.1.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.1.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.1.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.1.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.1.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.1.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.1.norm3.weight, seg_head.stuff_mask_head.blocks.1.norm3.bias, seg_head.stuff_mask_head.blocks.2.head_norm1.weight, seg_head.stuff_mask_head.blocks.2.head_norm1.bias, seg_head.stuff_mask_head.blocks.2.attn.q.weight, seg_head.stuff_mask_head.blocks.2.attn.q.bias, seg_head.stuff_mask_head.blocks.2.attn.k.weight, seg_head.stuff_mask_head.blocks.2.attn.k.bias, seg_head.stuff_mask_head.blocks.2.attn.v.weight, seg_head.stuff_mask_head.blocks.2.attn.v.bias, seg_head.stuff_mask_head.blocks.2.attn.proj.weight, seg_head.stuff_mask_head.blocks.2.attn.proj.bias, seg_head.stuff_mask_head.blocks.2.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.2.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.2.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.2.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.2.head_norm2.weight, seg_head.stuff_mask_head.blocks.2.head_norm2.bias, seg_head.stuff_mask_head.blocks.2.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.2.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.2.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.2.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.2.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.2.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.2.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.2.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.2.norm3.weight, seg_head.stuff_mask_head.blocks.2.norm3.bias, seg_head.stuff_mask_head.blocks.3.head_norm1.weight, seg_head.stuff_mask_head.blocks.3.head_norm1.bias, seg_head.stuff_mask_head.blocks.3.attn.q.weight, seg_head.stuff_mask_head.blocks.3.attn.q.bias, seg_head.stuff_mask_head.blocks.3.attn.k.weight, seg_head.stuff_mask_head.blocks.3.attn.k.bias, seg_head.stuff_mask_head.blocks.3.attn.v.weight, seg_head.stuff_mask_head.blocks.3.attn.v.bias, seg_head.stuff_mask_head.blocks.3.attn.proj.weight, seg_head.stuff_mask_head.blocks.3.attn.proj.bias, seg_head.stuff_mask_head.blocks.3.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.3.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.3.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.3.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.3.head_norm2.weight, seg_head.stuff_mask_head.blocks.3.head_norm2.bias, seg_head.stuff_mask_head.blocks.3.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.3.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.3.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.3.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.3.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.3.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.3.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.3.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.3.norm3.weight, seg_head.stuff_mask_head.blocks.3.norm3.bias, seg_head.stuff_mask_head.blocks.4.head_norm1.weight, seg_head.stuff_mask_head.blocks.4.head_norm1.bias, seg_head.stuff_mask_head.blocks.4.attn.q.weight, seg_head.stuff_mask_head.blocks.4.attn.q.bias, seg_head.stuff_mask_head.blocks.4.attn.k.weight, seg_head.stuff_mask_head.blocks.4.attn.k.bias, seg_head.stuff_mask_head.blocks.4.attn.v.weight, seg_head.stuff_mask_head.blocks.4.attn.v.bias, seg_head.stuff_mask_head.blocks.4.attn.proj.weight, seg_head.stuff_mask_head.blocks.4.attn.proj.bias, seg_head.stuff_mask_head.blocks.4.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.4.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.4.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.4.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.4.head_norm2.weight, seg_head.stuff_mask_head.blocks.4.head_norm2.bias, seg_head.stuff_mask_head.blocks.4.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.4.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.4.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.4.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.4.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.4.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.4.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.4.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.4.norm3.weight, seg_head.stuff_mask_head.blocks.4.norm3.bias, seg_head.stuff_mask_head.blocks.5.head_norm1.weight, seg_head.stuff_mask_head.blocks.5.head_norm1.bias, seg_head.stuff_mask_head.blocks.5.attn.q.weight, seg_head.stuff_mask_head.blocks.5.attn.q.bias, seg_head.stuff_mask_head.blocks.5.attn.k.weight, seg_head.stuff_mask_head.blocks.5.attn.k.bias, seg_head.stuff_mask_head.blocks.5.attn.v.weight, seg_head.stuff_mask_head.blocks.5.attn.v.bias, seg_head.stuff_mask_head.blocks.5.attn.proj.weight, seg_head.stuff_mask_head.blocks.5.attn.proj.bias, seg_head.stuff_mask_head.blocks.5.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.5.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.5.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.5.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.5.head_norm2.weight, seg_head.stuff_mask_head.blocks.5.head_norm2.bias, seg_head.stuff_mask_head.blocks.5.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.5.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.5.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.5.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.5.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.5.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.5.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.5.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.5.norm3.weight, seg_head.stuff_mask_head.blocks.5.norm3.bias, seg_head.stuff_mask_head.attnen.q.weight, seg_head.stuff_mask_head.attnen.q.bias, seg_head.stuff_mask_head.attnen.k.weight, seg_head.stuff_mask_head.attnen.k.bias, seg_head.stuff_mask_head.attnen.linear_l1.0.weight, seg_head.stuff_mask_head.attnen.linear_l1.0.bias, seg_head.stuff_mask_head.attnen.linear.0.weight, seg_head.stuff_mask_head.attnen.linear.0.bias

2025-05-12 07:49:51,132 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: pts_bbox_head.query_embedding.weight, pts_bbox_head.transformer.reference_points.weight, pts_bbox_head.transformer.reference_points.bias

missing keys in source state_dict: pts_bbox_head.past_traj_reg_branches.0.0.weight, pts_bbox_head.past_traj_reg_branches.0.0.bias, pts_bbox_head.past_traj_reg_branches.0.2.weight, pts_bbox_head.past_traj_reg_branches.0.2.bias, pts_bbox_head.past_traj_reg_branches.0.4.weight, pts_bbox_head.past_traj_reg_branches.0.4.bias, pts_bbox_head.past_traj_reg_branches.1.0.weight, pts_bbox_head.past_traj_reg_branches.1.0.bias, pts_bbox_head.past_traj_reg_branches.1.2.weight, pts_bbox_head.past_traj_reg_branches.1.2.bias, pts_bbox_head.past_traj_reg_branches.1.4.weight, pts_bbox_head.past_traj_reg_branches.1.4.bias, pts_bbox_head.past_traj_reg_branches.2.0.weight, pts_bbox_head.past_traj_reg_branches.2.0.bias, pts_bbox_head.past_traj_reg_branches.2.2.weight, pts_bbox_head.past_traj_reg_branches.2.2.bias, pts_bbox_head.past_traj_reg_branches.2.4.weight, pts_bbox_head.past_traj_reg_branches.2.4.bias, pts_bbox_head.past_traj_reg_branches.3.0.weight, pts_bbox_head.past_traj_reg_branches.3.0.bias, pts_bbox_head.past_traj_reg_branches.3.2.weight, pts_bbox_head.past_traj_reg_branches.3.2.bias, pts_bbox_head.past_traj_reg_branches.3.4.weight, pts_bbox_head.past_traj_reg_branches.3.4.bias, pts_bbox_head.past_traj_reg_branches.4.0.weight, pts_bbox_head.past_traj_reg_branches.4.0.bias, pts_bbox_head.past_traj_reg_branches.4.2.weight, pts_bbox_head.past_traj_reg_branches.4.2.bias, pts_bbox_head.past_traj_reg_branches.4.4.weight, pts_bbox_head.past_traj_reg_branches.4.4.bias, pts_bbox_head.past_traj_reg_branches.5.0.weight, pts_bbox_head.past_traj_reg_branches.5.0.bias, pts_bbox_head.past_traj_reg_branches.5.2.weight, pts_bbox_head.past_traj_reg_branches.5.2.bias, pts_bbox_head.past_traj_reg_branches.5.4.weight, pts_bbox_head.past_traj_reg_branches.5.4.bias, query_embedding.weight, reference_points.weight, reference_points.bias, query_interact.self_attn.in_proj_weight, query_interact.self_attn.in_proj_bias, query_interact.self_attn.out_proj.weight, query_interact.self_attn.out_proj.bias, query_interact.linear1.weight, query_interact.linear1.bias, query_interact.linear2.weight, query_interact.linear2.bias, query_interact.linear_pos1.weight, query_interact.linear_pos1.bias, query_interact.linear_pos2.weight, query_interact.linear_pos2.bias, query_interact.norm_pos.weight, query_interact.norm_pos.bias, query_interact.linear_feat1.weight, query_interact.linear_feat1.bias, query_interact.linear_feat2.weight, query_interact.linear_feat2.bias, query_interact.norm_feat.weight, query_interact.norm_feat.bias, query_interact.norm1.weight, query_interact.norm1.bias, query_interact.norm2.weight, query_interact.norm2.bias, memory_bank.save_proj.weight, memory_bank.save_proj.bias, memory_bank.temporal_attn.in_proj_weight, memory_bank.temporal_attn.in_proj_bias, memory_bank.temporal_attn.out_proj.weight, memory_bank.temporal_attn.out_proj.bias, memory_bank.temporal_fc1.weight, memory_bank.temporal_fc1.bias, memory_bank.temporal_fc2.weight, memory_bank.temporal_fc2.bias, memory_bank.temporal_norm1.weight, memory_bank.temporal_norm1.bias, memory_bank.temporal_norm2.weight, memory_bank.temporal_norm2.bias, criterion.code_weights, seg_head.transformer.level_embeds, seg_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.0.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.0.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.0.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.0.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.0.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.0.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.0.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.0.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.0.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.0.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.0.norms.0.weight, seg_head.transformer.encoder.layers.0.norms.0.bias, seg_head.transformer.encoder.layers.0.norms.1.weight, seg_head.transformer.encoder.layers.0.norms.1.bias, seg_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.1.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.1.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.1.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.1.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.1.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.1.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.1.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.1.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.1.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.1.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.1.norms.0.weight, seg_head.transformer.encoder.layers.1.norms.0.bias, seg_head.transformer.encoder.layers.1.norms.1.weight, seg_head.transformer.encoder.layers.1.norms.1.bias, seg_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.2.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.2.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.2.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.2.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.2.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.2.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.2.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.2.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.2.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.2.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.2.norms.0.weight, seg_head.transformer.encoder.layers.2.norms.0.bias, seg_head.transformer.encoder.layers.2.norms.1.weight, seg_head.transformer.encoder.layers.2.norms.1.bias, seg_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.3.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.3.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.3.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.3.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.3.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.3.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.3.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.3.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.3.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.3.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.3.norms.0.weight, seg_head.transformer.encoder.layers.3.norms.0.bias, seg_head.transformer.encoder.layers.3.norms.1.weight, seg_head.transformer.encoder.layers.3.norms.1.bias, seg_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.4.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.4.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.4.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.4.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.4.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.4.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.4.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.4.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.4.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.4.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.4.norms.0.weight, seg_head.transformer.encoder.layers.4.norms.0.bias, seg_head.transformer.encoder.layers.4.norms.1.weight, seg_head.transformer.encoder.layers.4.norms.1.bias, seg_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.weight, seg_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.bias, seg_head.transformer.encoder.layers.5.attentions.0.attention_weights.weight, seg_head.transformer.encoder.layers.5.attentions.0.attention_weights.bias, seg_head.transformer.encoder.layers.5.attentions.0.value_proj.weight, seg_head.transformer.encoder.layers.5.attentions.0.value_proj.bias, seg_head.transformer.encoder.layers.5.attentions.0.output_proj.weight, seg_head.transformer.encoder.layers.5.attentions.0.output_proj.bias, seg_head.transformer.encoder.layers.5.ffns.0.layers.0.0.weight, seg_head.transformer.encoder.layers.5.ffns.0.layers.0.0.bias, seg_head.transformer.encoder.layers.5.ffns.0.layers.1.weight, seg_head.transformer.encoder.layers.5.ffns.0.layers.1.bias, seg_head.transformer.encoder.layers.5.norms.0.weight, seg_head.transformer.encoder.layers.5.norms.0.bias, seg_head.transformer.encoder.layers.5.norms.1.weight, seg_head.transformer.encoder.layers.5.norms.1.bias, seg_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.0.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.0.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.0.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.0.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.0.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.0.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.0.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.0.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.0.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.0.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.0.norms.0.weight, seg_head.transformer.decoder.layers.0.norms.0.bias, seg_head.transformer.decoder.layers.0.norms.1.weight, seg_head.transformer.decoder.layers.0.norms.1.bias, seg_head.transformer.decoder.layers.0.norms.2.weight, seg_head.transformer.decoder.layers.0.norms.2.bias, seg_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.1.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.1.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.1.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.1.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.1.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.1.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.1.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.1.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.1.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.1.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.1.norms.0.weight, seg_head.transformer.decoder.layers.1.norms.0.bias, seg_head.transformer.decoder.layers.1.norms.1.weight, seg_head.transformer.decoder.layers.1.norms.1.bias, seg_head.transformer.decoder.layers.1.norms.2.weight, seg_head.transformer.decoder.layers.1.norms.2.bias, seg_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.2.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.2.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.2.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.2.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.2.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.2.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.2.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.2.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.2.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.2.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.2.norms.0.weight, seg_head.transformer.decoder.layers.2.norms.0.bias, seg_head.transformer.decoder.layers.2.norms.1.weight, seg_head.transformer.decoder.layers.2.norms.1.bias, seg_head.transformer.decoder.layers.2.norms.2.weight, seg_head.transformer.decoder.layers.2.norms.2.bias, seg_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.3.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.3.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.3.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.3.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.3.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.3.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.3.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.3.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.3.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.3.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.3.norms.0.weight, seg_head.transformer.decoder.layers.3.norms.0.bias, seg_head.transformer.decoder.layers.3.norms.1.weight, seg_head.transformer.decoder.layers.3.norms.1.bias, seg_head.transformer.decoder.layers.3.norms.2.weight, seg_head.transformer.decoder.layers.3.norms.2.bias, seg_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.4.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.4.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.4.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.4.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.4.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.4.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.4.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.4.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.4.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.4.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.4.norms.0.weight, seg_head.transformer.decoder.layers.4.norms.0.bias, seg_head.transformer.decoder.layers.4.norms.1.weight, seg_head.transformer.decoder.layers.4.norms.1.bias, seg_head.transformer.decoder.layers.4.norms.2.weight, seg_head.transformer.decoder.layers.4.norms.2.bias, seg_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_weight, seg_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_bias, seg_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.weight, seg_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.bias, seg_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.weight, seg_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.bias, seg_head.transformer.decoder.layers.5.attentions.1.attention_weights.weight, seg_head.transformer.decoder.layers.5.attentions.1.attention_weights.bias, seg_head.transformer.decoder.layers.5.attentions.1.value_proj.weight, seg_head.transformer.decoder.layers.5.attentions.1.value_proj.bias, seg_head.transformer.decoder.layers.5.attentions.1.output_proj.weight, seg_head.transformer.decoder.layers.5.attentions.1.output_proj.bias, seg_head.transformer.decoder.layers.5.ffns.0.layers.0.0.weight, seg_head.transformer.decoder.layers.5.ffns.0.layers.0.0.bias, seg_head.transformer.decoder.layers.5.ffns.0.layers.1.weight, seg_head.transformer.decoder.layers.5.ffns.0.layers.1.bias, seg_head.transformer.decoder.layers.5.norms.0.weight, seg_head.transformer.decoder.layers.5.norms.0.bias, seg_head.transformer.decoder.layers.5.norms.1.weight, seg_head.transformer.decoder.layers.5.norms.1.bias, seg_head.transformer.decoder.layers.5.norms.2.weight, seg_head.transformer.decoder.layers.5.norms.2.bias, seg_head.transformer.reference_points.weight, seg_head.transformer.reference_points.bias, seg_head.bev_embedding.weight, seg_head.cls_branches.0.weight, seg_head.cls_branches.0.bias, seg_head.cls_branches.1.weight, seg_head.cls_branches.1.bias, seg_head.cls_branches.2.weight, seg_head.cls_branches.2.bias, seg_head.cls_branches.3.weight, seg_head.cls_branches.3.bias, seg_head.cls_branches.4.weight, seg_head.cls_branches.4.bias, seg_head.cls_branches.5.weight, seg_head.cls_branches.5.bias, seg_head.reg_branches.0.0.weight, seg_head.reg_branches.0.0.bias, seg_head.reg_branches.0.2.weight, seg_head.reg_branches.0.2.bias, seg_head.reg_branches.0.4.weight, seg_head.reg_branches.0.4.bias, seg_head.reg_branches.1.0.weight, seg_head.reg_branches.1.0.bias, seg_head.reg_branches.1.2.weight, seg_head.reg_branches.1.2.bias, seg_head.reg_branches.1.4.weight, seg_head.reg_branches.1.4.bias, seg_head.reg_branches.2.0.weight, seg_head.reg_branches.2.0.bias, seg_head.reg_branches.2.2.weight, seg_head.reg_branches.2.2.bias, seg_head.reg_branches.2.4.weight, seg_head.reg_branches.2.4.bias, seg_head.reg_branches.3.0.weight, seg_head.reg_branches.3.0.bias, seg_head.reg_branches.3.2.weight, seg_head.reg_branches.3.2.bias, seg_head.reg_branches.3.4.weight, seg_head.reg_branches.3.4.bias, seg_head.reg_branches.4.0.weight, seg_head.reg_branches.4.0.bias, seg_head.reg_branches.4.2.weight, seg_head.reg_branches.4.2.bias, seg_head.reg_branches.4.4.weight, seg_head.reg_branches.4.4.bias, seg_head.reg_branches.5.0.weight, seg_head.reg_branches.5.0.bias, seg_head.reg_branches.5.2.weight, seg_head.reg_branches.5.2.bias, seg_head.reg_branches.5.4.weight, seg_head.reg_branches.5.4.bias, seg_head.query_embedding.weight, seg_head.stuff_query.weight, seg_head.reg_branches2.0.0.weight, seg_head.reg_branches2.0.0.bias, seg_head.reg_branches2.0.2.weight, seg_head.reg_branches2.0.2.bias, seg_head.reg_branches2.0.4.weight, seg_head.reg_branches2.0.4.bias, seg_head.reg_branches2.1.0.weight, seg_head.reg_branches2.1.0.bias, seg_head.reg_branches2.1.2.weight, seg_head.reg_branches2.1.2.bias, seg_head.reg_branches2.1.4.weight, seg_head.reg_branches2.1.4.bias, seg_head.reg_branches2.2.0.weight, seg_head.reg_branches2.2.0.bias, seg_head.reg_branches2.2.2.weight, seg_head.reg_branches2.2.2.bias, seg_head.reg_branches2.2.4.weight, seg_head.reg_branches2.2.4.bias, seg_head.reg_branches2.3.0.weight, seg_head.reg_branches2.3.0.bias, seg_head.reg_branches2.3.2.weight, seg_head.reg_branches2.3.2.bias, seg_head.reg_branches2.3.4.weight, seg_head.reg_branches2.3.4.bias, seg_head.cls_thing_branches.0.weight, seg_head.cls_thing_branches.0.bias, seg_head.cls_thing_branches.1.weight, seg_head.cls_thing_branches.1.bias, seg_head.cls_thing_branches.2.weight, seg_head.cls_thing_branches.2.bias, seg_head.cls_thing_branches.3.weight, seg_head.cls_thing_branches.3.bias, seg_head.cls_stuff_branches.0.weight, seg_head.cls_stuff_branches.0.bias, seg_head.cls_stuff_branches.1.weight, seg_head.cls_stuff_branches.1.bias, seg_head.cls_stuff_branches.2.weight, seg_head.cls_stuff_branches.2.bias, seg_head.cls_stuff_branches.3.weight, seg_head.cls_stuff_branches.3.bias, seg_head.cls_stuff_branches.4.weight, seg_head.cls_stuff_branches.4.bias, seg_head.cls_stuff_branches.5.weight, seg_head.cls_stuff_branches.5.bias, seg_head.things_mask_head.blocks.0.head_norm1.weight, seg_head.things_mask_head.blocks.0.head_norm1.bias, seg_head.things_mask_head.blocks.0.attn.q.weight, seg_head.things_mask_head.blocks.0.attn.q.bias, seg_head.things_mask_head.blocks.0.attn.k.weight, seg_head.things_mask_head.blocks.0.attn.k.bias, seg_head.things_mask_head.blocks.0.attn.v.weight, seg_head.things_mask_head.blocks.0.attn.v.bias, seg_head.things_mask_head.blocks.0.attn.proj.weight, seg_head.things_mask_head.blocks.0.attn.proj.bias, seg_head.things_mask_head.blocks.0.attn.linear_l1.0.weight, seg_head.things_mask_head.blocks.0.attn.linear_l1.0.bias, seg_head.things_mask_head.blocks.0.attn.linear.0.weight, seg_head.things_mask_head.blocks.0.attn.linear.0.bias, seg_head.things_mask_head.blocks.0.head_norm2.weight, seg_head.things_mask_head.blocks.0.head_norm2.bias, seg_head.things_mask_head.blocks.0.mlp.fc1.weight, seg_head.things_mask_head.blocks.0.mlp.fc1.bias, seg_head.things_mask_head.blocks.0.mlp.fc2.weight, seg_head.things_mask_head.blocks.0.mlp.fc2.bias, seg_head.things_mask_head.blocks.1.head_norm1.weight, seg_head.things_mask_head.blocks.1.head_norm1.bias, seg_head.things_mask_head.blocks.1.attn.q.weight, seg_head.things_mask_head.blocks.1.attn.q.bias, seg_head.things_mask_head.blocks.1.attn.k.weight, seg_head.things_mask_head.blocks.1.attn.k.bias, seg_head.things_mask_head.blocks.1.attn.v.weight, seg_head.things_mask_head.blocks.1.attn.v.bias, seg_head.things_mask_head.blocks.1.attn.proj.weight, seg_head.things_mask_head.blocks.1.attn.proj.bias, seg_head.things_mask_head.blocks.1.attn.linear_l1.0.weight, seg_head.things_mask_head.blocks.1.attn.linear_l1.0.bias, seg_head.things_mask_head.blocks.1.attn.linear.0.weight, seg_head.things_mask_head.blocks.1.attn.linear.0.bias, seg_head.things_mask_head.blocks.1.head_norm2.weight, seg_head.things_mask_head.blocks.1.head_norm2.bias, seg_head.things_mask_head.blocks.1.mlp.fc1.weight, seg_head.things_mask_head.blocks.1.mlp.fc1.bias, seg_head.things_mask_head.blocks.1.mlp.fc2.weight, seg_head.things_mask_head.blocks.1.mlp.fc2.bias, seg_head.things_mask_head.blocks.2.head_norm1.weight, seg_head.things_mask_head.blocks.2.head_norm1.bias, seg_head.things_mask_head.blocks.2.attn.q.weight, seg_head.things_mask_head.blocks.2.attn.q.bias, seg_head.things_mask_head.blocks.2.attn.k.weight, seg_head.things_mask_head.blocks.2.attn.k.bias, seg_head.things_mask_head.blocks.2.attn.v.weight, seg_head.things_mask_head.blocks.2.attn.v.bias, seg_head.things_mask_head.blocks.2.attn.proj.weight, seg_head.things_mask_head.blocks.2.attn.proj.bias, seg_head.things_mask_head.blocks.2.attn.linear_l1.0.weight, seg_head.things_mask_head.blocks.2.attn.linear_l1.0.bias, seg_head.things_mask_head.blocks.2.attn.linear.0.weight, seg_head.things_mask_head.blocks.2.attn.linear.0.bias, seg_head.things_mask_head.blocks.2.head_norm2.weight, seg_head.things_mask_head.blocks.2.head_norm2.bias, seg_head.things_mask_head.blocks.2.mlp.fc1.weight, seg_head.things_mask_head.blocks.2.mlp.fc1.bias, seg_head.things_mask_head.blocks.2.mlp.fc2.weight, seg_head.things_mask_head.blocks.2.mlp.fc2.bias, seg_head.things_mask_head.blocks.3.head_norm1.weight, seg_head.things_mask_head.blocks.3.head_norm1.bias, seg_head.things_mask_head.blocks.3.attn.q.weight, seg_head.things_mask_head.blocks.3.attn.q.bias, seg_head.things_mask_head.blocks.3.attn.k.weight, seg_head.things_mask_head.blocks.3.attn.k.bias, seg_head.things_mask_head.blocks.3.attn.v.weight, seg_head.things_mask_head.blocks.3.attn.v.bias, seg_head.things_mask_head.blocks.3.attn.proj.weight, seg_head.things_mask_head.blocks.3.attn.proj.bias, seg_head.things_mask_head.blocks.3.attn.linear_l1.0.weight, seg_head.things_mask_head.blocks.3.attn.linear_l1.0.bias, seg_head.things_mask_head.blocks.3.attn.linear.0.weight, seg_head.things_mask_head.blocks.3.attn.linear.0.bias, seg_head.things_mask_head.blocks.3.head_norm2.weight, seg_head.things_mask_head.blocks.3.head_norm2.bias, seg_head.things_mask_head.blocks.3.mlp.fc1.weight, seg_head.things_mask_head.blocks.3.mlp.fc1.bias, seg_head.things_mask_head.blocks.3.mlp.fc2.weight, seg_head.things_mask_head.blocks.3.mlp.fc2.bias, seg_head.things_mask_head.attnen.q.weight, seg_head.things_mask_head.attnen.q.bias, seg_head.things_mask_head.attnen.k.weight, seg_head.things_mask_head.attnen.k.bias, seg_head.things_mask_head.attnen.linear_l1.0.weight, seg_head.things_mask_head.attnen.linear_l1.0.bias, seg_head.things_mask_head.attnen.linear.0.weight, seg_head.things_mask_head.attnen.linear.0.bias, seg_head.stuff_mask_head.blocks.0.head_norm1.weight, seg_head.stuff_mask_head.blocks.0.head_norm1.bias, seg_head.stuff_mask_head.blocks.0.attn.q.weight, seg_head.stuff_mask_head.blocks.0.attn.q.bias, seg_head.stuff_mask_head.blocks.0.attn.k.weight, seg_head.stuff_mask_head.blocks.0.attn.k.bias, seg_head.stuff_mask_head.blocks.0.attn.v.weight, seg_head.stuff_mask_head.blocks.0.attn.v.bias, seg_head.stuff_mask_head.blocks.0.attn.proj.weight, seg_head.stuff_mask_head.blocks.0.attn.proj.bias, seg_head.stuff_mask_head.blocks.0.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.0.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.0.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.0.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.0.head_norm2.weight, seg_head.stuff_mask_head.blocks.0.head_norm2.bias, seg_head.stuff_mask_head.blocks.0.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.0.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.0.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.0.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.0.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.0.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.0.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.0.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.0.norm3.weight, seg_head.stuff_mask_head.blocks.0.norm3.bias, seg_head.stuff_mask_head.blocks.1.head_norm1.weight, seg_head.stuff_mask_head.blocks.1.head_norm1.bias, seg_head.stuff_mask_head.blocks.1.attn.q.weight, seg_head.stuff_mask_head.blocks.1.attn.q.bias, seg_head.stuff_mask_head.blocks.1.attn.k.weight, seg_head.stuff_mask_head.blocks.1.attn.k.bias, seg_head.stuff_mask_head.blocks.1.attn.v.weight, seg_head.stuff_mask_head.blocks.1.attn.v.bias, seg_head.stuff_mask_head.blocks.1.attn.proj.weight, seg_head.stuff_mask_head.blocks.1.attn.proj.bias, seg_head.stuff_mask_head.blocks.1.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.1.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.1.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.1.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.1.head_norm2.weight, seg_head.stuff_mask_head.blocks.1.head_norm2.bias, seg_head.stuff_mask_head.blocks.1.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.1.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.1.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.1.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.1.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.1.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.1.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.1.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.1.norm3.weight, seg_head.stuff_mask_head.blocks.1.norm3.bias, seg_head.stuff_mask_head.blocks.2.head_norm1.weight, seg_head.stuff_mask_head.blocks.2.head_norm1.bias, seg_head.stuff_mask_head.blocks.2.attn.q.weight, seg_head.stuff_mask_head.blocks.2.attn.q.bias, seg_head.stuff_mask_head.blocks.2.attn.k.weight, seg_head.stuff_mask_head.blocks.2.attn.k.bias, seg_head.stuff_mask_head.blocks.2.attn.v.weight, seg_head.stuff_mask_head.blocks.2.attn.v.bias, seg_head.stuff_mask_head.blocks.2.attn.proj.weight, seg_head.stuff_mask_head.blocks.2.attn.proj.bias, seg_head.stuff_mask_head.blocks.2.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.2.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.2.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.2.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.2.head_norm2.weight, seg_head.stuff_mask_head.blocks.2.head_norm2.bias, seg_head.stuff_mask_head.blocks.2.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.2.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.2.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.2.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.2.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.2.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.2.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.2.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.2.norm3.weight, seg_head.stuff_mask_head.blocks.2.norm3.bias, seg_head.stuff_mask_head.blocks.3.head_norm1.weight, seg_head.stuff_mask_head.blocks.3.head_norm1.bias, seg_head.stuff_mask_head.blocks.3.attn.q.weight, seg_head.stuff_mask_head.blocks.3.attn.q.bias, seg_head.stuff_mask_head.blocks.3.attn.k.weight, seg_head.stuff_mask_head.blocks.3.attn.k.bias, seg_head.stuff_mask_head.blocks.3.attn.v.weight, seg_head.stuff_mask_head.blocks.3.attn.v.bias, seg_head.stuff_mask_head.blocks.3.attn.proj.weight, seg_head.stuff_mask_head.blocks.3.attn.proj.bias, seg_head.stuff_mask_head.blocks.3.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.3.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.3.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.3.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.3.head_norm2.weight, seg_head.stuff_mask_head.blocks.3.head_norm2.bias, seg_head.stuff_mask_head.blocks.3.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.3.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.3.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.3.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.3.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.3.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.3.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.3.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.3.norm3.weight, seg_head.stuff_mask_head.blocks.3.norm3.bias, seg_head.stuff_mask_head.blocks.4.head_norm1.weight, seg_head.stuff_mask_head.blocks.4.head_norm1.bias, seg_head.stuff_mask_head.blocks.4.attn.q.weight, seg_head.stuff_mask_head.blocks.4.attn.q.bias, seg_head.stuff_mask_head.blocks.4.attn.k.weight, seg_head.stuff_mask_head.blocks.4.attn.k.bias, seg_head.stuff_mask_head.blocks.4.attn.v.weight, seg_head.stuff_mask_head.blocks.4.attn.v.bias, seg_head.stuff_mask_head.blocks.4.attn.proj.weight, seg_head.stuff_mask_head.blocks.4.attn.proj.bias, seg_head.stuff_mask_head.blocks.4.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.4.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.4.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.4.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.4.head_norm2.weight, seg_head.stuff_mask_head.blocks.4.head_norm2.bias, seg_head.stuff_mask_head.blocks.4.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.4.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.4.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.4.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.4.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.4.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.4.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.4.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.4.norm3.weight, seg_head.stuff_mask_head.blocks.4.norm3.bias, seg_head.stuff_mask_head.blocks.5.head_norm1.weight, seg_head.stuff_mask_head.blocks.5.head_norm1.bias, seg_head.stuff_mask_head.blocks.5.attn.q.weight, seg_head.stuff_mask_head.blocks.5.attn.q.bias, seg_head.stuff_mask_head.blocks.5.attn.k.weight, seg_head.stuff_mask_head.blocks.5.attn.k.bias, seg_head.stuff_mask_head.blocks.5.attn.v.weight, seg_head.stuff_mask_head.blocks.5.attn.v.bias, seg_head.stuff_mask_head.blocks.5.attn.proj.weight, seg_head.stuff_mask_head.blocks.5.attn.proj.bias, seg_head.stuff_mask_head.blocks.5.attn.linear_l1.0.weight, seg_head.stuff_mask_head.blocks.5.attn.linear_l1.0.bias, seg_head.stuff_mask_head.blocks.5.attn.linear.0.weight, seg_head.stuff_mask_head.blocks.5.attn.linear.0.bias, seg_head.stuff_mask_head.blocks.5.head_norm2.weight, seg_head.stuff_mask_head.blocks.5.head_norm2.bias, seg_head.stuff_mask_head.blocks.5.mlp.fc1.weight, seg_head.stuff_mask_head.blocks.5.mlp.fc1.bias, seg_head.stuff_mask_head.blocks.5.mlp.fc2.weight, seg_head.stuff_mask_head.blocks.5.mlp.fc2.bias, seg_head.stuff_mask_head.blocks.5.self_attention.qkv.weight, seg_head.stuff_mask_head.blocks.5.self_attention.qkv.bias, seg_head.stuff_mask_head.blocks.5.self_attention.proj.weight, seg_head.stuff_mask_head.blocks.5.self_attention.proj.bias, seg_head.stuff_mask_head.blocks.5.norm3.weight, seg_head.stuff_mask_head.blocks.5.norm3.bias, seg_head.stuff_mask_head.attnen.q.weight, seg_head.stuff_mask_head.attnen.q.bias, seg_head.stuff_mask_head.attnen.k.weight, seg_head.stuff_mask_head.attnen.k.bias, seg_head.stuff_mask_head.attnen.linear_l1.0.weight, seg_head.stuff_mask_head.attnen.linear_l1.0.bias, seg_head.stuff_mask_head.attnen.linear.0.weight, seg_head.stuff_mask_head.attnen.linear.0.bias

2025-05-12 07:49:51,134 - mmdet - INFO - Start running, host: liuji@hjbog-srdc-20.amd.com, work_dir: /mnt/raid0/liuji/UniAD/projects/work_dirs/stage1_track_map/base_track_map_profile
2025-05-12 07:49:51,134 - mmdet - INFO - Start running, host: liuji@hjbog-srdc-20.amd.com, work_dir: /mnt/raid0/liuji/UniAD/projects/work_dirs/stage1_track_map/base_track_map_profile
2025-05-12 07:49:51,134 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(NORMAL      ) CustomDistEvalHook                 
(NORMAL      ) MyProfilerHook                     
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) CustomDistEvalHook                 
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CustomDistEvalHook                 
(NORMAL      ) MyProfilerHook                     
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) CustomDistEvalHook                 
(NORMAL      ) MyProfilerHook                     
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) CustomDistEvalHook                 
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(NORMAL      ) MyProfilerHook                     
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2025-05-12 07:49:51,134 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CheckpointHook                     
(NORMAL      ) CustomDistEvalHook                 
(NORMAL      ) MyProfilerHook                     
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) CustomDistEvalHook                 
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) CustomDistEvalHook                 
(NORMAL      ) MyProfilerHook                     
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(NORMAL      ) CustomDistEvalHook                 
(NORMAL      ) MyProfilerHook                     
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(NORMAL      ) CustomDistEvalHook                 
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(NORMAL      ) MyProfilerHook                     
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2025-05-12 07:49:51,135 - mmdet - INFO - workflow: [('train', 1)], max: 6 epochs
2025-05-12 07:49:51,135 - mmdet - INFO - workflow: [('train', 1)], max: 6 epochs
2025-05-12 07:49:51,135 - mmdet - INFO - Checkpoints will be saved to /mnt/raid0/liuji/UniAD/projects/work_dirs/stage1_track_map/base_track_map_profile by HardDiskBackend.
2025-05-12 07:49:51,135 - mmdet - INFO - Checkpoints will be saved to /mnt/raid0/liuji/UniAD/projects/work_dirs/stage1_track_map/base_track_map_profile by HardDiskBackend.
2025-05-12 07:49:51,136 - mmdet - INFO - Init MyProfilerHook: self.log_dir='./profiler_logs', self.profile_step_start=20, self.profile_step_end=22, self.wait=19, self.warmup=1, self.active=2, self.repeat=1
2025-05-12 07:49:51,136 - mmdet - INFO - Init MyProfilerHook: self.log_dir='./profiler_logs', self.profile_step_start=20, self.profile_step_end=22, self.wait=19, self.warmup=1, self.active=2, self.repeat=1
2025-05-12 07:49:55,437 - shapely.geos - INFO - Self-intersection at or near point 134.36374450633136 1091.2903070826083
2025-05-12 07:49:55,458 - shapely.geos - INFO - Self-intersection at or near point 165.02390945024581 1095.7013529720464
2025-05-12 07:49:55,471 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:55,473 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:55,473 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:55,474 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:55,483 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:55,484 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:55,485 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:55,485 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:55,507 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:55,507 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:55,507 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:55,508 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:55,508 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:55,522 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:55,522 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:55,522 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:55,522 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:55,525 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:55,551 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:55,567 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:56,444 - shapely.geos - INFO - Self-intersection at or near point 134.36374450633136 1091.2903070826083
2025-05-12 07:49:56,465 - shapely.geos - INFO - Self-intersection at or near point 165.02390945024581 1095.7013529720464
2025-05-12 07:49:56,628 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:56,639 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:56,642 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:56,653 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:56,663 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:56,664 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:56,675 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:56,676 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:56,677 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:56,681 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:56,687 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:56,693 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:56,700 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:56,712 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:56,716 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:56,729 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:56,779 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:56,791 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:56,816 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:56,849 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:57,172 - shapely.geos - INFO - Self-intersection at or near point 134.36374450633136 1091.2903070826083
2025-05-12 07:49:57,192 - shapely.geos - INFO - Self-intersection at or near point 165.02390945024581 1095.7013529720464
2025-05-12 07:49:57,492 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:57,504 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:57,529 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:57,531 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:57,540 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:57,541 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:57,547 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:57,552 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:57,565 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:57,576 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:57,581 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:57,592 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:57,622 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:57,638 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:57,676 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:57,701 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:57,794 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:57,807 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:57,833 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:57,851 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:57,881 - shapely.geos - INFO - Self-intersection at or near point 134.36374450633136 1091.2903070826083
2025-05-12 07:49:57,902 - shapely.geos - INFO - Self-intersection at or near point 165.02390945024581 1095.7013529720464
2025-05-12 07:49:58,355 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:58,367 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:58,394 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:58,402 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:58,412 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:58,414 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:58,421 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:58,433 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:58,439 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:58,456 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:58,457 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:58,473 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:58,484 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:58,496 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:58,522 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:58,539 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:58,604 - shapely.geos - INFO - Self-intersection at or near point 134.36374450633136 1091.2903070826083
2025-05-12 07:49:58,625 - shapely.geos - INFO - Self-intersection at or near point 165.02390945024581 1095.7013529720464
2025-05-12 07:49:58,783 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:58,796 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:58,824 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:58,842 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:59,236 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:59,248 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:59,257 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:59,270 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:59,278 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:59,294 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:59,295 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:59,311 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:59,348 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:59,352 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:59,360 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:59,363 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:59,385 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:59,388 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:59,402 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:59,403 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:59,835 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:49:59,848 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:49:59,874 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:49:59,891 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:49:59,953 - shapely.geos - INFO - Self-intersection at or near point 134.36374450633136 1091.2903070826083
2025-05-12 07:49:59,976 - shapely.geos - INFO - Self-intersection at or near point 165.02390945024581 1095.7013529720464
2025-05-12 07:50:00,285 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:00,299 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:00,327 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:00,344 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:00,435 - mmdet - INFO - [MyProfilerHook] runner.iter=0, Synchronize before training iter...
2025-05-12 07:50:00,435 - mmdet - INFO - [MyProfilerHook] runner.iter=0, Synchronize before training iter...
2025-05-12 07:50:00,723 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:00,735 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:00,745 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:00,758 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:00,763 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:00,780 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:00,784 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:00,802 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:00,866 - shapely.geos - INFO - Self-intersection at or near point 134.36374450633136 1091.2903070826083
2025-05-12 07:50:00,889 - shapely.geos - INFO - Self-intersection at or near point 165.02390945024581 1095.7013529720464
2025-05-12 07:50:01,164 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:01,177 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:01,206 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:01,224 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:01,464 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:01,476 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:01,502 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:01,502 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:01,515 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:01,521 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:01,542 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:01,562 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:01,805 - shapely.geos - INFO - Self-intersection at or near point 134.36374450633136 1091.2903070826083
2025-05-12 07:50:01,828 - shapely.geos - INFO - Self-intersection at or near point 165.02390945024581 1095.7013529720464
2025-05-12 07:50:02,003 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:02,015 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:02,043 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:02,060 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:02,301 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:02,313 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:02,339 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:02,356 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:02,390 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:02,405 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:02,434 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:02,453 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:02,680 - shapely.geos - INFO - Self-intersection at or near point 134.36374450633136 1091.2903070826083
2025-05-12 07:50:02,704 - shapely.geos - INFO - Self-intersection at or near point 165.02390945024581 1095.7013529720464
2025-05-12 07:50:02,839 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:02,852 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:02,878 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:02,898 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:03,079 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:03,091 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:03,119 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:03,137 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:03,304 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:03,319 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:03,357 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:03,382 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:03,682 - shapely.geos - INFO - Self-intersection at or near point 134.36374450633136 1091.2903070826083
2025-05-12 07:50:03,704 - shapely.geos - INFO - Self-intersection at or near point 165.02390945024581 1095.7013529720464
2025-05-12 07:50:03,747 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:03,758 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:03,798 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:03,815 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:03,965 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:03,978 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:04,005 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:04,022 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:04,253 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:04,265 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:04,271 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:04,284 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:04,292 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:04,310 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:04,310 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:04,328 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:05,222 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:05,234 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:05,260 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:05,275 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:05,277 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:05,290 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:05,317 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:05,333 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:06,072 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:06,084 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:06,108 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:06,123 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:06,155 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:06,167 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:06,191 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:06,207 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:06,957 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:06,970 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:06,999 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:07,019 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:07,118 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:07,132 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:07,160 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:07,180 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:07,992 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:08,005 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:08,032 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:08,049 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:08,201 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:08,214 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:08,242 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:08,261 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:09,011 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:09,024 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:09,055 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:09,072 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:12,433 - mmdet - INFO - [MyProfilerHook] runner.iter=1, Synchronize before training iter...
2025-05-12 07:50:12,433 - mmdet - INFO - [MyProfilerHook] runner.iter=1, Synchronize before training iter...
2025-05-12 07:50:23,452 - mmdet - INFO - [MyProfilerHook] runner.iter=2, Synchronize before training iter...
2025-05-12 07:50:23,452 - mmdet - INFO - [MyProfilerHook] runner.iter=2, Synchronize before training iter...
2025-05-12 07:50:23,463 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:23,479 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:23,512 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:23,534 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:24,492 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:24,508 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:24,541 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:24,562 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:25,602 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:25,618 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:25,651 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:25,673 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:26,697 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:26,713 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:26,756 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:26,777 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:27,814 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:27,830 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:27,866 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:27,888 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:34,510 - mmdet - INFO - [MyProfilerHook] runner.iter=3, Synchronize before training iter...
2025-05-12 07:50:34,510 - mmdet - INFO - [MyProfilerHook] runner.iter=3, Synchronize before training iter...
2025-05-12 07:50:34,539 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:34,556 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:34,590 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:34,610 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:35,369 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:35,385 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:35,422 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:35,444 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:36,348 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:36,365 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:36,400 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:36,422 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:37,428 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:37,448 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:37,484 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:37,507 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:38,491 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:38,508 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:38,541 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:38,563 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:45,050 - mmdet - INFO - [MyProfilerHook] runner.iter=4, Synchronize before training iter...
2025-05-12 07:50:45,050 - mmdet - INFO - [MyProfilerHook] runner.iter=4, Synchronize before training iter...
2025-05-12 07:50:45,074 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:45,088 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:45,116 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:45,134 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:45,970 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:45,983 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:46,012 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:46,030 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:47,062 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:47,076 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:47,111 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:47,134 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:48,227 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:48,248 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:48,285 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:48,308 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:49,394 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:49,411 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:49,448 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:49,471 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:50:55,443 - mmdet - INFO - [MyProfilerHook] runner.iter=5, Synchronize before training iter...
2025-05-12 07:50:55,443 - mmdet - INFO - [MyProfilerHook] runner.iter=5, Synchronize before training iter...
2025-05-12 07:50:55,463 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:50:55,480 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:50:55,514 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:50:55,535 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:06,342 - mmdet - INFO - [MyProfilerHook] runner.iter=6, Synchronize before training iter...
2025-05-12 07:51:06,342 - mmdet - INFO - [MyProfilerHook] runner.iter=6, Synchronize before training iter...
2025-05-12 07:51:06,358 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:06,375 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:06,407 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:06,433 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:07,360 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:07,376 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:07,408 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:07,430 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:08,389 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:08,404 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:08,435 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:08,455 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:09,436 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:09,452 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:09,485 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:09,506 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:10,443 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:10,460 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:10,492 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:10,512 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:17,171 - mmdet - INFO - [MyProfilerHook] runner.iter=7, Synchronize before training iter...
2025-05-12 07:51:17,171 - mmdet - INFO - [MyProfilerHook] runner.iter=7, Synchronize before training iter...
2025-05-12 07:51:17,171 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:17,188 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:17,239 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:17,258 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:18,010 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:18,025 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:18,054 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:18,072 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:18,817 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:18,831 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:18,861 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:18,879 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:19,565 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:19,577 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:19,601 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:19,616 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:19,970 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:19,984 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:20,012 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:20,029 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:20,345 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:20,358 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:20,384 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:20,400 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:21,209 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:21,222 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:21,248 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:21,266 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:22,419 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:22,431 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:22,455 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:22,471 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:23,726 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:23,744 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:23,791 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:23,811 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:27,789 - mmdet - INFO - [MyProfilerHook] runner.iter=8, Synchronize before training iter...
2025-05-12 07:51:27,789 - mmdet - INFO - [MyProfilerHook] runner.iter=8, Synchronize before training iter...
2025-05-12 07:51:38,131 - mmdet - INFO - [MyProfilerHook] runner.iter=9, Synchronize before training iter...
2025-05-12 07:51:38,131 - mmdet - INFO - [MyProfilerHook] runner.iter=9, Synchronize before training iter...
2025-05-12 07:51:48,424 - mmdet - INFO - Epoch [1][10/28130]	lr: 6.907e-05, eta: 22 days, 21:47:52, time: 11.728, data_time: 1.060, memory: 47021, track.frame_0_loss_cls_0: 1.2785, track.frame_0_loss_bbox_0: 2.3639, track.frame_0_loss_past_trajs_0: 0.0000, track.frame_0_loss_cls_1: 1.2684, track.frame_0_loss_bbox_1: 2.2886, track.frame_0_loss_past_trajs_1: 0.0000, track.frame_0_loss_cls_2: 1.2888, track.frame_0_loss_bbox_2: 2.2769, track.frame_0_loss_past_trajs_2: 0.0000, track.frame_0_loss_cls_3: 1.2418, track.frame_0_loss_bbox_3: 2.2507, track.frame_0_loss_past_trajs_3: 0.0000, track.frame_0_loss_cls_4: 1.2215, track.frame_0_loss_bbox_4: 2.2111, track.frame_0_loss_past_trajs_4: 0.0000, track.frame_0_loss_cls_5: 1.2445, track.frame_0_loss_bbox_5: 2.2302, track.frame_0_loss_past_trajs_5: 0.0000, track.frame_1_loss_cls_0: 1.6274, track.frame_1_loss_bbox_0: 2.1239, track.frame_1_loss_past_trajs_0: 0.0000, track.frame_1_loss_cls_1: 1.6875, track.frame_1_loss_bbox_1: 2.0290, track.frame_1_loss_past_trajs_1: 0.0000, track.frame_1_loss_cls_2: 1.6971, track.frame_1_loss_bbox_2: 2.0039, track.frame_1_loss_past_trajs_2: 0.0000, track.frame_1_loss_cls_3: 1.7112, track.frame_1_loss_bbox_3: 1.9664, track.frame_1_loss_past_trajs_3: 0.0000, track.frame_1_loss_cls_4: 1.6878, track.frame_1_loss_bbox_4: 1.9592, track.frame_1_loss_past_trajs_4: 0.0000, track.frame_1_loss_cls_5: 1.7369, track.frame_1_loss_bbox_5: 1.9812, track.frame_1_loss_past_trajs_5: 0.0000, track.frame_2_loss_cls_0: 1.6557, track.frame_2_loss_bbox_0: 2.0060, track.frame_2_loss_past_trajs_0: 0.0000, track.frame_2_loss_cls_1: 1.5981, track.frame_2_loss_bbox_1: 1.9149, track.frame_2_loss_past_trajs_1: 0.0000, track.frame_2_loss_cls_2: 1.6914, track.frame_2_loss_bbox_2: 1.8801, track.frame_2_loss_past_trajs_2: 0.0000, track.frame_2_loss_cls_3: 1.6643, track.frame_2_loss_bbox_3: 1.8554, track.frame_2_loss_past_trajs_3: 0.0000, track.frame_2_loss_cls_4: 1.6370, track.frame_2_loss_bbox_4: 1.8316, track.frame_2_loss_past_trajs_4: 0.0000, track.frame_2_loss_cls_5: 1.6211, track.frame_2_loss_bbox_5: 1.8360, track.frame_2_loss_past_trajs_5: 0.0000, track.frame_3_loss_cls_0: 1.8653, track.frame_3_loss_bbox_0: 2.0948, track.frame_3_loss_past_trajs_0: 0.0000, track.frame_3_loss_cls_1: 1.6782, track.frame_3_loss_bbox_1: 1.9816, track.frame_3_loss_past_trajs_1: 0.0000, track.frame_3_loss_cls_2: 1.7458, track.frame_3_loss_bbox_2: 1.9703, track.frame_3_loss_past_trajs_2: 0.0000, track.frame_3_loss_cls_3: 1.7782, track.frame_3_loss_bbox_3: 2.0760, track.frame_3_loss_past_trajs_3: 0.0000, track.frame_3_loss_cls_4: 1.8053, track.frame_3_loss_bbox_4: 2.0778, track.frame_3_loss_past_trajs_4: 0.0000, track.frame_3_loss_cls_5: 1.7506, track.frame_3_loss_bbox_5: 2.1252, track.frame_3_loss_past_trajs_5: 0.0000, track.frame_4_loss_cls_0: 1.8821, track.frame_4_loss_bbox_0: 2.1233, track.frame_4_loss_past_trajs_0: 0.0000, track.frame_4_loss_cls_1: 1.7915, track.frame_4_loss_bbox_1: 2.0095, track.frame_4_loss_past_trajs_1: 0.0000, track.frame_4_loss_cls_2: 1.7458, track.frame_4_loss_bbox_2: 2.0264, track.frame_4_loss_past_trajs_2: 0.0000, track.frame_4_loss_cls_3: 1.6537, track.frame_4_loss_bbox_3: 2.0234, track.frame_4_loss_past_trajs_3: 0.0000, track.frame_4_loss_cls_4: 1.5983, track.frame_4_loss_bbox_4: 2.0212, track.frame_4_loss_past_trajs_4: 0.0000, track.frame_4_loss_cls_5: 1.6488, track.frame_4_loss_bbox_5: 2.0365, track.frame_4_loss_past_trajs_5: 0.0000, map.loss_cls: 1.2118, map.loss_bbox: 1.7820, map.loss_iou: 2.0779, map.loss_mask_things: 1.7983, map.loss_mask_stuff: 0.0882, map.d0.loss_mask_things_f: 1.8087, map.d0.loss_iou_f: 0.0000, map.d0.loss_bbox_f: 0.0000, map.d0.loss_cls_f: 0.0000, map.d1.loss_mask_things_f: 1.7934, map.d1.loss_iou_f: 0.0000, map.d1.loss_bbox_f: 0.0000, map.d1.loss_cls_f: 0.0000, map.d2.loss_mask_things_f: 1.7931, map.d2.loss_iou_f: 0.0000, map.d2.loss_bbox_f: 0.0000, map.d2.loss_cls_f: 0.0000, map.d3.loss_mask_things_f: 1.8092, map.d3.loss_iou_f: 0.0000, map.d3.loss_bbox_f: 0.0000, map.d3.loss_cls_f: 0.0000, map.d0.loss_mask_stuff_f: 0.0832, map.d0.loss_cls_stuff_f: 0.1393, map.d1.loss_mask_stuff_f: 0.1116, map.d1.loss_cls_stuff_f: 0.1350, map.d2.loss_mask_stuff_f: 0.0763, map.d2.loss_cls_stuff_f: 0.1333, map.d3.loss_mask_stuff_f: 0.0849, map.d3.loss_cls_stuff_f: 0.1204, map.d4.loss_mask_stuff_f: 0.0838, map.d4.loss_cls_stuff_f: 0.1406, map.d5.loss_mask_stuff_f: 0.0917, map.d5.loss_cls_stuff_f: 0.1559, map.d0.loss_cls: 1.6916, map.d0.loss_bbox: 1.8212, map.d0.loss_iou: 2.1049, map.d1.loss_cls: 1.5628, map.d1.loss_bbox: 1.8079, map.d1.loss_iou: 2.0951, map.d2.loss_cls: 1.2749, map.d2.loss_bbox: 1.7980, map.d2.loss_iou: 2.0863, map.d3.loss_cls: 1.2231, map.d3.loss_bbox: 1.7956, map.d3.loss_iou: 2.0864, map.d4.loss_cls: 1.2453, map.d4.loss_bbox: 1.7838, map.d4.loss_iou: 2.0816, loss: 152.0546, grad_norm: 2834.1053
2025-05-12 07:51:48,424 - mmdet - INFO - Epoch [1][10/28130]	lr: 6.907e-05, eta: 22 days, 21:47:52, time: 11.728, data_time: 1.060, memory: 47021, track.frame_0_loss_cls_0: 1.2785, track.frame_0_loss_bbox_0: 2.3639, track.frame_0_loss_past_trajs_0: 0.0000, track.frame_0_loss_cls_1: 1.2684, track.frame_0_loss_bbox_1: 2.2886, track.frame_0_loss_past_trajs_1: 0.0000, track.frame_0_loss_cls_2: 1.2888, track.frame_0_loss_bbox_2: 2.2769, track.frame_0_loss_past_trajs_2: 0.0000, track.frame_0_loss_cls_3: 1.2418, track.frame_0_loss_bbox_3: 2.2507, track.frame_0_loss_past_trajs_3: 0.0000, track.frame_0_loss_cls_4: 1.2215, track.frame_0_loss_bbox_4: 2.2111, track.frame_0_loss_past_trajs_4: 0.0000, track.frame_0_loss_cls_5: 1.2445, track.frame_0_loss_bbox_5: 2.2302, track.frame_0_loss_past_trajs_5: 0.0000, track.frame_1_loss_cls_0: 1.6274, track.frame_1_loss_bbox_0: 2.1239, track.frame_1_loss_past_trajs_0: 0.0000, track.frame_1_loss_cls_1: 1.6875, track.frame_1_loss_bbox_1: 2.0290, track.frame_1_loss_past_trajs_1: 0.0000, track.frame_1_loss_cls_2: 1.6971, track.frame_1_loss_bbox_2: 2.0039, track.frame_1_loss_past_trajs_2: 0.0000, track.frame_1_loss_cls_3: 1.7112, track.frame_1_loss_bbox_3: 1.9664, track.frame_1_loss_past_trajs_3: 0.0000, track.frame_1_loss_cls_4: 1.6878, track.frame_1_loss_bbox_4: 1.9592, track.frame_1_loss_past_trajs_4: 0.0000, track.frame_1_loss_cls_5: 1.7369, track.frame_1_loss_bbox_5: 1.9812, track.frame_1_loss_past_trajs_5: 0.0000, track.frame_2_loss_cls_0: 1.6557, track.frame_2_loss_bbox_0: 2.0060, track.frame_2_loss_past_trajs_0: 0.0000, track.frame_2_loss_cls_1: 1.5981, track.frame_2_loss_bbox_1: 1.9149, track.frame_2_loss_past_trajs_1: 0.0000, track.frame_2_loss_cls_2: 1.6914, track.frame_2_loss_bbox_2: 1.8801, track.frame_2_loss_past_trajs_2: 0.0000, track.frame_2_loss_cls_3: 1.6643, track.frame_2_loss_bbox_3: 1.8554, track.frame_2_loss_past_trajs_3: 0.0000, track.frame_2_loss_cls_4: 1.6370, track.frame_2_loss_bbox_4: 1.8316, track.frame_2_loss_past_trajs_4: 0.0000, track.frame_2_loss_cls_5: 1.6211, track.frame_2_loss_bbox_5: 1.8360, track.frame_2_loss_past_trajs_5: 0.0000, track.frame_3_loss_cls_0: 1.8653, track.frame_3_loss_bbox_0: 2.0948, track.frame_3_loss_past_trajs_0: 0.0000, track.frame_3_loss_cls_1: 1.6782, track.frame_3_loss_bbox_1: 1.9816, track.frame_3_loss_past_trajs_1: 0.0000, track.frame_3_loss_cls_2: 1.7458, track.frame_3_loss_bbox_2: 1.9703, track.frame_3_loss_past_trajs_2: 0.0000, track.frame_3_loss_cls_3: 1.7782, track.frame_3_loss_bbox_3: 2.0760, track.frame_3_loss_past_trajs_3: 0.0000, track.frame_3_loss_cls_4: 1.8053, track.frame_3_loss_bbox_4: 2.0778, track.frame_3_loss_past_trajs_4: 0.0000, track.frame_3_loss_cls_5: 1.7506, track.frame_3_loss_bbox_5: 2.1252, track.frame_3_loss_past_trajs_5: 0.0000, track.frame_4_loss_cls_0: 1.8821, track.frame_4_loss_bbox_0: 2.1233, track.frame_4_loss_past_trajs_0: 0.0000, track.frame_4_loss_cls_1: 1.7915, track.frame_4_loss_bbox_1: 2.0095, track.frame_4_loss_past_trajs_1: 0.0000, track.frame_4_loss_cls_2: 1.7458, track.frame_4_loss_bbox_2: 2.0264, track.frame_4_loss_past_trajs_2: 0.0000, track.frame_4_loss_cls_3: 1.6537, track.frame_4_loss_bbox_3: 2.0234, track.frame_4_loss_past_trajs_3: 0.0000, track.frame_4_loss_cls_4: 1.5983, track.frame_4_loss_bbox_4: 2.0212, track.frame_4_loss_past_trajs_4: 0.0000, track.frame_4_loss_cls_5: 1.6488, track.frame_4_loss_bbox_5: 2.0365, track.frame_4_loss_past_trajs_5: 0.0000, map.loss_cls: 1.2118, map.loss_bbox: 1.7820, map.loss_iou: 2.0779, map.loss_mask_things: 1.7983, map.loss_mask_stuff: 0.0882, map.d0.loss_mask_things_f: 1.8087, map.d0.loss_iou_f: 0.0000, map.d0.loss_bbox_f: 0.0000, map.d0.loss_cls_f: 0.0000, map.d1.loss_mask_things_f: 1.7934, map.d1.loss_iou_f: 0.0000, map.d1.loss_bbox_f: 0.0000, map.d1.loss_cls_f: 0.0000, map.d2.loss_mask_things_f: 1.7931, map.d2.loss_iou_f: 0.0000, map.d2.loss_bbox_f: 0.0000, map.d2.loss_cls_f: 0.0000, map.d3.loss_mask_things_f: 1.8092, map.d3.loss_iou_f: 0.0000, map.d3.loss_bbox_f: 0.0000, map.d3.loss_cls_f: 0.0000, map.d0.loss_mask_stuff_f: 0.0832, map.d0.loss_cls_stuff_f: 0.1393, map.d1.loss_mask_stuff_f: 0.1116, map.d1.loss_cls_stuff_f: 0.1350, map.d2.loss_mask_stuff_f: 0.0763, map.d2.loss_cls_stuff_f: 0.1333, map.d3.loss_mask_stuff_f: 0.0849, map.d3.loss_cls_stuff_f: 0.1204, map.d4.loss_mask_stuff_f: 0.0838, map.d4.loss_cls_stuff_f: 0.1406, map.d5.loss_mask_stuff_f: 0.0917, map.d5.loss_cls_stuff_f: 0.1559, map.d0.loss_cls: 1.6916, map.d0.loss_bbox: 1.8212, map.d0.loss_iou: 2.1049, map.d1.loss_cls: 1.5628, map.d1.loss_bbox: 1.8079, map.d1.loss_iou: 2.0951, map.d2.loss_cls: 1.2749, map.d2.loss_bbox: 1.7980, map.d2.loss_iou: 2.0863, map.d3.loss_cls: 1.2231, map.d3.loss_bbox: 1.7956, map.d3.loss_iou: 2.0864, map.d4.loss_cls: 1.2453, map.d4.loss_bbox: 1.7838, map.d4.loss_iou: 2.0816, loss: 152.0546, grad_norm: 2834.1053
2025-05-12 07:51:48,526 - mmdet - INFO - [MyProfilerHook] runner.iter=10, Synchronize before training iter...
2025-05-12 07:51:48,526 - mmdet - INFO - [MyProfilerHook] runner.iter=10, Synchronize before training iter...
2025-05-12 07:51:48,544 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:48,556 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:48,581 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:48,597 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:49,414 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:49,426 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:49,450 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:49,467 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:50,287 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:50,298 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:50,322 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:50,339 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:51,154 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:51,166 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:51,190 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:51,205 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:52,114 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:51:52,128 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:51:52,153 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:51:52,169 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:51:58,647 - mmdet - INFO - [MyProfilerHook] runner.iter=11, Synchronize before training iter...
2025-05-12 07:51:58,647 - mmdet - INFO - [MyProfilerHook] runner.iter=11, Synchronize before training iter...
2025-05-12 07:52:08,958 - mmdet - INFO - [MyProfilerHook] runner.iter=12, Synchronize before training iter...
2025-05-12 07:52:08,958 - mmdet - INFO - [MyProfilerHook] runner.iter=12, Synchronize before training iter...
2025-05-12 07:52:08,972 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:08,983 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:09,008 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:09,023 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:09,982 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:09,993 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:10,018 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:10,034 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:11,027 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:11,038 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:11,062 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:11,077 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:12,096 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:12,107 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:12,132 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:12,149 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:13,314 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:13,324 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:13,348 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:13,363 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:19,233 - mmdet - INFO - [MyProfilerHook] runner.iter=13, Synchronize before training iter...
2025-05-12 07:52:19,233 - mmdet - INFO - [MyProfilerHook] runner.iter=13, Synchronize before training iter...
2025-05-12 07:52:19,257 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:19,269 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:19,294 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:19,310 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:20,205 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:20,217 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:20,243 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:20,260 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:21,180 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:21,192 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:21,217 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:21,233 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:22,183 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:22,195 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:22,221 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:22,237 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:23,149 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:23,161 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:23,185 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:23,200 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:29,734 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:29,745 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:29,745 - mmdet - INFO - [MyProfilerHook] runner.iter=14, Synchronize before training iter...
2025-05-12 07:52:29,745 - mmdet - INFO - [MyProfilerHook] runner.iter=14, Synchronize before training iter...
2025-05-12 07:52:29,768 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:29,783 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:30,527 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:30,538 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:30,561 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:30,575 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:31,378 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:31,389 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:31,412 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:31,426 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:32,201 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:32,212 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:32,236 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:32,252 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:33,130 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:33,141 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:33,166 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:33,181 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:40,427 - mmdet - INFO - [MyProfilerHook] runner.iter=15, Synchronize before training iter...
2025-05-12 07:52:40,427 - mmdet - INFO - [MyProfilerHook] runner.iter=15, Synchronize before training iter...
2025-05-12 07:52:40,438 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:40,455 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:40,488 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:40,508 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:41,580 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:41,595 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:41,625 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:41,644 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:42,814 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:42,829 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:42,862 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:42,880 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:44,160 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:44,176 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:44,208 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:44,228 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:52:45,545 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:52:45,562 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:52:45,593 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:52:45,612 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:00,742 - mmdet - INFO - [MyProfilerHook] runner.iter=16, Synchronize before training iter...
2025-05-12 07:53:00,742 - mmdet - INFO - [MyProfilerHook] runner.iter=16, Synchronize before training iter...
2025-05-12 07:53:00,780 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:00,796 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:00,824 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:00,843 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:01,671 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:01,684 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:01,713 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:01,734 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:02,533 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:02,547 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:02,576 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:02,595 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:03,354 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:03,367 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:03,402 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:03,421 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:04,212 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:04,225 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:04,253 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:04,271 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:12,449 - mmdet - INFO - [MyProfilerHook] runner.iter=17, Synchronize before training iter...
2025-05-12 07:53:12,449 - mmdet - INFO - [MyProfilerHook] runner.iter=17, Synchronize before training iter...
2025-05-12 07:53:12,481 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:12,494 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:12,523 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:12,542 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:13,343 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:13,355 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:13,382 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:13,400 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:14,201 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:14,213 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:14,240 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:14,256 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:15,086 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:15,098 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:15,124 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:15,140 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:16,001 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:16,014 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:16,040 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:16,056 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:22,679 - mmdet - INFO - [MyProfilerHook] runner.iter=18, Synchronize before training iter...
2025-05-12 07:53:22,679 - mmdet - INFO - [MyProfilerHook] runner.iter=18, Synchronize before training iter...
2025-05-12 07:53:33,004 - mmdet - INFO - [MyProfilerHook] runner.iter=19, Synchronize before training iter...
2025-05-12 07:53:33,004 - mmdet - INFO - [MyProfilerHook] runner.iter=19, Synchronize before training iter...
2025-05-12 07:53:33,009 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:33,023 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:33,052 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:33,070 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:33,926 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:33,939 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:33,968 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:33,986 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:34,812 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:34,825 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:34,853 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:34,870 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:35,770 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:35,783 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:35,810 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:35,827 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:36,646 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:36,659 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:36,686 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:36,703 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:43,688 - mmdet - INFO - Epoch [1][20/28130]	lr: 7.173e-05, eta: 22 days, 17:02:51, time: 11.526, data_time: 1.046, memory: 47021, track.frame_0_loss_cls_0: 0.7323, track.frame_0_loss_bbox_0: 1.9506, track.frame_0_loss_past_trajs_0: 0.0000, track.frame_0_loss_cls_1: 0.7061, track.frame_0_loss_bbox_1: 1.8831, track.frame_0_loss_past_trajs_1: 0.0000, track.frame_0_loss_cls_2: 0.6751, track.frame_0_loss_bbox_2: 1.8546, track.frame_0_loss_past_trajs_2: 0.0000, track.frame_0_loss_cls_3: 0.6541, track.frame_0_loss_bbox_3: 1.8273, track.frame_0_loss_past_trajs_3: 0.0000, track.frame_0_loss_cls_4: 0.6440, track.frame_0_loss_bbox_4: 1.8132, track.frame_0_loss_past_trajs_4: 0.0000, track.frame_0_loss_cls_5: 0.6626, track.frame_0_loss_bbox_5: 1.7951, track.frame_0_loss_past_trajs_5: 0.0000, track.frame_1_loss_cls_0: 0.9398, track.frame_1_loss_bbox_0: 1.9578, track.frame_1_loss_past_trajs_0: 0.0000, track.frame_1_loss_cls_1: 0.8191, track.frame_1_loss_bbox_1: 1.8689, track.frame_1_loss_past_trajs_1: 0.0000, track.frame_1_loss_cls_2: 0.8019, track.frame_1_loss_bbox_2: 1.8363, track.frame_1_loss_past_trajs_2: 0.0000, track.frame_1_loss_cls_3: 0.8043, track.frame_1_loss_bbox_3: 1.8188, track.frame_1_loss_past_trajs_3: 0.0000, track.frame_1_loss_cls_4: 0.8123, track.frame_1_loss_bbox_4: 1.7951, track.frame_1_loss_past_trajs_4: 0.0000, track.frame_1_loss_cls_5: 0.8085, track.frame_1_loss_bbox_5: 1.7779, track.frame_1_loss_past_trajs_5: 0.0000, track.frame_2_loss_cls_0: 0.9370, track.frame_2_loss_bbox_0: 1.9832, track.frame_2_loss_past_trajs_0: 0.0000, track.frame_2_loss_cls_1: 0.8375, track.frame_2_loss_bbox_1: 1.9229, track.frame_2_loss_past_trajs_1: 0.0000, track.frame_2_loss_cls_2: 0.7757, track.frame_2_loss_bbox_2: 1.8841, track.frame_2_loss_past_trajs_2: 0.0000, track.frame_2_loss_cls_3: 0.7421, track.frame_2_loss_bbox_3: 1.8769, track.frame_2_loss_past_trajs_3: 0.0000, track.frame_2_loss_cls_4: 0.7267, track.frame_2_loss_bbox_4: 1.8646, track.frame_2_loss_past_trajs_4: 0.0000, track.frame_2_loss_cls_5: 0.7407, track.frame_2_loss_bbox_5: 1.8577, track.frame_2_loss_past_trajs_5: 0.0000, track.frame_3_loss_cls_0: 0.9376, track.frame_3_loss_bbox_0: 2.0892, track.frame_3_loss_past_trajs_0: 0.0000, track.frame_3_loss_cls_1: 0.8085, track.frame_3_loss_bbox_1: 1.9982, track.frame_3_loss_past_trajs_1: 0.0000, track.frame_3_loss_cls_2: 0.7564, track.frame_3_loss_bbox_2: 1.9413, track.frame_3_loss_past_trajs_2: 0.0000, track.frame_3_loss_cls_3: 0.7536, track.frame_3_loss_bbox_3: 1.9175, track.frame_3_loss_past_trajs_3: 0.0000, track.frame_3_loss_cls_4: 0.7423, track.frame_3_loss_bbox_4: 1.9009, track.frame_3_loss_past_trajs_4: 0.0000, track.frame_3_loss_cls_5: 0.7402, track.frame_3_loss_bbox_5: 1.8973, track.frame_3_loss_past_trajs_5: 0.0000, track.frame_4_loss_cls_0: 0.7436, track.frame_4_loss_bbox_0: 1.9972, track.frame_4_loss_past_trajs_0: 0.0000, track.frame_4_loss_cls_1: 0.6939, track.frame_4_loss_bbox_1: 1.9474, track.frame_4_loss_past_trajs_1: 0.0000, track.frame_4_loss_cls_2: 0.6973, track.frame_4_loss_bbox_2: 1.9020, track.frame_4_loss_past_trajs_2: 0.0000, track.frame_4_loss_cls_3: 0.6972, track.frame_4_loss_bbox_3: 1.8703, track.frame_4_loss_past_trajs_3: 0.0000, track.frame_4_loss_cls_4: 0.7109, track.frame_4_loss_bbox_4: 1.8644, track.frame_4_loss_past_trajs_4: 0.0000, track.frame_4_loss_cls_5: 0.7213, track.frame_4_loss_bbox_5: 1.8386, track.frame_4_loss_past_trajs_5: 0.0000, map.loss_cls: 0.9788, map.loss_bbox: 2.1525, map.loss_iou: 2.0318, map.loss_mask_things: 1.7252, map.loss_mask_stuff: 0.0828, map.d0.loss_mask_things_f: 1.7451, map.d0.loss_iou_f: 0.0000, map.d0.loss_bbox_f: 0.0000, map.d0.loss_cls_f: 0.0000, map.d1.loss_mask_things_f: 1.7305, map.d1.loss_iou_f: 0.0000, map.d1.loss_bbox_f: 0.0000, map.d1.loss_cls_f: 0.0000, map.d2.loss_mask_things_f: 1.7073, map.d2.loss_iou_f: 0.0000, map.d2.loss_bbox_f: 0.0000, map.d2.loss_cls_f: 0.0000, map.d3.loss_mask_things_f: 1.7030, map.d3.loss_iou_f: 0.0000, map.d3.loss_bbox_f: 0.0000, map.d3.loss_cls_f: 0.0000, map.d0.loss_mask_stuff_f: 0.0817, map.d0.loss_cls_stuff_f: 0.0049, map.d1.loss_mask_stuff_f: 0.0872, map.d1.loss_cls_stuff_f: 0.0021, map.d2.loss_mask_stuff_f: 0.0775, map.d2.loss_cls_stuff_f: 0.0013, map.d3.loss_mask_stuff_f: 0.0819, map.d3.loss_cls_stuff_f: 0.0009, map.d4.loss_mask_stuff_f: 0.0812, map.d4.loss_cls_stuff_f: 0.0012, map.d5.loss_mask_stuff_f: 0.0838, map.d5.loss_cls_stuff_f: 0.0013, map.d0.loss_cls: 1.4209, map.d0.loss_bbox: 2.2291, map.d0.loss_iou: 2.0957, map.d1.loss_cls: 1.0027, map.d1.loss_bbox: 2.2044, map.d1.loss_iou: 2.0919, map.d2.loss_cls: 0.9190, map.d2.loss_bbox: 2.1815, map.d2.loss_iou: 2.0732, map.d3.loss_cls: 0.9204, map.d3.loss_bbox: 2.1711, map.d3.loss_iou: 2.0587, map.d4.loss_cls: 0.9830, map.d4.loss_bbox: 2.1667, map.d4.loss_iou: 2.0458, loss: 120.4812, grad_norm: 451.0885
2025-05-12 07:53:43,688 - mmdet - INFO - Epoch [1][20/28130]	lr: 7.173e-05, eta: 22 days, 17:02:51, time: 11.526, data_time: 1.046, memory: 47021, track.frame_0_loss_cls_0: 0.7323, track.frame_0_loss_bbox_0: 1.9506, track.frame_0_loss_past_trajs_0: 0.0000, track.frame_0_loss_cls_1: 0.7061, track.frame_0_loss_bbox_1: 1.8831, track.frame_0_loss_past_trajs_1: 0.0000, track.frame_0_loss_cls_2: 0.6751, track.frame_0_loss_bbox_2: 1.8546, track.frame_0_loss_past_trajs_2: 0.0000, track.frame_0_loss_cls_3: 0.6541, track.frame_0_loss_bbox_3: 1.8273, track.frame_0_loss_past_trajs_3: 0.0000, track.frame_0_loss_cls_4: 0.6440, track.frame_0_loss_bbox_4: 1.8132, track.frame_0_loss_past_trajs_4: 0.0000, track.frame_0_loss_cls_5: 0.6626, track.frame_0_loss_bbox_5: 1.7951, track.frame_0_loss_past_trajs_5: 0.0000, track.frame_1_loss_cls_0: 0.9398, track.frame_1_loss_bbox_0: 1.9578, track.frame_1_loss_past_trajs_0: 0.0000, track.frame_1_loss_cls_1: 0.8191, track.frame_1_loss_bbox_1: 1.8689, track.frame_1_loss_past_trajs_1: 0.0000, track.frame_1_loss_cls_2: 0.8019, track.frame_1_loss_bbox_2: 1.8363, track.frame_1_loss_past_trajs_2: 0.0000, track.frame_1_loss_cls_3: 0.8043, track.frame_1_loss_bbox_3: 1.8188, track.frame_1_loss_past_trajs_3: 0.0000, track.frame_1_loss_cls_4: 0.8123, track.frame_1_loss_bbox_4: 1.7951, track.frame_1_loss_past_trajs_4: 0.0000, track.frame_1_loss_cls_5: 0.8085, track.frame_1_loss_bbox_5: 1.7779, track.frame_1_loss_past_trajs_5: 0.0000, track.frame_2_loss_cls_0: 0.9370, track.frame_2_loss_bbox_0: 1.9832, track.frame_2_loss_past_trajs_0: 0.0000, track.frame_2_loss_cls_1: 0.8375, track.frame_2_loss_bbox_1: 1.9229, track.frame_2_loss_past_trajs_1: 0.0000, track.frame_2_loss_cls_2: 0.7757, track.frame_2_loss_bbox_2: 1.8841, track.frame_2_loss_past_trajs_2: 0.0000, track.frame_2_loss_cls_3: 0.7421, track.frame_2_loss_bbox_3: 1.8769, track.frame_2_loss_past_trajs_3: 0.0000, track.frame_2_loss_cls_4: 0.7267, track.frame_2_loss_bbox_4: 1.8646, track.frame_2_loss_past_trajs_4: 0.0000, track.frame_2_loss_cls_5: 0.7407, track.frame_2_loss_bbox_5: 1.8577, track.frame_2_loss_past_trajs_5: 0.0000, track.frame_3_loss_cls_0: 0.9376, track.frame_3_loss_bbox_0: 2.0892, track.frame_3_loss_past_trajs_0: 0.0000, track.frame_3_loss_cls_1: 0.8085, track.frame_3_loss_bbox_1: 1.9982, track.frame_3_loss_past_trajs_1: 0.0000, track.frame_3_loss_cls_2: 0.7564, track.frame_3_loss_bbox_2: 1.9413, track.frame_3_loss_past_trajs_2: 0.0000, track.frame_3_loss_cls_3: 0.7536, track.frame_3_loss_bbox_3: 1.9175, track.frame_3_loss_past_trajs_3: 0.0000, track.frame_3_loss_cls_4: 0.7423, track.frame_3_loss_bbox_4: 1.9009, track.frame_3_loss_past_trajs_4: 0.0000, track.frame_3_loss_cls_5: 0.7402, track.frame_3_loss_bbox_5: 1.8973, track.frame_3_loss_past_trajs_5: 0.0000, track.frame_4_loss_cls_0: 0.7436, track.frame_4_loss_bbox_0: 1.9972, track.frame_4_loss_past_trajs_0: 0.0000, track.frame_4_loss_cls_1: 0.6939, track.frame_4_loss_bbox_1: 1.9474, track.frame_4_loss_past_trajs_1: 0.0000, track.frame_4_loss_cls_2: 0.6973, track.frame_4_loss_bbox_2: 1.9020, track.frame_4_loss_past_trajs_2: 0.0000, track.frame_4_loss_cls_3: 0.6972, track.frame_4_loss_bbox_3: 1.8703, track.frame_4_loss_past_trajs_3: 0.0000, track.frame_4_loss_cls_4: 0.7109, track.frame_4_loss_bbox_4: 1.8644, track.frame_4_loss_past_trajs_4: 0.0000, track.frame_4_loss_cls_5: 0.7213, track.frame_4_loss_bbox_5: 1.8386, track.frame_4_loss_past_trajs_5: 0.0000, map.loss_cls: 0.9788, map.loss_bbox: 2.1525, map.loss_iou: 2.0318, map.loss_mask_things: 1.7252, map.loss_mask_stuff: 0.0828, map.d0.loss_mask_things_f: 1.7451, map.d0.loss_iou_f: 0.0000, map.d0.loss_bbox_f: 0.0000, map.d0.loss_cls_f: 0.0000, map.d1.loss_mask_things_f: 1.7305, map.d1.loss_iou_f: 0.0000, map.d1.loss_bbox_f: 0.0000, map.d1.loss_cls_f: 0.0000, map.d2.loss_mask_things_f: 1.7073, map.d2.loss_iou_f: 0.0000, map.d2.loss_bbox_f: 0.0000, map.d2.loss_cls_f: 0.0000, map.d3.loss_mask_things_f: 1.7030, map.d3.loss_iou_f: 0.0000, map.d3.loss_bbox_f: 0.0000, map.d3.loss_cls_f: 0.0000, map.d0.loss_mask_stuff_f: 0.0817, map.d0.loss_cls_stuff_f: 0.0049, map.d1.loss_mask_stuff_f: 0.0872, map.d1.loss_cls_stuff_f: 0.0021, map.d2.loss_mask_stuff_f: 0.0775, map.d2.loss_cls_stuff_f: 0.0013, map.d3.loss_mask_stuff_f: 0.0819, map.d3.loss_cls_stuff_f: 0.0009, map.d4.loss_mask_stuff_f: 0.0812, map.d4.loss_cls_stuff_f: 0.0012, map.d5.loss_mask_stuff_f: 0.0838, map.d5.loss_cls_stuff_f: 0.0013, map.d0.loss_cls: 1.4209, map.d0.loss_bbox: 2.2291, map.d0.loss_iou: 2.0957, map.d1.loss_cls: 1.0027, map.d1.loss_bbox: 2.2044, map.d1.loss_iou: 2.0919, map.d2.loss_cls: 0.9190, map.d2.loss_bbox: 2.1815, map.d2.loss_iou: 2.0732, map.d3.loss_cls: 0.9204, map.d3.loss_bbox: 2.1711, map.d3.loss_iou: 2.0587, map.d4.loss_cls: 0.9830, map.d4.loss_bbox: 2.1667, map.d4.loss_iou: 2.0458, loss: 120.4812, grad_norm: 451.0885
2025-05-12 07:53:43,777 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:43,789 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:43,797 - mmdet - INFO - [MyProfilerHook] runner.iter=20, Synchronize before training iter...
2025-05-12 07:53:43,797 - mmdet - INFO - [MyProfilerHook] runner.iter=20, Synchronize before training iter...
2025-05-12 07:53:43,812 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:43,827 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:44,544 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:44,555 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:44,586 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:44,600 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:45,315 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:45,326 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:45,349 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:45,364 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:46,091 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:46,103 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:46,127 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:46,143 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:46,889 - shapely.geos - INFO - Self-intersection at or near point 471.98647224679792 1711.8705119768197
2025-05-12 07:53:46,900 - shapely.geos - INFO - Self-intersection at or near point 1070.4578478045039 1612.8333503895974
2025-05-12 07:53:46,922 - shapely.geos - INFO - Self-intersection at or near point 1147.8004993016441 1404.4814343572746
2025-05-12 07:53:46,937 - shapely.geos - INFO - Self-intersection at or near point 1942.7006727221749 863.01771240972209
2025-05-12 07:53:55,183 - shapely.geos - INFO - Self-intersection at or near point 134.36374450633136 1091.2903070826083
2025-05-12 07:53:55,203 - shapely.geos - INFO - Self-intersection at or near point 165.02390945024581 1095.7013529720464
2025-05-12 07:53:55,227 - mmdet - INFO - [MyProfilerHook] runner.iter=21, Synchronize before training iter...
2025-05-12 07:53:55,227 - mmdet - INFO - [MyProfilerHook] runner.iter=21, Synchronize before training iter...
2025-05-12 07:53:55,822 - shapely.geos - INFO - Self-intersection at or near point 134.36374450633136 1091.2903070826083
2025-05-12 07:53:55,841 - shapely.geos - INFO - Self-intersection at or near point 165.02390945024581 1095.7013529720464
2025-05-12 07:53:56,512 - shapely.geos - INFO - Self-intersection at or near point 134.36374450633136 1091.2903070826083
2025-05-12 07:53:56,531 - shapely.geos - INFO - Self-intersection at or near point 165.02390945024581 1095.7013529720464
2025-05-12 07:53:57,205 - shapely.geos - INFO - Self-intersection at or near point 134.36374450633136 1091.2903070826083
2025-05-12 07:53:57,224 - shapely.geos - INFO - Self-intersection at or near point 165.02390945024581 1095.7013529720464
2025-05-12 07:53:57,927 - shapely.geos - INFO - Self-intersection at or near point 134.36374450633136 1091.2903070826083
2025-05-12 07:53:57,946 - shapely.geos - INFO - Self-intersection at or near point 165.02390945024581 1095.7013529720464
[rank0]:[W512 07:54:17.728963169 collection.cpp:1100] Warning: ROCTracer produced duplicate flow start: 180255 (function operator())
2025-05-12 07:54:40,990 - mmdet - INFO - [MyProfilerHook] runner.iter=22, Synchronize before training iter...
2025-05-12 07:54:40,990 - mmdet - INFO - [MyProfilerHook] runner.iter=22, Synchronize before training iter...
2025-05-12 07:56:53,630 - mmdet - INFO - -------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  Total KFLOPs  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us       22.534s       129.25%       22.534s        5.633s             4            --  
                               aten::miopen_convolution         0.92%     261.354ms         1.01%     287.788ms     129.634us        2.915s        16.72%        2.947s       1.327ms          2220            --  
void ms_deformable_col2im_gpu_kernel_shm_blocksize_a...         0.00%       0.000us         0.00%       0.000us       0.000us        2.544s        14.59%        2.544s      12.469ms           204            --  
          MultiScaleDeformableAttnFunction_fp32Backward         0.06%      16.423ms         0.10%      27.783ms     154.350us        2.510s        14.40%        2.533s      14.071ms           180            --  
                                           aten::addmm_         0.40%     114.585ms         0.53%     149.600ms      29.968us        2.016s        11.56%        2.016s     403.773us          4992            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT112x128x16...         0.00%       0.000us         0.00%       0.000us       0.000us        1.760s        10.09%        1.760s     398.542us          4416            --  
                                               aten::mm         0.49%     138.303ms         0.63%     179.673ms      37.061us        1.175s         6.74%        1.175s     242.393us          4848  14036913166.528  
                                            aten::addmm         0.47%     135.172ms         0.61%     172.620ms      43.679us     948.766ms         5.44%     948.766ms     240.072us          3952  19822865382.400  
        miopenSp3AsmConv_v30_3_1_gfx9_fp32_f2x3_stride1         0.00%       0.000us         0.00%       0.000us       0.000us     903.689ms         5.18%     903.689ms       1.189ms           760            --  
void ms_deformable_im2col_gpu_kernel<float>(int, flo...         0.00%       0.000us         0.00%       0.000us       0.000us     876.474ms         5.03%     876.474ms       1.873ms           468            --  
                  MultiScaleDeformableAttnFunction_fp32         0.06%      16.597ms         0.11%      29.972ms      67.504us     871.878ms         5.00%     883.450ms       1.990ms           444            --  
                                              aten::bmm         0.09%      24.798ms         0.11%      31.589ms      40.812us     840.290ms         4.82%     840.290ms       1.086ms           774  193599422.976  
                          ModulatedDeformConv2dFunction         0.46%     130.300ms         1.70%     484.095ms     930.952us     825.184ms         4.73%        2.867s       5.514ms           520            --  
void modulated_deformable_im2col_gpu_kernel<float>(i...         0.00%       0.000us         0.00%       0.000us       0.000us     825.184ms         4.73%     825.184ms     165.301us          4992            --  
Cijk_Alik_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT32x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us     808.651ms         4.64%     808.651ms      25.270ms            32            --  
                             aten::convolution_backward         0.06%      18.226ms         0.08%      23.719ms     338.841us     745.328ms         4.28%     773.213ms      11.046ms            70            --  
                                            aten::copy_         0.63%     178.419ms        38.93%       11.091s     136.384us     712.932ms         4.09%     713.569ms       8.775us         81321            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     697.812ms         4.00%     697.812ms     181.817us          3838            --  
                                       aten::clamp_min_         0.03%       8.875ms         0.07%      19.289ms       7.841us     690.697ms         3.96%     690.697ms     280.771us          2460            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT128x64x32_...         0.00%       0.000us         0.00%       0.000us       0.000us     654.196ms         3.75%     654.196ms     430.392us          1520            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     610.636ms         3.50%     610.636ms      53.275us         11462            --  
                                             aten::add_         0.11%      30.966ms         0.24%      67.659ms       5.831us     601.355ms         3.45%     601.355ms      51.823us         11604            --  
_ZN2ck16tensor_operation6device37kernel_batched_gemm...         0.00%       0.000us         0.00%       0.000us       0.000us     598.462ms         3.43%     598.462ms      29.923ms            20            --  
Cijk_Ailk_Bljk_SB_MT96x64x32_MI16x16x4x1_SN_1LDSB1_A...         0.00%       0.000us         0.00%       0.000us       0.000us     546.381ms         3.13%     546.381ms       1.188ms           460            --  
Cijk_Ailk_Bljk_SB_MT96x64x32_MI16x16x4x1_SN_1LDSB1_A...         0.00%       0.000us         0.00%       0.000us       0.000us     502.078ms         2.88%     502.078ms       1.091ms           460            --  
Cijk_Ailk_Bljk_SB_MT128x128x32_MI16x16x4x1_SN_1LDSB1...         0.00%       0.000us         0.00%       0.000us       0.000us     498.355ms         2.86%     498.355ms       1.917ms           260            --  
Cijk_Alik_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT32x16x8_MI...         0.00%       0.000us         0.00%       0.000us       0.000us     453.641ms         2.60%     453.641ms       9.451ms            48            --  
                           Memcpy HtoD (Host -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us     444.208ms         2.55%     444.208ms       7.737us         57411            --  
                                aten::miopen_batch_norm         0.15%      43.517ms         0.23%      65.422ms      31.453us     441.671ms         2.53%     441.671ms     212.342us          2080            --  
                      MIOpenBatchNormFwdInferSpatialEst         0.00%       0.000us         0.00%       0.000us       0.000us     441.671ms         2.53%     441.671ms     212.342us          2080            --  
                           Memcpy DtoH (Device -> Host)         0.00%       0.000us         0.00%       0.000us       0.000us     358.511ms         2.06%     358.511ms       5.638us         63593            --  
                              Optimizer.step#AdamW.step         0.00%       0.000us         0.00%       0.000us       0.000us     333.267ms         1.91%     333.267ms     166.634ms             2            --  
                              aten::_local_scalar_dense         0.38%     108.874ms         4.91%        1.399s      21.196us     298.462ms         1.71%     298.462ms       4.521us         66011            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x128x16_...         0.00%       0.000us         0.00%       0.000us       0.000us     255.672ms         1.47%     255.672ms     443.875us           576            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT256x240x16...         0.00%       0.000us         0.00%       0.000us       0.000us     241.960ms         1.39%     241.960ms     611.009us           396            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT128x64x32_...         0.00%       0.000us         0.00%       0.000us       0.000us     178.483ms         1.02%     178.483ms     417.016us           428            --  
                                              aten::add         0.14%      38.811ms         0.22%      63.998ms      12.456us     174.222ms         1.00%     174.222ms      33.909us          5138  16629086.422  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     164.968ms         0.95%     164.968ms      47.845us          3448            --  
                                              aten::div         0.08%      21.631ms         0.13%      37.703ms      11.302us     163.962ms         0.94%     163.962ms      49.149us          3336            --  
                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us     160.338ms         0.92%     160.338ms      12.045us         13312            --  
                                          aten::nonzero         0.20%      58.022ms        15.45%        4.403s       1.196ms     156.817ms         0.90%     156.817ms      42.590us          3682            --  
        miopenSp3AsmConv_v30_3_1_gfx9_fp32_f3x2_stride2         0.00%       0.000us         0.00%       0.000us       0.000us     139.544ms         0.80%     139.544ms       3.489ms            40            --  
                                aten::native_layer_norm         0.05%      12.996ms         0.10%      27.313ms      25.384us     138.506ms         0.79%     138.506ms     128.723us          1076            --  
void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us     138.506ms         0.79%     138.506ms     128.723us          1076            --  
                                            aten::fill_         0.08%      22.719ms         0.26%      73.519ms       5.419us     136.084ms         0.78%     136.084ms      10.030us         13568            --  
                                              aten::sum         0.15%      43.065ms         0.36%     102.466ms      20.115us     135.193ms         0.78%     150.760ms      29.596us          5094            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     134.265ms         0.77%     134.265ms      12.572us         10680            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     127.341ms         0.73%     127.341ms     187.267us           680            --  
Cijk_Ailk_Bljk_SB_MT64x128x16_MI16x16x4x1_SN_1LDSB1_...         0.00%       0.000us         0.00%       0.000us       0.000us     118.254ms         0.68%     118.254ms       1.408ms            84            --  
Cijk_Ailk_Bljk_SB_MT64x128x16_MI16x16x4x1_SN_1LDSB1_...         0.00%       0.000us         0.00%       0.000us       0.000us     113.092ms         0.65%     113.092ms       2.570ms            44            --  
                                              aten::cat         0.12%      34.107ms         0.24%      68.035ms      17.043us     107.513ms         0.62%     107.513ms      26.932us          3992            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT128x32x32_...         0.00%       0.000us         0.00%       0.000us       0.000us      98.274ms         0.56%      98.274ms     545.969us           180            --  
                                            aten::index         0.24%      68.076ms         1.04%     297.450ms      37.153us      96.046ms         0.55%     179.755ms      22.452us          8006            --  
                                             aten::mean         0.02%       5.740ms         0.03%       8.721ms      15.088us      95.434ms         0.55%      95.434ms     165.112us           578            --  
                                 aten::_index_put_impl_         0.12%      35.217ms        13.50%        3.846s       1.243ms      92.870ms         0.53%     132.416ms      42.798us          3094            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT128x48x32_...         0.00%       0.000us         0.00%       0.000us       0.000us      92.814ms         0.53%      92.814ms     703.133us           132            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      92.686ms         0.53%      92.686ms      22.662us          4090            --  
void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      92.677ms         0.53%      92.677ms     382.963us           242            --  
void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      90.050ms         0.52%      90.050ms      40.969us          2198            --  
void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      89.889ms         0.52%      89.889ms      14.314us          6280            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT256x64x16_...         0.00%       0.000us         0.00%       0.000us       0.000us      70.434ms         0.40%      70.434ms     533.592us           132            --  
Cijk_Ailk_Bljk_SB_MT64x64x32_MI16x16x4x1_SN_1LDSB1_A...         0.00%       0.000us         0.00%       0.000us       0.000us      67.674ms         0.39%      67.674ms       1.128ms            60            --  
                       aten::native_layer_norm_backward         0.03%       7.629ms         0.08%      23.023ms      35.640us      65.612ms         0.38%      65.612ms     101.566us           646            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us      63.863ms         0.37%      63.863ms     115.693us           552            --  
                                              aten::mul         0.16%      44.712ms         0.29%      83.327ms       8.885us      54.757ms         0.31%      54.757ms       5.839us          9378   2408866.765  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT48x128x32_...         0.00%       0.000us         0.00%       0.000us       0.000us      51.954ms         0.30%      51.954ms     721.589us            72            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT128x32x32_...         0.00%       0.000us         0.00%       0.000us       0.000us      51.208ms         0.29%      51.208ms     206.485us           248            --  
                          aten::max_pool2d_with_indices         0.00%     254.408us         0.00%     435.351us      21.768us      46.128ms         0.26%      46.128ms       2.306ms            20            --  
void at::native::(anonymous namespace)::max_pool_for...         0.00%       0.000us         0.00%       0.000us       0.000us      46.128ms         0.26%      46.128ms       2.306ms            20            --  
Cijk_Ailk_Bljk_SB_MT64x64x32_MI16x16x4x1_SN_1LDSB1_A...         0.00%       0.000us         0.00%       0.000us       0.000us      43.834ms         0.25%      43.834ms       1.096ms            40            --  
                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us      38.085ms         0.22%      38.085ms       7.111us          5356            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT128x64x16_...         0.00%       0.000us         0.00%       0.000us       0.000us      34.882ms         0.20%      34.882ms     484.477us            72            --  
                                    aten::_foreach_mul_         0.05%      13.597ms         0.13%      37.167ms       8.737us      34.789ms         0.20%      34.789ms       8.178us          4254            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      33.987ms         0.19%      33.987ms       7.993us          4252            --  
void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      33.515ms         0.19%      33.515ms      20.663us          1622            --  
               MultiScaleDeformableAttnFunctionBackward         0.01%       1.463ms         0.01%       2.693ms     112.192us      33.495ms         0.19%      34.716ms       1.447ms            24            --  
                                         aten::_softmax         0.01%       4.271ms         0.03%       7.978ms      13.523us      32.984ms         0.19%      32.984ms      55.904us           590            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x128x32_...         0.00%       0.000us         0.00%       0.000us       0.000us      31.378ms         0.18%      31.378ms     237.711us           132            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us      29.652ms         0.17%      29.652ms      60.269us           492            --  
void at::native::(anonymous namespace)::cuComputeGra...         0.00%       0.000us         0.00%       0.000us       0.000us      28.584ms         0.16%      28.584ms     140.119us           204            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x160x32_...         0.00%       0.000us         0.00%       0.000us       0.000us      28.467ms         0.16%      28.467ms     148.264us           192            --  
void at::native::(anonymous namespace)::cuComputePar...         0.00%       0.000us         0.00%       0.000us       0.000us      27.708ms         0.16%      27.708ms      51.312us           540            --  
Cijk_Alik_Bljk_SB_MT64x32x64_MI16x16x4x1_SN_1LDSB1_A...         0.00%       0.000us         0.00%       0.000us       0.000us      26.287ms         0.15%      26.287ms     219.060us           120            --  
void (anonymous namespace)::indexing_backward_kernel...         0.00%       0.000us         0.00%       0.000us       0.000us      25.798ms         0.15%      25.798ms      33.418us           772            --  
void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us      25.155ms         0.14%      25.155ms     130.337us           193            --  
                     transpose_NCHW2CNHW_V2_2D_WG_off64         0.00%       0.000us         0.00%       0.000us       0.000us      21.175ms         0.12%      21.175ms     176.459us           120            --  
Cijk_Ailk_Bljk_SB_MT64x64x32_MI16x16x4x1_SN_1LDSB1_A...         0.00%       0.000us         0.00%       0.000us       0.000us      20.327ms         0.12%      20.327ms       1.452ms            14            --  
                                    aten::_foreach_sqrt         0.03%       9.331ms         0.09%      25.305ms      11.903us      19.370ms         0.11%      19.370ms       9.111us          2126            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      19.370ms         0.11%      19.370ms       9.111us          2126            --  
                                aten::_foreach_addcdiv_         0.02%       7.023ms         0.07%      18.552ms       8.726us      19.101ms         0.11%      19.101ms       8.985us          2126            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      19.101ms         0.11%      19.101ms       8.985us          2126            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT80x128x16_...         0.00%       0.000us         0.00%       0.000us       0.000us      19.099ms         0.11%      19.099ms     318.310us            60            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      18.864ms         0.11%      18.864ms       4.998us          3774            --  
                                   aten::_foreach_lerp_         0.02%       5.018ms         0.06%      16.282ms       7.659us      18.409ms         0.11%      18.409ms       8.659us          2126            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      18.409ms         0.11%      18.409ms       8.659us          2126            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      17.885ms         0.10%      17.885ms      56.243us           318            --  
                                    aten::_foreach_div_         0.02%       5.849ms         0.06%      18.029ms       8.480us      17.547ms         0.10%      17.547ms       8.253us          2126            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      17.547ms         0.10%      17.547ms       8.253us          2126            --  
                                   aten::native_dropout         0.02%       6.530ms         0.05%      15.074ms      23.702us      17.408ms         0.10%      17.408ms      27.371us           636            --  
void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us      17.408ms         0.10%      17.408ms      27.371us           636            --  
void rocprim::detail::transform_kernel<rocprim::deta...         0.00%       0.000us         0.00%       0.000us       0.000us      16.872ms         0.10%      16.872ms       4.607us          3662            --  
void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      16.552ms         0.09%      16.552ms      10.776us          1536            --  
                          aten::native_dropout_backward         0.01%       2.767ms         0.03%       7.228ms      11.365us      15.533ms         0.09%      15.533ms      24.422us           636            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      15.533ms         0.09%      15.533ms      24.422us           636            --  
void rocprim::detail::init_lookback_scan_state_kerne...         0.00%       0.000us         0.00%       0.000us       0.000us      14.906ms         0.09%      14.906ms       4.042us          3688            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      14.723ms         0.08%      14.723ms      21.462us           686            --  
                                aten::_foreach_addcmul_         0.03%       7.590ms         0.07%      18.981ms       8.928us      14.709ms         0.08%      14.709ms       6.919us          2126            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      14.709ms         0.08%      14.709ms       6.919us          2126            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT32x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us      14.547ms         0.08%      14.547ms      17.339us           839            --  
void rocprim::detail::device_block_merge_oddeven_ker...         0.00%       0.000us         0.00%       0.000us       0.000us      13.393ms         0.08%      13.393ms       6.377us          2100            --  
                                    aten::_foreach_add_         0.03%       8.476ms         0.08%      22.732ms       5.346us      13.127ms         0.08%      13.127ms       3.087us          4252            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      13.127ms         0.08%      13.127ms       6.175us          2126            --  
void rocprim::detail::partition_kernel<(rocprim::det...         0.00%       0.000us         0.00%       0.000us       0.000us      12.047ms         0.07%      12.047ms       4.800us          2510            --  
Cijk_Ailk_Bljk_SB_MT32x32x64_MI16x16x4x1_SN_1LDSB0_A...         0.00%       0.000us         0.00%       0.000us       0.000us      11.983ms         0.07%      11.983ms     599.155us            20            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      11.503ms         0.07%      11.503ms      19.833us           580            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      11.455ms         0.07%      11.455ms       8.977us          1276            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      11.343ms         0.07%      11.343ms       9.846us          1152            --  
                                  aten::grid_sampler_2d         0.00%     190.925us         0.00%     429.563us      19.526us      11.062ms         0.06%      11.062ms     502.824us            22            --  
void at::native::(anonymous namespace)::grid_sampler...         0.00%       0.000us         0.00%       0.000us       0.000us      11.062ms         0.06%      11.062ms     502.824us            22            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us      10.778ms         0.06%      10.778ms      15.992us           674            --  
void rocprim::detail::radix_sort_block_sort_kernel<r...         0.00%       0.000us         0.00%       0.000us       0.000us      10.658ms         0.06%      10.658ms      10.209us          1044            --  
              transpose_CNHW2NCHW_V1_1D_WG_float4_off64         0.00%       0.000us         0.00%       0.000us       0.000us      10.282ms         0.06%      10.282ms     128.527us            80            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT80x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us      10.155ms         0.06%      10.155ms     169.251us            60            --  
                          batched_transpose_32x32_dword         0.00%       0.000us         0.00%       0.000us       0.000us       9.775ms         0.06%       9.775ms     244.387us            40            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       9.304ms         0.05%       9.304ms     930.425us            10            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT128x96x16_...         0.00%       0.000us         0.00%       0.000us       0.000us       9.141ms         0.05%       9.141ms     380.895us            24            --  
                           aten::_softmax_backward_data         0.01%       3.073ms         0.03%       9.080ms      28.198us       8.867ms         0.05%      18.057ms      56.078us           322            --  
                               aten::threshold_backward         0.01%       2.984ms         0.02%       5.563ms       8.665us       8.786ms         0.05%       8.786ms      13.685us           642            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       8.786ms         0.05%       8.786ms      13.685us           642            --  
void rocprim::detail::block_reduce_kernel<true, rocp...         0.00%       0.000us         0.00%       0.000us       0.000us       8.769ms         0.05%       8.769ms       3.494us          2510            --  
                                             aten::div_         0.02%       6.282ms         0.04%      12.761ms       8.330us       8.627ms         0.05%       8.627ms       5.631us          1532            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       7.748ms         0.04%       7.748ms      16.075us           482            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT96x128x32_...         0.00%       0.000us         0.00%       0.000us       0.000us       7.704ms         0.04%       7.704ms      64.202us           120            --  
                               aten::upsample_nearest2d         0.00%     430.613us         0.00%     727.074us      17.311us       7.613ms         0.04%       7.619ms     181.401us            42            --  
void at::native::(anonymous namespace)::upsample_nea...         0.00%       0.000us         0.00%       0.000us       0.000us       7.613ms         0.04%       7.613ms     190.334us            40            --  
void rocprim::detail::partition_kernel<(rocprim::det...         0.00%       0.000us         0.00%       0.000us       0.000us       7.569ms         0.04%       7.569ms       6.571us          1152            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT64x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       7.468ms         0.04%       7.468ms      51.859us           144            --  
Cijk_Ailk_Bljk_SB_MT64x256x16_MI16x16x4x1_SN_1LDSB1_...         0.00%       0.000us         0.00%       0.000us       0.000us       7.011ms         0.04%       7.011ms       1.753ms             4            --  
                                              aten::sub         0.04%      10.212ms         0.09%      24.938ms      14.185us       6.646ms         0.04%       6.646ms       3.780us          1758            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       6.399ms         0.04%       6.399ms       5.228us          1224            --  
                                        aten::remainder         0.03%       7.661ms         0.04%      12.634ms      10.670us       6.364ms         0.04%       6.364ms       5.375us          1184            --  
void rocprim::detail::block_reduce_kernel<false, roc...         0.00%       0.000us         0.00%       0.000us       0.000us       6.291ms         0.04%       6.291ms       5.461us          1152            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       6.287ms         0.04%       6.287ms       5.373us          1170            --  
                                   aten::_cdist_forward         0.01%       1.456ms         0.02%       4.505ms      60.884us       6.119ms         0.04%       6.545ms      88.448us            74            --  
void at::native::(anonymous namespace)::cdist_kernel...         0.00%       0.000us         0.00%       0.000us       0.000us       6.119ms         0.04%       6.119ms      82.690us            74            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       5.892ms         0.03%       5.892ms       9.323us           632            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.786ms         0.03%       5.786ms       5.542us          1044            --  
void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.668ms         0.03%       5.668ms       3.565us          1590            --  
                                          aten::sigmoid         0.02%       6.259ms         0.04%      10.425ms      12.038us       5.640ms         0.03%       5.640ms       6.513us           866            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT256x64x16_...         0.00%       0.000us         0.00%       0.000us       0.000us       5.590ms         0.03%       5.590ms     232.920us            24            --  
void rocprim::detail::block_reduce_kernel<true, rocp...         0.00%       0.000us         0.00%       0.000us       0.000us       5.517ms         0.03%       5.517ms       4.789us          1152            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.394ms         0.03%       5.394ms       4.143us          1302            --  
                                            aten::clamp         0.02%       6.635ms         0.05%      13.458ms      13.431us       5.309ms         0.03%       6.439ms       6.426us          1002            --  
                                           aten::arange         0.02%       6.976ms         0.09%      26.182ms      10.423us       5.246ms         0.03%      10.492ms       4.177us          2512            --  
void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us       5.241ms         0.03%       5.241ms       4.622us          1134            --  
                                            Im2d2Col_v2         0.00%       0.000us         0.00%       0.000us       0.000us       5.222ms         0.03%       5.222ms      43.515us           120            --  
void at::native::(anonymous namespace)::layer_norm_g...         0.00%       0.000us         0.00%       0.000us       0.000us       5.176ms         0.03%       5.176ms      11.711us           442            --  
Cijk_Alik_Bljk_SB_MT64x64x32_MI16x16x4x1_SN_1LDSB0_A...         0.00%       0.000us         0.00%       0.000us       0.000us       5.047ms         0.03%       5.047ms      84.124us            60            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT64x16x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       4.978ms         0.03%       4.978ms      19.993us           249            --  
                                               aten::gt         0.02%       4.731ms         0.03%       7.516ms      12.444us       4.897ms         0.03%       4.897ms       8.107us           604            --  
                                               aten::eq         0.02%       6.332ms         0.04%      10.949ms      10.798us       4.890ms         0.03%       4.890ms       4.823us          1014            --  
Cijk_Ailk_Bljk_SB_MT64x64x32_MI16x16x4x1_SN_1LDSB1_A...         0.00%       0.000us         0.00%       0.000us       0.000us       4.879ms         0.03%       4.879ms     348.487us            14            --  
void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us       4.766ms         0.03%       4.766ms      79.426us            60            --  
                     aten::upsample_bilinear2d_backward         0.00%     131.104us         0.00%     415.960us      17.332us       4.740ms         0.03%       4.847ms     201.976us            24            --  
void at::native::(anonymous namespace)::upsample_bil...         0.00%       0.000us         0.00%       0.000us       0.000us       4.740ms         0.03%       4.740ms     197.495us            24            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.680ms         0.03%       4.680ms       4.957us           944            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       4.653ms         0.03%       4.653ms       9.124us           510            --  
                       MultiScaleDeformableAttnFunction         0.00%     800.037us         0.01%       1.483ms      61.791us       4.596ms         0.03%       4.940ms     205.848us            24            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       4.456ms         0.03%       4.456ms      13.584us           328            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       4.367ms         0.03%       4.367ms       6.824us           640            --  
void at::native::elementwise_kernel<512, 1, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       4.258ms         0.02%       4.258ms       9.257us           460            --  
                                        hipEventDestroy         0.00%     293.785us         0.00%     293.785us       0.512us       4.150ms         0.02%       4.150ms       7.231us           574            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.068ms         0.02%       4.068ms       9.461us           430            --  
           Cijk_SS_BiasS_HAS_ScaleAlphaVec_PostGSU8_VW4         0.00%       0.000us         0.00%       0.000us       0.000us       4.048ms         0.02%       4.048ms       6.405us           632            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       3.977ms         0.02%       3.977ms      14.154us           281            --  
                                     aten::masked_fill_         0.00%     640.019us         0.01%       1.447ms       8.221us       3.900ms         0.02%       3.900ms      22.158us           176            --  
void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us       3.851ms         0.02%       3.851ms      14.811us           260            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.833ms         0.02%       3.833ms       5.755us           666            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x16x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       3.637ms         0.02%       3.637ms      10.987us           331            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x96x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       3.549ms         0.02%       3.549ms      26.885us           132            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT16x256x16_...         0.00%       0.000us         0.00%       0.000us       0.000us       3.475ms         0.02%       3.475ms      72.401us            48            --  
void rocprim::detail::transform_kernel<rocprim::deta...         0.00%       0.000us         0.00%       0.000us       0.000us       3.361ms         0.02%       3.361ms       6.224us           540            --  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       3.283ms         0.02%       3.283ms       7.427us           442            --  
void rocprim::detail::transform_kernel<rocprim::deta...         0.00%       0.000us         0.00%       0.000us       0.000us       3.273ms         0.02%       3.273ms       6.062us           540            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.271ms         0.02%       3.271ms       4.660us           702            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.230ms         0.02%       3.230ms      67.295us            48            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       3.111ms         0.02%       3.111ms       5.847us           532            --  
void at::native::(anonymous namespace)::cuComputeGra...         0.00%       0.000us         0.00%       0.000us       0.000us       3.087ms         0.02%       3.087ms       5.716us           540            --  
                                               aten::ge         0.01%       2.624ms         0.02%       4.404ms      12.032us       2.936ms         0.02%       2.936ms       8.021us           366            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.890ms         0.02%       2.890ms       6.783us           426            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x16x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       2.769ms         0.02%       2.769ms      11.985us           231            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       2.757ms         0.02%       2.757ms       8.206us           336            --  
                                               aten::ne         0.01%       3.613ms         0.02%       6.497ms       9.335us       2.746ms         0.02%       2.746ms       3.945us           696            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT32x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       2.684ms         0.02%       2.684ms      12.198us           220            --  
      miopenSp3AsmConv_v30_3_1_gfx9_fp32_f3x2_dilation2         0.00%       0.000us         0.00%       0.000us       0.000us       2.546ms         0.01%       2.546ms     254.588us            10            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       2.518ms         0.01%       2.518ms       4.433us           568            --  
                                              aten::neg         0.01%       2.086ms         0.01%       4.119ms       8.140us       2.483ms         0.01%       2.483ms       4.907us           506            --  
                                        aten::clamp_min         0.01%       2.147ms         0.01%       4.271ms       8.374us       2.409ms         0.01%       2.409ms       4.724us           510            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT48x128x16_...         0.00%       0.000us         0.00%       0.000us       0.000us       2.325ms         0.01%       2.325ms     193.734us            12            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.302ms         0.01%       2.302ms       4.940us           466            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       2.281ms         0.01%       2.281ms       4.618us           494            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT32x128x16_...         0.00%       0.000us         0.00%       0.000us       0.000us       2.279ms         0.01%       2.279ms     113.952us            20            --  
Cijk_Alik_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT32x16x8_MI...         0.00%       0.000us         0.00%       0.000us       0.000us       2.234ms         0.01%       2.234ms      93.068us            24            --  
              transpose_CNHW2NCHW_V1_1D_WG_float2_off64         0.00%       0.000us         0.00%       0.000us       0.000us       2.213ms         0.01%       2.213ms      55.323us            40            --  
                                              aten::abs         0.01%       3.924ms         0.04%      12.147ms      11.331us       2.157ms         0.01%       4.315ms       4.025us          1072            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.157ms         0.01%       2.157ms       4.025us           536            --  
void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us       2.126ms         0.01%       2.126ms      35.435us            60            --  
                                              aten::log         0.01%       2.141ms         0.01%       4.045ms       9.406us       2.114ms         0.01%       2.114ms       4.917us           430            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.040ms         0.01%       2.040ms       4.834us           422            --  
                      aten::upsample_nearest2d_backward         0.00%     107.123us         0.00%     243.371us      12.169us       2.016ms         0.01%       2.016ms     100.798us            20            --  
void at::native::(anonymous namespace)::upsample_nea...         0.00%       0.000us         0.00%       0.000us       0.000us       2.016ms         0.01%       2.016ms     100.798us            20            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT32x128x32_...         0.00%       0.000us         0.00%       0.000us       0.000us       2.010ms         0.01%       2.010ms      33.503us            60            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.941ms         0.01%       1.941ms       5.107us           380            --  
void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.889ms         0.01%       1.889ms       4.972us           380            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.860ms         0.01%       1.860ms       3.495us           532            --  
void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us       1.795ms         0.01%       1.795ms      29.910us            60            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT128x32x16_...         0.00%       0.000us         0.00%       0.000us       0.000us       1.790ms         0.01%       1.790ms       9.178us           195            --  
                                            aten::where         0.01%       2.286ms         0.02%       4.603ms      12.645us       1.790ms         0.01%       1.790ms       4.917us           364            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.762ms         0.01%       1.762ms      10.242us           172            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT48x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       1.730ms         0.01%       1.730ms      24.029us            72            --  
void at::native::vectorized_elementwise_kernel<16, a...         0.00%       0.000us         0.00%       0.000us       0.000us       1.723ms         0.01%       1.723ms       7.240us           238            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT16x128x16_...         0.00%       0.000us         0.00%       0.000us       0.000us       1.695ms         0.01%       1.695ms      11.008us           154            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT80x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       1.655ms         0.01%       1.655ms     165.500us            10            --  
          Cijk_SS_BiasS_HAS_ScaleAlphaVec_PostGSU16_VW4         0.00%       0.000us         0.00%       0.000us       0.000us       1.643ms         0.01%       1.643ms       9.445us           174            --  
Cijk_Alik_Bljk_SB_MT64x64x32_MI16x16x4x1_SN_1LDSB0_A...         0.00%       0.000us         0.00%       0.000us       0.000us       1.638ms         0.01%       1.638ms      27.304us            60            --  
                                      aten::bitwise_and         0.00%       1.408ms         0.01%       2.495ms      11.444us       1.628ms         0.01%       1.628ms       7.468us           218            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.610ms         0.01%       1.610ms       4.066us           396            --  
                                          aten::maximum         0.01%       2.075ms         0.01%       3.591ms      12.468us       1.539ms         0.01%       1.539ms       5.343us           288            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.537ms         0.01%       1.537ms       2.254us           682            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.530ms         0.01%       1.530ms       9.564us           160            --  
                                         aten::_unique2         0.00%     501.511us         0.01%       2.668ms      95.302us       1.471ms         0.01%       1.776ms      63.420us            28            --  
void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.457ms         0.01%       1.457ms       3.624us           402            --  
                                       aten::nan_to_num         0.01%       1.920ms         0.03%       7.324ms       9.951us       1.444ms         0.01%       3.278ms       4.453us           736            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.444ms         0.01%       1.444ms       4.299us           336            --  
void at::native::elementwise_kernel<512, 1, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.443ms         0.01%       1.443ms       5.081us           284            --  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       1.433ms         0.01%       1.433ms       5.193us           276            --  
void at::native::reduce_kernel<256, 2, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       1.428ms         0.01%       1.428ms      10.058us           142            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       1.345ms         0.01%       1.345ms       9.964us           135            --  
void (anonymous namespace)::indexing_backward_kernel...         0.00%       0.000us         0.00%       0.000us       0.000us       1.327ms         0.01%       1.327ms       4.877us           272            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.304ms         0.01%       1.304ms       5.017us           260            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT256x8x8_MI...         0.00%       0.000us         0.00%       0.000us       0.000us       1.260ms         0.01%       1.260ms      52.488us            24            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.212ms         0.01%       1.212ms       5.666us           214            --  
                                               aten::lt         0.00%     802.586us         0.01%       1.510ms       8.986us       1.171ms         0.01%       1.171ms       6.969us           168            --  
                                              aten::exp         0.01%       1.643ms         0.01%       3.291ms       7.835us       1.126ms         0.01%       1.126ms       2.682us           420            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       1.110ms         0.01%       1.110ms       5.781us           192            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT128x16x32_...         0.00%       0.000us         0.00%       0.000us       0.000us       1.088ms         0.01%       1.088ms      90.636us            12            --  
void at::native::(anonymous namespace)::cunn_SoftMax...         0.00%       0.000us         0.00%       0.000us       0.000us       1.087ms         0.01%       1.087ms      54.365us            20            --  
void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us       1.079ms         0.01%       1.079ms       8.563us           126            --  
void at::native::(anonymous namespace)::GammaBetaBac...         0.00%       0.000us         0.00%       0.000us       0.000us       1.056ms         0.01%       1.056ms       9.962us           106            --  
                                 aten::sigmoid_backward         0.00%     716.340us         0.01%       1.426ms       8.389us       1.041ms         0.01%       1.041ms       6.124us           170            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.041ms         0.01%       1.041ms       6.124us           170            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.003ms         0.01%       1.003ms       2.572us           390            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     991.936us         0.01%     991.936us       8.857us           112            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     970.082us         0.01%     970.082us       3.976us           244            --  
void at::native::vectorized_elementwise_kernel<16, a...         0.00%       0.000us         0.00%       0.000us       0.000us     955.088us         0.01%     955.088us       3.460us           276            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     876.047us         0.01%     876.047us       3.174us           276            --  
                                              aten::max         0.01%       1.903ms         0.02%       5.987ms      15.755us     836.520us         0.00%       1.970ms       5.183us           380            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     819.565us         0.00%     819.565us       6.830us           120            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us     801.825us         0.00%     801.825us      40.091us            20            --  
void rocprim::detail::radix_sort_block_sort_kernel<r...         0.00%       0.000us         0.00%       0.000us       0.000us     758.777us         0.00%     758.777us      29.184us            26            --  
                                              aten::pow         0.00%       1.416ms         0.01%       2.266ms      14.910us     742.975us         0.00%     758.612us       4.991us           152            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     731.776us         0.00%     731.776us       4.944us           148            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     722.384us         0.00%     722.384us       5.160us           140            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT128x32x16_...         0.00%       0.000us         0.00%       0.000us       0.000us     719.088us         0.00%     719.088us      19.975us            36            --  
                                              aten::sgn         0.00%     645.882us         0.00%       1.261ms       9.007us     714.226us         0.00%     714.226us       5.102us           140            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     714.226us         0.00%     714.226us       5.102us           140            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     701.384us         0.00%     701.384us       3.812us           184            --  
void at::native::elementwise_kernel<512, 1, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     678.124us         0.00%     678.124us       2.422us           280            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     676.732us         0.00%     676.732us       3.525us           192            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     669.557us         0.00%     669.557us       5.231us           128            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x32x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us     666.492us         0.00%     666.492us      18.514us            36            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     612.493us         0.00%     612.493us       8.750us            70            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     610.844us         0.00%     610.844us       2.545us           240            --  
                                          aten::minimum         0.00%     879.639us         0.01%       1.464ms      11.441us     596.281us         0.00%     596.281us       4.658us           128            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     595.924us         0.00%     595.924us       4.966us           120            --  
void at::native::(anonymous namespace)::cunn_SoftMax...         0.00%       0.000us         0.00%       0.000us       0.000us     574.984us         0.00%     574.984us      28.749us            20            --  
                                             aten::sort         0.00%     199.323us         0.00%     674.435us      67.444us     568.472us         0.00%     677.194us      67.719us            10            --  
void at::native::radixSortKVInPlace<-2, -1, 32, 32, ...         0.00%       0.000us         0.00%       0.000us       0.000us     568.472us         0.00%     568.472us      56.847us            10            --  
void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us     561.977us         0.00%     561.977us      20.814us            27            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT64x64x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us     540.617us         0.00%     540.617us      22.526us            24            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     529.030us         0.00%     529.030us       5.750us            92            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     527.776us         0.00%     527.776us       3.566us           148            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x16x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us     504.765us         0.00%     504.765us       6.232us            81            --  
                                         aten::linspace         0.00%       1.019ms         0.02%       6.631ms      15.788us     499.840us         0.00%       1.030ms       2.453us           420            --  
void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us     499.840us         0.00%     499.840us       2.403us           208            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us     492.586us         0.00%     492.586us       8.493us            58            --  
void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     489.464us         0.00%     489.464us       5.099us            96            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     472.481us         0.00%     472.481us       3.937us           120            --  
                                            aten::floor         0.00%     569.611us         0.00%       1.114ms       9.284us     470.843us         0.00%     470.843us       3.924us           120            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     470.843us         0.00%     470.843us       3.924us           120            --  
                       SigmoidFocalLossFunctionBackward         0.01%       4.261ms         0.02%       6.847ms      74.423us     456.551us         0.00%       1.160ms      12.611us            92            --  
void sigmoid_focal_loss_backward_cuda_kernel<float>(...         0.00%       0.000us         0.00%       0.000us       0.000us     456.551us         0.00%     456.551us       4.963us            92            --  
                                            aten::atan2         0.00%     834.575us         0.01%       1.505ms      10.750us     453.260us         0.00%     453.260us       3.238us           140            --  
void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us     451.335us         0.00%     451.335us      16.716us            27            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x48x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us     450.018us         0.00%     450.018us      18.751us            24            --  
                                             aten::mul_         0.00%     304.365us         0.00%     682.215us       7.415us     447.789us         0.00%     447.789us       4.867us            92            --  
                               SigmoidFocalLossFunction         0.01%       4.212ms         0.04%      12.443ms     135.251us     445.630us         0.00%       2.704ms      29.397us            92            --  
void sigmoid_focal_loss_forward_cuda_kernel<float>(i...         0.00%       0.000us         0.00%       0.000us       0.000us     445.630us         0.00%     445.630us       4.844us            92            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x96x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us     428.538us         0.00%     428.538us      17.856us            24            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x48x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us     418.780us         0.00%     418.780us      17.449us            24            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     413.922us         0.00%     413.922us       3.449us           120            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     409.990us         0.00%     409.990us       3.154us           130            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT128x16x16_...         0.00%       0.000us         0.00%       0.000us       0.000us     393.402us         0.00%     393.402us       9.367us            42            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     389.392us         0.00%     389.392us       4.327us            90            --  
                                    aten::_foreach_norm         0.01%       3.277ms         0.01%       3.601ms       1.801ms     383.577us         0.00%     388.935us     194.468us             2            --  
                         aten::embedding_dense_backward         0.00%     106.816us         0.00%     488.826us      24.441us     372.663us         0.00%     493.243us      24.662us            20            --  
void at::native::(anonymous namespace)::embedding_ba...         0.00%       0.000us         0.00%       0.000us       0.000us     372.663us         0.00%     372.663us      18.633us            20            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x64x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us     372.261us         0.00%     372.261us      15.511us            24            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     364.466us         0.00%     364.466us       3.645us           100            --  
                                     aten::index_select         0.00%     515.157us         0.00%       1.134ms      17.724us     363.776us         0.00%     363.776us       5.684us            64            --  
void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     363.776us         0.00%     363.776us       5.684us            64            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     360.376us         0.00%     360.376us       3.465us           104            --  
                              aten::upsample_bilinear2d         0.00%     205.086us         0.00%     334.641us      11.951us     356.575us         0.00%     356.575us      12.735us            28            --  
void at::native::(anonymous namespace)::upsample_bil...         0.00%       0.000us         0.00%       0.000us       0.000us     356.575us         0.00%     356.575us      12.735us            28            --  
                                               aten::le         0.00%     232.302us         0.00%     424.642us       8.847us     352.474us         0.00%     352.474us       7.343us            48            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us     351.142us         0.00%     351.142us      17.557us            20            --  
                                             aten::topk         0.00%     268.513us         0.00%     478.585us      23.929us     330.211us         0.00%     330.211us      16.511us            20            --  
                                           aten::cumsum         0.00%     502.360us         0.00%     905.160us      23.820us     318.484us         0.00%     336.480us       8.855us            38            --  
                                      aten::logical_and         0.00%     100.698us         0.00%     243.694us       8.703us     301.532us         0.00%     301.532us      10.769us            28            --  
void at::native::vectorized_elementwise_kernel<16, a...         0.00%       0.000us         0.00%       0.000us       0.000us     301.532us         0.00%     301.532us      10.769us            28            --  
          Cijk_SS_BiasS_HAS_ScaleAlphaVec_PostGSU16_VW1         0.00%       0.000us         0.00%       0.000us       0.000us     299.671us         0.00%     299.671us       5.993us            50            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     292.812us         0.00%     292.812us       9.760us            30            --  
                                              aten::all         0.00%     311.395us         0.00%     526.086us      13.152us     269.922us         0.00%     269.922us       6.748us            40            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     269.922us         0.00%     269.922us       6.748us            40            --  
                                SubTensorOpWithScalar1d         0.00%       0.000us         0.00%       0.000us       0.000us     254.841us         0.00%     254.841us       6.371us            40            --  
                                             aten::prod         0.00%     680.377us         0.01%       1.803ms      53.036us     245.368us         0.00%     245.368us       7.217us            34            --  
                                  reduction_prod_kernel         0.00%       0.000us         0.00%       0.000us       0.000us     245.368us         0.00%     245.368us       7.217us            34            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     234.376us         0.00%     234.376us       8.371us            28            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT16x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us     234.096us         0.00%     234.096us       9.364us            25            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     231.815us         0.00%     231.815us       8.279us            28            --  
void at::native::sbtopk::gatherTopK<float, unsigned ...         0.00%       0.000us         0.00%       0.000us       0.000us     207.421us         0.00%     207.421us      10.371us            20            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT32x96x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us     195.108us         0.00%     195.108us      16.259us            12            --  
void at::native::elementwise_kernel<512, 1, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     193.541us         0.00%     193.541us       3.024us            64            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT96x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us     189.549us         0.00%     189.549us      15.796us            12            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     180.881us         0.00%     180.881us       4.522us            40            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT128x16x32_...         0.00%       0.000us         0.00%       0.000us       0.000us     168.467us         0.00%     168.467us      12.959us            13            --  
                                              aten::sin         0.00%     105.337us         0.00%     215.019us       8.959us     162.496us         0.00%     162.496us       6.771us            24            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     158.581us         0.00%     158.581us       2.643us            60            --  
                                              aten::cos         0.00%      97.472us         0.00%     213.838us       8.910us     155.777us         0.00%     155.777us       6.491us            24            --  
void rocprim::detail::single_scan_kernel<false, rocp...         0.00%       0.000us         0.00%       0.000us       0.000us     154.327us         0.00%     154.327us       4.539us            34            --  
void rocprim::detail::partition_kernel<(rocprim::det...         0.00%       0.000us         0.00%       0.000us       0.000us     144.455us         0.00%     144.455us       5.556us            26            --  
                                     hipStreamWaitEvent         0.02%       5.312ms         0.02%       5.312ms       5.228us     143.901us         0.00%     143.901us       0.142us          1016            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     135.370us         0.00%     135.370us       4.512us            30            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     132.906us         0.00%     132.906us       9.493us            14            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT16x64x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us     130.789us         0.00%     130.789us      10.899us            12            --  
void at::native::tensor_kernel_scan_outer_dim<float,...         0.00%       0.000us         0.00%       0.000us       0.000us     128.879us         0.00%     128.879us      64.440us             2            --  
void rocprim::detail::transform_kernel<rocprim::deta...         0.00%       0.000us         0.00%       0.000us       0.000us     127.334us         0.00%     127.334us       4.897us            26            --  
                                              aten::any         0.00%     242.110us         0.00%     562.338us      20.084us     127.140us         0.00%     171.364us       6.120us            28            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     127.140us         0.00%     127.140us       6.357us            20            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     120.106us         0.00%     120.106us       8.579us            14            --  
                                    aten::gelu_backward         0.00%     121.889us         0.00%     215.471us      10.774us     119.700us         0.00%     119.700us       5.985us            20            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     119.700us         0.00%     119.700us       5.985us            20            --  
                                             aten::gelu         0.00%     160.965us         0.00%     263.950us      13.198us     119.420us         0.00%     119.420us       5.971us            20            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     119.420us         0.00%     119.420us       5.971us            20            --  
void at::native::vectorized_elementwise_kernel<16, a...         0.00%       0.000us         0.00%       0.000us       0.000us     119.168us         0.00%     119.168us       3.724us            32            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT16x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us     115.904us         0.00%     115.904us       7.244us            16            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     114.387us         0.00%     114.387us       8.171us            14            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT64x128x16_...         0.00%       0.000us         0.00%       0.000us       0.000us     107.473us         0.00%     107.473us      13.434us             8            --  
void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us     106.390us         0.00%     106.390us       8.866us            12            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x64x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us     104.070us         0.00%     104.070us       8.673us            12            --  
void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us     103.229us         0.00%     103.229us       8.602us            12            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT128x64x32_...         0.00%       0.000us         0.00%       0.000us       0.000us     102.753us         0.00%     102.753us      12.844us             8            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      99.951us         0.00%      99.951us       9.995us            10            --  
void at::native::elementwise_kernel<512, 1, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      97.776us         0.00%      97.776us       4.074us            24            --  
                                     aten::bitwise_and_         0.00%     138.357us         0.00%     228.242us      11.412us      95.103us         0.00%      95.103us       4.755us            20            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      93.815us         0.00%      93.815us       3.608us            26            --  
void at::native::radixSortKVInPlace<-2, -1, 32, 4, f...         0.00%       0.000us         0.00%       0.000us       0.000us      92.875us         0.00%      92.875us      18.575us             5            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      89.891us         0.00%      89.891us       2.996us            30            --  
void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      88.308us         0.00%      88.308us       7.359us            12            --  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      83.700us         0.00%      83.700us       4.185us            20            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      81.290us         0.00%      81.290us       2.710us            30            --  
                          batched_transpose_16x32_dword         0.00%       0.000us         0.00%       0.000us       0.000us      80.431us         0.00%      80.431us       8.043us            10            --  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      79.980us         0.00%      79.980us       3.999us            20            --  
                                  aten::linalg_lu_solve         0.00%     244.016us         0.00%     694.438us      86.805us      78.736us         0.00%     112.640us      14.080us             8            --  
                          batched_transpose_32x16_dword         0.00%       0.000us         0.00%       0.000us       0.000us      77.311us         0.00%      77.311us       7.731us            10            --  
                                          aten::baddbmm         0.00%     413.671us         0.00%     575.590us      71.949us      76.272us         0.00%      92.824us      11.603us             8       491.520  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      75.749us         0.00%      75.749us       6.312us            12            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      74.532us         0.00%      74.532us       2.662us            28            --  
void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us      71.868us         0.00%      71.868us       5.989us            12            --  
void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us      67.868us         0.00%      67.868us       5.656us            12            --  
                          batched_transpose_4x256_dword         0.00%       0.000us         0.00%       0.000us       0.000us      63.750us         0.00%      63.750us       6.375us            10            --  
void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us      60.388us         0.00%      60.388us       5.032us            12            --  
                          batched_transpose_256x4_dword         0.00%       0.000us         0.00%       0.000us       0.000us      60.150us         0.00%      60.150us       6.015us            10            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      58.466us         0.00%      58.466us       4.176us            14            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      55.910us         0.00%      55.910us       5.591us            10            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT256x16x16_...         0.00%       0.000us         0.00%       0.000us       0.000us      55.037us         0.00%      55.037us      18.346us             3            --  
void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us      54.231us         0.00%      54.231us       5.423us            10            --  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      52.030us         0.00%      52.030us       5.203us            10            --  
                              aten::linalg_lu_factor_ex         0.00%     171.102us         0.00%     370.782us      46.348us      51.304us         0.00%      74.536us       9.317us             8            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT256x16x16_...         0.00%       0.000us         0.00%       0.000us       0.000us      50.238us         0.00%      50.238us      16.746us             3            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT16x16x4_MI...         0.00%       0.000us         0.00%       0.000us       0.000us      47.153us         0.00%      47.153us       6.736us             7            --  
                                       aten::bernoulli_         0.00%     130.029us         0.00%     214.694us      21.469us      46.270us         0.00%      46.270us       4.627us            10            --  
void at::cuda::(anonymous namespace)::kernelPointwis...         0.00%       0.000us         0.00%       0.000us       0.000us      46.270us         0.00%      46.270us       4.627us            10            --  
                                         aten::uniform_         0.00%     110.111us         0.00%     203.814us      20.381us      45.790us         0.00%      45.790us       4.579us            10            --  
void at::native::(anonymous namespace)::distribution...         0.00%       0.000us         0.00%       0.000us       0.000us      45.790us         0.00%      45.790us       4.579us            10            --  
void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us      43.518us         0.00%      43.518us      21.759us             2            --  
void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us      43.350us         0.00%      43.350us       4.335us            10            --  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      43.270us         0.00%      43.270us       4.327us            10            --  
void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us      42.390us         0.00%      42.390us       4.239us            10            --  
void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us      41.390us         0.00%      41.390us       4.139us            10            --  
void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us      39.033us         0.00%      39.033us       5.576us             7            --  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      38.953us         0.00%      38.953us       5.565us             7            --  
void at::native::elementwise_kernel<512, 1, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      37.270us         0.00%      37.270us       3.727us            10            --  
void at::native::vectorized_elementwise_kernel<16, a...         0.00%       0.000us         0.00%       0.000us       0.000us      37.227us         0.00%      37.227us       2.659us            14            --  
void rocsolver::v32700::getf2_small_kernel<3, float,...         0.00%       0.000us         0.00%       0.000us       0.000us      35.512us         0.00%      35.512us       4.439us             8            --  
void at::native::tensor_kernel_scan_innermost_dim<fl...         0.00%       0.000us         0.00%       0.000us       0.000us      35.278us         0.00%      35.278us      17.639us             2            --  
void at::native::lpnorm_cleanup<float, (at::native::...         0.00%       0.000us         0.00%       0.000us       0.000us      32.435us         0.00%      32.435us       5.406us             6            --  
void rocsolver::v32700::nonunit_forward_substitution...         0.00%       0.000us         0.00%       0.000us       0.000us      31.752us         0.00%      31.752us       3.969us             8            --  
void at::native::bitonicSortKVInPlace<-2, -1, 16, 16...         0.00%       0.000us         0.00%       0.000us       0.000us      29.915us         0.00%      29.915us       5.983us             5            --  
void rocsolver::v32700::laswp_kernel<float, int, flo...         0.00%       0.000us         0.00%       0.000us       0.000us      25.592us         0.00%      25.592us       3.199us             8            --  
void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us      24.596us         0.00%      24.596us       6.149us             4            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT16x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us      22.637us         0.00%      22.637us       7.546us             3            --  
void rocsolver::v32700::unit_backward_substitution_k...         0.00%       0.000us         0.00%       0.000us       0.000us      21.392us         0.00%      21.392us       2.674us             8            --  
void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us      19.996us         0.00%      19.996us       3.999us             5            --  
                                   hipDeviceSynchronize         0.00%      88.536us         0.00%      88.536us      17.707us      17.699us         0.00%      17.699us       3.540us             5            --  
                                      aten::bitwise_not         0.00%      24.197us         0.00%      51.780us      12.945us      17.076us         0.00%      17.076us       4.269us             4            --  
void rocsolver::v32700::reset_info<int, int, int>(in...         0.00%       0.000us         0.00%       0.000us       0.000us      15.792us         0.00%      15.792us       1.974us             8            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      14.678us         0.00%      14.678us       7.339us             2            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x32x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us      13.918us         0.00%      13.918us       6.959us             2            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT64x16x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us      13.838us         0.00%      13.838us       6.919us             2            --  
                               aten::linalg_vector_norm         0.00%      53.050us         0.00%      72.442us      36.221us      13.798us         0.00%      13.798us       6.899us             2            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      13.798us         0.00%      13.798us       6.899us             2            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT16x64x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us      13.718us         0.00%      13.718us       6.859us             2            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      11.199us         0.00%      11.199us       5.600us             2            --  
                                     aten::floor_divide         0.00%      19.519us         0.00%      38.880us      19.440us      11.198us         0.00%      11.198us       5.599us             2            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      11.198us         0.00%      11.198us       5.599us             2            --  
void at::native::vectorized_elementwise_kernel<16, a...         0.00%       0.000us         0.00%       0.000us       0.000us      10.198us         0.00%      10.198us       5.099us             2            --  
                                       aten::reciprocal         0.00%      17.383us         0.00%      29.501us      14.751us       9.718us         0.00%       9.718us       4.859us             2            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       9.718us         0.00%       9.718us       4.859us             2            --  
void at::native::vectorized_elementwise_kernel<16, a...         0.00%       0.000us         0.00%       0.000us       0.000us       9.438us         0.00%       9.438us       4.719us             2            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       8.598us         0.00%       8.598us       4.299us             2            --  
void at::native::elementwise_kernel<512, 1, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       7.918us         0.00%       7.918us       3.959us             2            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       7.638us         0.00%       7.638us       3.819us             2            --  
void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us       5.959us         0.00%       5.959us       5.959us             1            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       5.958us         0.00%       5.958us       2.979us             2            --  
void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us       4.718us         0.00%       4.718us       2.359us             2            --  
void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us       3.959us         0.00%       3.959us       3.959us             1            --  
                                          ProfilerStep*        26.95%        7.679s        80.39%       22.902s       11.451s       0.000us         0.00%       12.071s        6.036s             2            --  
                                            aten::empty         0.31%      87.363ms         0.31%      87.363ms       1.660us       0.000us         0.00%       0.000us       0.000us         52641            --  
                                               aten::to         0.03%       8.226ms        30.94%        8.816s     581.799us       0.000us         0.00%     126.368ms       8.339us         15153            --  
                                         aten::_to_copy         0.05%      14.347ms        30.92%        8.808s       2.127ms       0.000us         0.00%     126.368ms      30.516us          4141            --  
                                    aten::empty_strided         0.09%      26.875ms         0.10%      27.078ms       2.203us       0.000us         0.00%       0.000us       0.000us         12289            --  
                                    hipMemcpyWithStream        56.95%       16.224s        56.95%       16.224s     134.237us       0.000us         0.00%       0.000us       0.000us        120864            --  
                                       aten::lift_fresh         0.02%       4.505ms         0.02%       4.505ms       0.076us       0.000us         0.00%       0.000us       0.000us         59159            --  
                                          aten::detach_         0.01%       3.139ms         0.01%       4.121ms       1.357us       0.000us         0.00%       0.000us       0.000us          3037            --  
                                                detach_         0.00%     981.402us         0.00%     981.402us       0.323us       0.000us         0.00%       0.000us       0.000us          3037            --  
                                             aten::item         0.25%      72.566ms         5.17%        1.472s      22.295us       0.000us         0.00%     298.462ms       4.521us         66011            --  
enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         0.00%     385.044us         0.00%     385.044us     192.522us       0.000us         0.00%       0.000us       0.000us             2            --  
                                         hipMemcpyAsync         0.58%     164.945ms         0.58%     164.945ms      12.262us       0.000us         0.00%       0.000us       0.000us         13452            --  
                                    aten::record_stream         0.00%     101.544us         0.00%     101.544us       0.769us       0.000us         0.00%       0.000us       0.000us           132            --  
                                                Scatter         0.01%       1.737ms         0.02%       6.418ms     200.553us       0.000us         0.00%     710.372us      22.199us            32            --  
                                            aten::chunk         0.01%       1.683ms         0.06%      15.858ms      21.663us       0.000us         0.00%       0.000us       0.000us           732            --  
                                            aten::split         0.02%       5.227ms         0.05%      14.416ms      19.324us       0.000us         0.00%       0.000us       0.000us           746            --  
                                           aten::narrow         0.02%       6.565ms         0.06%      16.633ms       4.196us       0.000us         0.00%       0.000us       0.000us          3964            --  
                                            aten::slice         0.18%      50.311ms         0.21%      60.585ms       2.873us       0.000us         0.00%       0.000us       0.000us         21090            --  
                                       aten::as_strided         0.57%     161.386ms         0.57%     161.386ms       0.578us       0.000us         0.00%       0.000us       0.000us        279392            --  
                                           aten::linear         0.09%      24.557ms         0.82%     234.005ms      58.414us       0.000us         0.00%     954.189ms     238.190us          4006            --  
                                                aten::t         0.09%      25.973ms         0.20%      58.379ms       3.386us       0.000us         0.00%       0.000us       0.000us         17242            --  
                                        aten::transpose         0.10%      27.398ms         0.13%      36.716ms       1.952us       0.000us         0.00%       0.000us       0.000us         18810            --  
                            hipGetDevicePropertiesR0600         0.10%      27.423ms         0.10%      27.423ms       0.437us       0.000us         0.00%       0.000us       0.000us         62780            --  
                               hipExtModuleLaunchKernel         0.37%     105.188ms         0.37%     105.188ms       5.131us       0.000us         0.00%       0.000us       0.000us         20500            --  
                                            aten::zeros         0.05%      13.279ms         0.22%      63.980ms      11.578us       0.000us         0.00%      71.011ms      12.850us          5526            --  
                                            aten::zero_         0.05%      13.863ms         0.26%      73.972ms       7.322us       0.000us         0.00%     130.642ms      12.932us         10102            --  
                                        hipLaunchKernel         2.18%     620.050ms         2.18%     620.050ms       4.703us       0.000us         0.00%       0.000us       0.000us        131850            --  
                                             aten::full         0.00%     339.270us         0.00%       1.077ms      12.822us       0.000us         0.00%     197.197us       2.348us            84            --  
                                             aten::ones         0.01%       1.898ms         0.03%       8.823ms      16.584us       0.000us         0.00%       3.071ms       5.772us           532            --  
                                           aten::unbind         0.01%       2.822ms         0.03%       7.797ms      18.744us       0.000us         0.00%       0.000us       0.000us           416            --  
                                           aten::select         1.60%     455.069ms         1.98%     563.780ms       2.783us       0.000us         0.00%       0.000us       0.000us        202556            --  
                                            aten::stack         0.03%       7.798ms         0.10%      27.757ms      32.887us       0.000us         0.00%      13.136ms      15.564us           844            --  
                                             aten::view         0.21%      59.282ms         0.21%      59.282ms       0.790us       0.000us         0.00%       0.000us       0.000us         75018            --  
                                          aten::reshape         0.10%      27.897ms         0.19%      53.351ms       2.241us       0.000us         0.00%       6.225ms       0.261us         23810            --  
                                           aten::conv2d         0.02%       6.179ms         1.10%     312.759ms     140.882us       0.000us         0.00%        2.947s       1.327ms          2220  64263359692.800  
                                      aten::convolution         0.03%       8.414ms         1.08%     306.580ms     138.099us       0.000us         0.00%        2.947s       1.327ms          2220            --  
                                     aten::_convolution         0.04%      10.378ms         1.05%     298.166ms     134.309us       0.000us         0.00%        2.947s       1.327ms          2220            --  
                                          aten::resize_         0.04%      11.350ms         0.04%      11.350ms       1.009us       0.000us         0.00%       0.000us       0.000us         11244            --  
                                  hipDeviceGetAttribute         0.01%       2.051ms         0.01%       2.051ms       0.440us       0.000us         0.00%       0.000us       0.000us          4660            --  
                                       aten::batch_norm         0.02%       4.721ms         0.29%      82.361ms      39.597us       0.000us         0.00%     441.671ms     212.342us          2080            --  
                           aten::_batch_norm_impl_index         0.03%       9.224ms         0.27%      77.640ms      37.327us       0.000us         0.00%     441.671ms     212.342us          2080            --  
                                            aten::relu_         0.03%       7.528ms         0.09%      26.817ms      10.901us       0.000us         0.00%     690.697ms     280.771us          2460            --  
                                       aten::max_pool2d         0.00%     108.026us         0.00%     543.377us      27.169us       0.000us         0.00%      46.128ms       2.306ms            20            --  
                                        aten::new_empty         0.03%       7.251ms         0.06%      16.915ms       3.458us       0.000us         0.00%       0.000us       0.000us          4892            --  
                                          aten::type_as         0.01%       2.525ms         0.01%       2.969ms       1.427us       0.000us         0.00%       0.000us       0.000us          2080            --  
                                          aten::flatten         0.04%      10.994ms         0.06%      17.807ms       1.719us       0.000us         0.00%       0.000us       0.000us         10362            --  
                                          aten::view_as         0.02%       4.377ms         0.03%       7.841ms       1.568us       0.000us         0.00%       0.000us       0.000us          5000            --  
                                        aten::embedding         0.00%     301.634us         0.01%       1.436ms      22.437us       0.000us         0.00%     363.776us       5.684us            64            --  
                                        aten::unsqueeze         0.06%      17.258ms         0.08%      21.524ms       2.368us       0.000us         0.00%       0.000us       0.000us          9090            --  
                                           aten::repeat         0.01%       2.512ms         0.04%      12.151ms      45.002us       0.000us         0.00%      23.301ms      86.300us           270            --  
                                           aten::expand         0.01%       4.236ms         0.02%       5.426ms       2.746us       0.000us         0.00%       0.000us       0.000us          1976            --  
                                            aten::alias         0.00%     258.803us         0.00%     258.803us       0.959us       0.000us         0.00%       0.000us       0.000us           270            --  
                                           aten::unfold         0.01%       1.809ms         0.01%       2.654ms       2.602us       0.000us         0.00%       0.000us       0.000us          1020            --  
                                        aten::expand_as         0.00%     442.049us         0.00%       1.293ms       4.199us       0.000us         0.00%       0.000us       0.000us           308            --  
                                          aten::permute         0.04%      10.333ms         0.04%      12.466ms       3.595us       0.000us         0.00%       0.000us       0.000us          3468            --  
                                       aten::layer_norm         0.01%       2.905ms         0.11%      30.219ms      28.084us       0.000us         0.00%     138.506ms     128.723us          1076            --  
                                        aten::new_zeros         0.02%       6.304ms         0.11%      32.182ms      13.824us       0.000us         0.00%      25.122ms      10.791us          2328            --  
                                       hipCtxGetCurrent         0.00%       8.070us         0.00%       8.070us       0.237us       0.000us         0.00%       0.000us       0.000us            34            --  
                                  hipModuleLaunchKernel         0.00%       1.090ms         0.00%       1.090ms      32.070us       0.000us         0.00%       0.000us       0.000us            34            --  
                                   aten::_reshape_alias         0.01%       1.704ms         0.01%       1.704ms       1.572us       0.000us         0.00%       0.000us       0.000us          1084            --  
                                         aten::meshgrid         0.00%     257.766us         0.00%     564.518us      16.603us       0.000us         0.00%       0.000us       0.000us            34            --  
                                            aten::clone         0.03%       9.867ms         0.16%      45.091ms      12.766us       0.000us         0.00%      82.489ms      23.355us          3532            --  
                                       aten::empty_like         0.05%      13.375ms         0.11%      31.848ms       3.462us       0.000us         0.00%       0.000us       0.000us          9200            --  
                                     aten::_unsafe_view         0.00%     684.414us         0.00%     684.414us       1.347us       0.000us         0.00%       0.000us       0.000us           508            --  
                                        aten::ones_like         0.00%     625.315us         0.01%       3.599ms      13.530us       0.000us         0.00%     736.656us       2.769us           266            --  
                                           aten::matmul         0.00%       1.291ms         0.04%      12.296ms      72.328us       0.000us         0.00%     816.151ms       4.801ms           170            --  
                                          aten::squeeze         0.02%       6.213ms         0.03%       7.312ms       2.680us       0.000us         0.00%       0.000us       0.000us          2728            --  
                                          aten::__and__         0.00%     342.457us         0.01%       2.837ms      13.015us       0.000us         0.00%       1.628ms       7.468us           218            --  
                                       aten::is_nonzero         0.00%     903.592us         0.27%      77.717ms     154.199us       0.000us         0.00%       7.404ms      14.691us           504            --  
                                          aten::softmax         0.00%       1.087ms         0.03%       9.066ms      15.366us       0.000us         0.00%      32.984ms      55.904us           590            --  
                                       aten::contiguous         0.00%       1.086ms         0.04%      11.823ms      18.302us       0.000us         0.00%      44.595ms      69.033us           646            --  
                                          aten::dropout         0.01%       1.482ms         0.06%      16.556ms      11.742us       0.000us         0.00%      17.408ms      12.346us          1410            --  
                                       aten::zeros_like         0.01%       3.612ms         0.08%      22.375ms      13.208us       0.000us         0.00%      22.202ms      13.106us          1694            --  
                                         hipMemsetAsync         0.17%      47.793ms         0.17%      47.793ms       8.923us       0.000us         0.00%       0.000us       0.000us          5356            --  
                                             aten::set_         0.03%       8.255ms         0.03%       8.255ms       1.937us       0.000us         0.00%       0.000us       0.000us          4262            --  
                                       aten::index_put_         0.02%       4.894ms         0.17%      48.371ms      23.596us       0.000us         0.00%      41.731ms      20.357us          2050            --  
                                             aten::rsub         0.01%       1.726ms         0.05%      13.343ms      31.322us       0.000us         0.00%       2.049ms       4.809us           426            --  
                                       aten::unsqueeze_         0.00%     110.697us         0.00%     183.611us       8.346us       0.000us         0.00%       0.000us       0.000us            22            --  
                                      aten::as_strided_         0.00%     148.404us         0.00%     148.404us       2.559us       0.000us         0.00%       0.000us       0.000us            58            --  
                                     aten::grid_sampler         0.00%      85.114us         0.00%     514.677us      23.394us       0.000us         0.00%      11.062ms     502.824us            22            --  
                                   hipStreamIsCapturing         0.00%     577.082us         0.00%     577.082us       0.327us       0.000us         0.00%       0.000us       0.000us          1763            --  
                                             aten::relu         0.01%       1.668ms         0.02%       5.939ms      11.644us       0.000us         0.00%       2.409ms       4.724us           510            --  
                                           aten::detach         0.01%       2.411ms         0.02%       5.388ms       2.167us       0.000us         0.00%       0.000us       0.000us          2486            --  
                                                 detach         0.01%       2.978ms         0.01%       2.978ms       1.198us       0.000us         0.00%       0.000us       0.000us          2486            --  
                                       aten::linalg_inv         0.00%      63.425us         0.01%       2.412ms     301.545us       0.000us         0.00%     421.388us      52.674us             8            --  
                                    aten::linalg_inv_ex         0.00%     131.262us         0.01%       1.681ms     210.071us       0.000us         0.00%     219.201us      27.400us             8            --  
                                         aten::diagonal         0.00%      21.919us         0.00%      27.144us       3.393us       0.000us         0.00%       0.000us       0.000us             8            --  
                                  aten::linalg_solve_ex         0.00%      55.827us         0.00%       1.397ms     174.630us       0.000us         0.00%     187.176us      23.397us             8            --  
                                 aten::_linalg_solve_ex         0.00%     149.580us         0.00%       1.308ms     163.511us       0.000us         0.00%     187.176us      23.397us             8            --  
                                               aten::mT         0.00%      20.528us         0.00%      55.017us       3.439us       0.000us         0.00%       0.000us       0.000us            16            --  
                             aten::_linalg_check_errors         0.00%      45.904us         0.00%     668.368us      83.546us       0.000us         0.00%     202.187us      25.273us             8            --  
                                     aten::resolve_conj         0.00%      40.391us         0.00%      40.391us       0.301us       0.000us         0.00%       0.000us       0.000us           134            --  
                                      aten::resolve_neg         0.00%      25.999us         0.00%      25.999us       0.194us       0.000us         0.00%       0.000us       0.000us           134            --  
                                         aten::new_full         0.00%     496.438us         0.01%       2.345ms      14.473us       0.000us         0.00%     404.763us       2.499us           162            --  
                                      aten::result_type         0.00%       1.275ms         0.00%       1.275ms       0.099us       0.000us         0.00%       0.000us       0.000us         12906            --  
                                            aten::cdist         0.00%     231.049us         0.02%       4.736ms      64.006us       0.000us         0.00%       6.545ms      88.448us            74            --  
                                              aten::min         0.00%     225.408us         0.01%       1.690ms      13.202us       0.000us         0.00%     596.281us       4.658us           128            --  
                                        aten::full_like         0.00%     513.108us         0.01%       2.632ms      14.620us       0.000us         0.00%     369.061us       2.050us           180            --  
                                       c10d::allreduce_         0.02%       5.758ms         0.09%      24.313ms      55.006us       0.000us         0.00%       0.000us       0.000us           442            --  
                                     record_param_comms         0.05%      15.075ms         0.07%      19.331ms      22.220us       0.000us         0.00%       0.000us       0.000us           870            --  
                                        nccl:all_reduce         0.00%       0.000us             0       9.530ms      21.560us       0.000us         0.00%       0.000us       0.000us           442            --  
                      hipOccupancyMaxPotentialBlockSize         0.00%      11.430us         0.00%      11.430us       2.286us       0.000us         0.00%       0.000us       0.000us             5            --  
                                         aten::__iand__         0.00%      35.820us         0.00%     264.062us      13.203us       0.000us         0.00%      95.103us       4.755us            20            --  
                                        aten::rand_like         0.00%      40.173us         0.00%     302.615us      30.261us       0.000us         0.00%      45.790us       4.579us            10            --  
                                        aten::bernoulli         0.00%      54.483us         0.00%     303.944us      30.394us       0.000us         0.00%      46.270us       4.627us            10            --  
                                          aten::argsort         0.00%      28.941us         0.00%     703.376us      70.338us       0.000us         0.00%     677.194us      67.719us            10            --  
                                    aten::scalar_tensor         0.00%     270.645us         0.00%       1.248ms       9.905us       0.000us         0.00%     385.800us       3.062us           126            --  
                                      aten::masked_fill         0.00%     376.367us         0.01%       1.976ms      41.160us       0.000us         0.00%       4.714ms      98.211us            48            --  
                                 aten::split_with_sizes         0.00%     673.306us         0.00%     799.669us      10.522us       0.000us         0.00%       0.000us       0.000us            76            --  
                                         aten::new_ones         0.00%      44.909us         0.00%     160.107us      11.436us       0.000us         0.00%      29.746us       2.125us            14            --  
torch.distributed.ddp.reducer::search_unused_paramet...         0.03%       8.128ms         0.03%       8.128ms       4.064ms       0.000us         0.00%       0.000us       0.000us             2            --  
                    Optimizer.zero_grad#AdamW.zero_grad         0.02%       5.532ms         0.02%       5.532ms       2.766ms       0.000us         0.00%       0.000us       0.000us             2            --  
      autograd::engine::evaluate_function: AddBackward0         0.03%       9.562ms         0.06%      17.225ms       7.989us       0.000us         0.00%      23.178ms      10.751us          2156            --  
                                           AddBackward0         0.00%       1.026ms         0.00%       1.026ms       0.447us       0.000us         0.00%       0.000us       0.000us          2296            --  
     autograd::engine::evaluate_function: MeanBackward0         0.00%     689.837us         0.02%       4.452ms      16.132us       0.000us         0.00%       1.015ms       3.676us           276            --  
                                          MeanBackward0         0.00%     566.380us         0.01%       3.763ms      13.632us       0.000us         0.00%       1.015ms       3.676us           276            --  
autograd::engine::evaluate_function: NanToNumBackwar...         0.00%       1.297ms         0.05%      14.192ms      51.421us       0.000us         0.00%       4.611ms      16.706us           276            --  
                                      NanToNumBackward0         0.00%     739.270us         0.05%      12.896ms      46.724us       0.000us         0.00%       4.611ms      16.706us           276            --  
                                         aten::isfinite         0.01%       1.536ms         0.04%      10.324ms      37.406us       0.000us         0.00%       3.947ms      14.301us           276            --  
      autograd::engine::evaluate_function: MulBackward0         0.02%       6.667ms         0.08%      23.937ms      15.404us       0.000us         0.00%      10.086ms       6.491us          1554            --  
                                           MulBackward0         0.01%       3.461ms         0.06%      16.767ms      10.790us       0.000us         0.00%       9.091ms       5.850us          1554            --  
      autograd::engine::evaluate_function: DivBackward0         0.01%       3.861ms         0.06%      16.438ms      25.057us       0.000us         0.00%      39.755ms      60.603us           656            --  
                                           DivBackward0         0.01%       1.995ms         0.04%      11.274ms      17.186us       0.000us         0.00%      39.296ms      59.902us           656            --  
      autograd::engine::evaluate_function: SumBackward0         0.00%     830.417us         0.01%       2.026ms       7.340us       0.000us         0.00%       0.000us       0.000us           276            --  
                                           SumBackward0         0.00%     387.422us         0.00%       1.195ms       4.331us       0.000us         0.00%       0.000us       0.000us           276            --  
autograd::engine::evaluate_function: SigmoidFocalLos...         0.00%     888.964us         0.03%       7.736ms      84.086us       0.000us         0.00%       1.160ms      12.611us            92            --  
     autograd::engine::evaluate_function: RsubBackward1         0.00%     211.627us         0.00%     802.627us      11.148us       0.000us         0.00%     356.449us       4.951us            72            --  
                                          RsubBackward1         0.00%      86.593us         0.00%     591.000us       8.208us       0.000us         0.00%     356.449us       4.951us            72            --  
      autograd::engine::evaluate_function: SumBackward1         0.00%     130.726us         0.00%     458.591us       9.554us       0.000us         0.00%       0.000us       0.000us            48            --  
                                           SumBackward1         0.00%     106.765us         0.00%     327.865us       6.831us       0.000us         0.00%       0.000us       0.000us            48            --  
     autograd::engine::evaluate_function: ViewBackward0         0.07%      19.276ms         0.17%      47.888ms       7.731us       0.000us         0.00%      32.616ms       5.266us          6194            --  
                                          ViewBackward0         0.03%       7.360ms         0.09%      24.549ms       3.963us       0.000us         0.00%       5.876ms       0.949us          6194            --  
autograd::engine::evaluate_function: SqueezeBackward...         0.00%      93.044us         0.00%     224.262us       7.008us       0.000us         0.00%       0.000us       0.000us            32            --  
                                       SqueezeBackward1         0.00%      36.929us         0.00%     131.218us       4.101us       0.000us         0.00%       0.000us       0.000us            32            --  
autograd::engine::evaluate_function: UpsampleBilinea...         0.00%      94.749us         0.00%     554.371us      23.099us       0.000us         0.00%       4.847ms     201.976us            24            --  
                            UpsampleBilinear2DBackward0         0.00%      43.662us         0.00%     459.622us      19.151us       0.000us         0.00%       4.847ms     201.976us            24            --  
autograd::engine::evaluate_function: UnsqueezeBackwa...         0.01%       2.082ms         0.02%       5.084ms       7.894us       0.000us         0.00%     828.942us       1.287us           644            --  
                                     UnsqueezeBackward0         0.00%     793.813us         0.01%       2.624ms       4.074us       0.000us         0.00%       0.000us       0.000us           644            --  
      autograd::engine::evaluate_function: AbsBackward0         0.00%     823.629us         0.01%       3.806ms      27.186us       0.000us         0.00%       1.313ms       9.381us           140            --  
                                           AbsBackward0         0.00%     617.203us         0.01%       2.982ms      21.303us       0.000us         0.00%       1.313ms       9.381us           140            --  
      autograd::engine::evaluate_function: SubBackward0         0.00%       1.307ms         0.01%       3.367ms       9.565us       0.000us         0.00%       1.331ms       3.780us           352            --  
                                           SubBackward0         0.00%     308.129us         0.01%       1.535ms       4.361us       0.000us         0.00%     926.185us       2.631us           352            --  
autograd::engine::evaluate_function: MaximumBackward...         0.00%     420.684us         0.02%       4.280ms      53.496us       0.000us         0.00%       2.260ms      28.244us            80            --  
                                       MaximumBackward0         0.00%     601.587us         0.01%       3.859ms      48.237us       0.000us         0.00%       2.260ms      28.244us            80            --  
autograd::engine::evaluate_function: SelectBackward0...         0.04%       9.987ms         0.26%      74.535ms      32.294us       0.000us         0.00%     170.607ms      73.920us          2308            --  
                                        SelectBackward0         0.01%       3.649ms         0.20%      55.603ms      24.091us       0.000us         0.00%      77.417ms      33.543us          2308            --  
                                  aten::select_backward         0.03%       7.415ms         0.18%      51.954ms      22.510us       0.000us         0.00%      77.417ms      33.543us          2308            --  
    autograd::engine::evaluate_function: ClampBackward1         0.00%     669.765us         0.02%       6.077ms      49.004us       0.000us         0.00%       2.909ms      23.460us           124            --  
                                         ClampBackward1         0.00%     776.128us         0.02%       5.240ms      42.261us       0.000us         0.00%       2.772ms      22.358us           124            --  
    autograd::engine::evaluate_function: SliceBackward0         0.02%       5.159ms         0.15%      41.748ms      30.607us       0.000us         0.00%      30.692ms      22.502us          1364            --  
                                         SliceBackward0         0.01%       2.398ms         0.12%      33.897ms      24.851us       0.000us         0.00%      19.800ms      14.516us          1364            --  
                                   aten::slice_backward         0.02%       5.380ms         0.11%      31.499ms      23.093us       0.000us         0.00%      19.800ms      14.516us          1364            --  
autograd::engine::evaluate_function: MinimumBackward...         0.00%     157.045us         0.01%       2.071ms      51.766us       0.000us         0.00%       1.121ms      28.015us            40            --  
                                       MinimumBackward0         0.00%     357.069us         0.01%       1.914ms      47.840us       0.000us         0.00%       1.121ms      28.015us            40            --  
      autograd::engine::evaluate_function: CatBackward0         0.01%       1.608ms         0.02%       6.066ms      17.736us       0.000us         0.00%      46.314us       0.135us           342            --  
                                           CatBackward0         0.00%       1.023ms         0.02%       4.415ms      12.910us       0.000us         0.00%       0.000us       0.000us           342            --  
autograd::engine::evaluate_function: SplitWithSizesB...         0.00%     117.260us         0.00%     590.639us      29.532us       0.000us         0.00%     204.363us      10.218us            20            --  
                                SplitWithSizesBackward0         0.00%      49.166us         0.00%     357.250us      17.862us       0.000us         0.00%     101.583us       5.079us            20            --  
    autograd::engine::evaluate_function: AddmmBackward0         0.09%      26.876ms         1.01%     287.593ms     123.114us       0.000us         0.00%     818.435ms     350.357us          2336            --  
                                         AddmmBackward0         0.07%      20.371ms         0.75%     212.585ms      91.004us       0.000us         0.00%     718.072ms     307.394us          2336            --  
autograd::engine::evaluate_function: torch::autograd...         0.06%      15.784ms         0.17%      48.356ms      22.745us       0.000us         0.00%      12.310ms       5.790us          2126            --  
                        torch::autograd::AccumulateGrad         0.01%       2.693ms         0.02%       6.572ms       3.091us       0.000us         0.00%       0.000us       0.000us          2126            --  
                   torch::distributed::reducer::mul_out         0.01%       3.438ms         0.07%      19.058ms       8.964us       0.000us         0.00%      12.253ms       5.763us          2126            --  
        autograd::engine::evaluate_function: TBackward0         0.03%       9.900ms         0.10%      27.348ms      11.462us       0.000us         0.00%       6.255ms       2.621us          2386            --  
                                             TBackward0         0.01%       2.464ms         0.03%       9.196ms       3.854us       0.000us         0.00%       0.000us       0.000us          2386            --  
autograd::engine::evaluate_function: torch::autograd...         0.03%       9.934ms         0.34%      95.900ms      63.594us       0.000us         0.00%     110.759ms      73.448us          1508            --  
                            torch::autograd::CopySlices         0.04%      12.542ms         0.30%      85.745ms      56.860us       0.000us         0.00%     110.638ms      73.367us          1508            --  
                                aten::new_empty_strided         0.01%       2.378ms         0.02%       5.205ms       3.452us       0.000us         0.00%       0.000us       0.000us          1508            --  
                         torch::autograd::CopyBackwards         0.01%       2.060ms         0.04%      11.248ms      13.018us       0.000us         0.00%       3.520ms       4.074us           864            --  
autograd::engine::evaluate_function: SigmoidBackward...         0.00%     832.106us         0.01%       2.683ms      15.784us       0.000us         0.00%       1.041ms       6.124us           170            --  
                                       SigmoidBackward0         0.00%     425.094us         0.01%       1.851ms      10.890us       0.000us         0.00%       1.041ms       6.124us           170            --  
autograd::engine::evaluate_function: AsStridedBackwa...         0.01%       2.951ms         0.09%      25.930ms      39.648us       0.000us         0.00%      13.130ms      20.077us           654            --  
                                     AsStridedBackward0         0.02%       5.262ms         0.07%      20.610ms      31.513us       0.000us         0.00%      10.931ms      16.713us           654            --  
     autograd::engine::evaluate_function: ReluBackward0         0.01%       2.407ms         0.03%       7.501ms      15.063us       0.000us         0.00%       2.974ms       5.971us           498            --  
                                          ReluBackward0         0.01%       1.526ms         0.02%       7.089ms      11.042us       0.000us         0.00%       8.786ms      13.685us           642            --  
    autograd::engine::evaluate_function: StackBackward0         0.00%     518.468us         0.01%       1.539ms      25.646us       0.000us         0.00%     799.554us      13.326us            60            --  
                                         StackBackward0         0.00%     251.010us         0.00%     962.757us      16.046us       0.000us         0.00%       0.000us       0.000us            60            --  
autograd::engine::evaluate_function: UnsafeViewBackw...         0.00%     408.194us         0.00%       1.072ms       8.246us       0.000us         0.00%      22.874us       0.176us           130            --  
                                    UnsafeViewBackward0         0.00%     207.504us         0.00%     663.742us       5.106us       0.000us         0.00%      22.874us       0.176us           130            --  
       autograd::engine::evaluate_function: MmBackward0         0.00%     545.590us         0.02%       6.284ms      95.208us       0.000us         0.00%     452.364ms       6.854ms            66            --  
                                            MmBackward0         0.00%     499.169us         0.02%       5.738ms      86.941us       0.000us         0.00%     452.364ms       6.854ms            66            --  
autograd::engine::evaluate_function: ReshapeAliasBac...         0.00%     660.342us         0.01%       1.704ms      10.651us       0.000us         0.00%     433.093us       2.707us           160            --  
                                  ReshapeAliasBackward0         0.00%     257.665us         0.00%     717.126us       4.482us       0.000us         0.00%       0.000us       0.000us           160            --  
autograd::engine::evaluate_function: PermuteBackward...         0.01%       3.269ms         0.03%       8.661ms       8.929us       0.000us         0.00%      20.354ms      20.984us           970            --  
                                       PermuteBackward0         0.01%       1.514ms         0.02%       4.561ms       4.702us       0.000us         0.00%       0.000us       0.000us           970            --  
      autograd::engine::evaluate_function: BmmBackward0         0.01%       1.886ms         0.07%      20.820ms      88.972us       0.000us         0.00%      22.485ms      96.091us           234            --  
                                           BmmBackward0         0.01%       1.690ms         0.07%      18.933ms      80.911us       0.000us         0.00%      22.485ms      96.091us           234            --  
autograd::engine::evaluate_function: ExpandBackward0...         0.00%     462.705us         0.00%     542.757us       3.119us       0.000us         0.00%       0.000us       0.000us           174            --  
                                        ExpandBackward0         0.00%      80.052us         0.00%      80.052us       0.460us       0.000us         0.00%       0.000us       0.000us           174            --  
    autograd::engine::evaluate_function: CloneBackward0         0.00%     707.621us         0.00%     798.454us       3.119us       0.000us         0.00%       0.000us       0.000us           256            --  
                                         CloneBackward0         0.00%      90.833us         0.00%      90.833us       0.355us       0.000us         0.00%       0.000us       0.000us           256            --  
autograd::engine::evaluate_function: TransposeBackwa...         0.01%       1.564ms         0.01%       3.425ms       6.689us       0.000us         0.00%      17.354us       0.034us           512            --  
                                     TransposeBackward0         0.00%     545.985us         0.01%       1.798ms       3.513us       0.000us         0.00%       0.000us       0.000us           512            --  
autograd::engine::evaluate_function: NativeLayerNorm...         0.03%       8.743ms         0.14%      39.653ms      61.383us       0.000us         0.00%      69.566ms     107.688us           646            --  
                               NativeLayerNormBackward0         0.01%       3.072ms         0.09%      26.096ms      40.396us       0.000us         0.00%      65.612ms     101.566us           646            --  
     autograd::engine::evaluate_function: GeluBackward0         0.00%     109.923us         0.00%     376.113us      18.806us       0.000us         0.00%     119.700us       5.985us            20            --  
                                          GeluBackward0         0.00%      50.719us         0.00%     266.190us      13.310us       0.000us         0.00%     119.700us       5.985us            20            --  
autograd::engine::evaluate_function: SoftmaxBackward...         0.01%       1.828ms         0.04%      12.095ms      37.561us       0.000us         0.00%      18.057ms      56.078us           322            --  
                                       SoftmaxBackward0         0.00%       1.187ms         0.04%      10.267ms      31.884us       0.000us         0.00%      18.057ms      56.078us           322            --  
    autograd::engine::evaluate_function: IndexBackward0         0.02%       6.185ms        13.43%        3.826s       3.665ms       0.000us         0.00%     104.593ms     100.185us          1044            --  
                                         IndexBackward0         0.01%       4.118ms        13.41%        3.820s       3.659ms       0.000us         0.00%     104.267ms      99.872us          1044            --  
                                          aten::divide_         0.00%       1.087ms         0.04%      10.019ms       9.597us       0.000us         0.00%       5.786ms       5.542us          1044            --  
    autograd::engine::evaluate_function: SplitBackward0         0.00%       1.193ms         0.02%       5.128ms      27.571us       0.000us         0.00%       1.628ms       8.753us           186            --  
                                         SplitBackward0         0.00%     508.790us         0.01%       3.158ms      16.977us       0.000us         0.00%     986.425us       5.303us           186            --  
autograd::engine::evaluate_function: UnbindBackward0...         0.00%      31.559us         0.00%     112.631us      28.158us       0.000us         0.00%      27.276us       6.819us             4            --  
                                        UnbindBackward0         0.00%       9.749us         0.00%      81.072us      20.268us       0.000us         0.00%      27.276us       6.819us             4            --  
      autograd::engine::evaluate_function: LogBackward0         0.00%     171.619us         0.00%     520.246us      18.580us       0.000us         0.00%     160.052us       5.716us            28            --  
                                           LogBackward0         0.00%      74.342us         0.00%     348.627us      12.451us       0.000us         0.00%     160.052us       5.716us            28            --  
                                     aten::logical_and_         0.00%      67.968us         0.00%     311.662us      11.131us       0.000us         0.00%     301.532us      10.769us            28            --  
autograd::engine::evaluate_function: NativeDropoutBa...         0.01%       3.124ms         0.04%      11.650ms      18.317us       0.000us         0.00%      15.533ms      24.422us           636            --  
                                 NativeDropoutBackward0         0.00%       1.298ms         0.03%       8.525ms      13.405us       0.000us         0.00%      15.533ms      24.422us           636            --  
autograd::engine::evaluate_function: MultiScaleDefor...         0.00%     289.786us         0.01%       2.982ms     124.266us       0.000us         0.00%      34.716ms       1.447ms            24            --  
autograd::engine::evaluate_function: MaskedFillBackw...         0.00%     121.813us         0.00%       1.098ms      45.769us       0.000us         0.00%       2.425ms     101.039us            24            --  
                                    MaskedFillBackward0         0.00%      50.207us         0.00%     976.632us      40.693us       0.000us         0.00%       2.425ms     101.039us            24            --  
autograd::engine::evaluate_function: MultiScaleDefor...         0.01%       3.127ms         0.11%      30.910ms     171.723us       0.000us         0.00%        2.533s      14.071ms           180            --  
                                      IndexPutBackward0         0.01%       2.085ms         0.08%      21.786ms      58.564us       0.000us         0.00%      28.210ms      75.834us           372            --  
                                        aten::index_put         0.00%     975.610us         0.03%       9.780ms      31.548us       0.000us         0.00%      15.906ms      51.310us           310            --  
     autograd::engine::evaluate_function: MeanBackward1         0.00%     275.962us         0.01%       2.149ms      35.823us       0.000us         0.00%       8.821ms     147.021us            60            --  
                                          MeanBackward1         0.00%     345.784us         0.01%       1.873ms      31.224us       0.000us         0.00%       8.821ms     147.021us            60            --  
autograd::engine::evaluate_function: RepeatBackward0...         0.00%     132.955us         0.00%     510.307us      12.758us       0.000us         0.00%     471.861us      11.797us            40            --  
                                        RepeatBackward0         0.00%      67.252us         0.00%     377.352us       9.434us       0.000us         0.00%     471.861us      11.797us            40            --  
autograd::engine::evaluate_function: EmbeddingBackwa...         0.00%     148.085us         0.00%     823.779us      41.189us       0.000us         0.00%     590.388us      29.519us            20            --  
                                     EmbeddingBackward0         0.00%      44.635us         0.00%     571.442us      28.572us       0.000us         0.00%     493.243us      24.662us            20            --  
                               aten::embedding_backward         0.00%      37.981us         0.00%     526.807us      26.340us       0.000us         0.00%     493.243us      24.662us            20            --  
autograd::engine::evaluate_function: ConvolutionBack...         0.00%     996.013us         0.09%      25.946ms     370.662us       0.000us         0.00%     774.455ms      11.064ms            70            --  
                                   ConvolutionBackward0         0.00%     364.747us         0.08%      24.084ms     344.052us       0.000us         0.00%     773.213ms      11.046ms            70            --  
autograd::engine::evaluate_function: UpsampleNearest...         0.00%     125.460us         0.00%     548.933us      27.447us       0.000us         0.00%       2.937ms     146.829us            20            --  
                             UpsampleNearest2DBackward0         0.00%      44.861us         0.00%     288.232us      14.412us       0.000us         0.00%       2.016ms     100.798us            20            --  
autograd::engine::evaluate_function: IndexPutBackwar...         0.00%      90.160us         0.01%       3.186ms     265.464us       0.000us         0.00%       1.087ms      90.563us            12            --  
autograd::engine::evaluate_function: BaddbmmBackward...         0.00%      75.500us         0.00%     721.978us     120.330us       0.000us         0.00%     113.189us      18.865us             6            --  
                                       BaddbmmBackward0         0.00%      54.233us         0.00%     646.478us     107.746us       0.000us         0.00%     113.189us      18.865us             6            --  
                                        aten::is_pinned         0.00%      11.864us         0.00%      15.674us       7.837us       0.000us         0.00%       0.000us       0.000us             2            --  
                                hipPointerGetAttributes         0.00%       3.810us         0.00%       3.810us       1.905us       0.000us         0.00%       0.000us       0.000us             2            --  
     torch.distributed.ddp.reducer::copy_bucket_to_grad         0.01%       3.249ms         0.06%      18.097ms       8.504us       0.000us         0.00%       8.952ms       4.207us          2128            --  
                              Optimizer.step#AdamW.step         0.61%     173.772ms         1.19%     339.161ms     169.581ms       0.000us         0.00%     136.251ms      68.126ms             2            --  
                                              hipMalloc         0.00%     974.358us         0.00%     974.358us     139.194us       0.000us         0.00%       0.000us       0.000us             7            --  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
Self CPU time total: 28.490s
Self CUDA time total: 17.434s

2025-05-12 07:56:53,630 - mmdet - INFO - -------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  Total KFLOPs  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                          ProfilerStep*         0.00%       0.000us         0.00%       0.000us       0.000us       22.534s       129.25%       22.534s        5.633s             4            --  
                               aten::miopen_convolution         0.92%     261.354ms         1.01%     287.788ms     129.634us        2.915s        16.72%        2.947s       1.327ms          2220            --  
void ms_deformable_col2im_gpu_kernel_shm_blocksize_a...         0.00%       0.000us         0.00%       0.000us       0.000us        2.544s        14.59%        2.544s      12.469ms           204            --  
          MultiScaleDeformableAttnFunction_fp32Backward         0.06%      16.423ms         0.10%      27.783ms     154.350us        2.510s        14.40%        2.533s      14.071ms           180            --  
                                           aten::addmm_         0.40%     114.585ms         0.53%     149.600ms      29.968us        2.016s        11.56%        2.016s     403.773us          4992            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT112x128x16...         0.00%       0.000us         0.00%       0.000us       0.000us        1.760s        10.09%        1.760s     398.542us          4416            --  
                                               aten::mm         0.49%     138.303ms         0.63%     179.673ms      37.061us        1.175s         6.74%        1.175s     242.393us          4848  14036913166.528  
                                            aten::addmm         0.47%     135.172ms         0.61%     172.620ms      43.679us     948.766ms         5.44%     948.766ms     240.072us          3952  19822865382.400  
        miopenSp3AsmConv_v30_3_1_gfx9_fp32_f2x3_stride1         0.00%       0.000us         0.00%       0.000us       0.000us     903.689ms         5.18%     903.689ms       1.189ms           760            --  
void ms_deformable_im2col_gpu_kernel<float>(int, flo...         0.00%       0.000us         0.00%       0.000us       0.000us     876.474ms         5.03%     876.474ms       1.873ms           468            --  
                  MultiScaleDeformableAttnFunction_fp32         0.06%      16.597ms         0.11%      29.972ms      67.504us     871.878ms         5.00%     883.450ms       1.990ms           444            --  
                                              aten::bmm         0.09%      24.798ms         0.11%      31.589ms      40.812us     840.290ms         4.82%     840.290ms       1.086ms           774  193599422.976  
                          ModulatedDeformConv2dFunction         0.46%     130.300ms         1.70%     484.095ms     930.952us     825.184ms         4.73%        2.867s       5.514ms           520            --  
void modulated_deformable_im2col_gpu_kernel<float>(i...         0.00%       0.000us         0.00%       0.000us       0.000us     825.184ms         4.73%     825.184ms     165.301us          4992            --  
Cijk_Alik_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT32x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us     808.651ms         4.64%     808.651ms      25.270ms            32            --  
                             aten::convolution_backward         0.06%      18.226ms         0.08%      23.719ms     338.841us     745.328ms         4.28%     773.213ms      11.046ms            70            --  
                                            aten::copy_         0.63%     178.419ms        38.93%       11.091s     136.384us     712.932ms         4.09%     713.569ms       8.775us         81321            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     697.812ms         4.00%     697.812ms     181.817us          3838            --  
                                       aten::clamp_min_         0.03%       8.875ms         0.07%      19.289ms       7.841us     690.697ms         3.96%     690.697ms     280.771us          2460            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT128x64x32_...         0.00%       0.000us         0.00%       0.000us       0.000us     654.196ms         3.75%     654.196ms     430.392us          1520            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     610.636ms         3.50%     610.636ms      53.275us         11462            --  
                                             aten::add_         0.11%      30.966ms         0.24%      67.659ms       5.831us     601.355ms         3.45%     601.355ms      51.823us         11604            --  
_ZN2ck16tensor_operation6device37kernel_batched_gemm...         0.00%       0.000us         0.00%       0.000us       0.000us     598.462ms         3.43%     598.462ms      29.923ms            20            --  
Cijk_Ailk_Bljk_SB_MT96x64x32_MI16x16x4x1_SN_1LDSB1_A...         0.00%       0.000us         0.00%       0.000us       0.000us     546.381ms         3.13%     546.381ms       1.188ms           460            --  
Cijk_Ailk_Bljk_SB_MT96x64x32_MI16x16x4x1_SN_1LDSB1_A...         0.00%       0.000us         0.00%       0.000us       0.000us     502.078ms         2.88%     502.078ms       1.091ms           460            --  
Cijk_Ailk_Bljk_SB_MT128x128x32_MI16x16x4x1_SN_1LDSB1...         0.00%       0.000us         0.00%       0.000us       0.000us     498.355ms         2.86%     498.355ms       1.917ms           260            --  
Cijk_Alik_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT32x16x8_MI...         0.00%       0.000us         0.00%       0.000us       0.000us     453.641ms         2.60%     453.641ms       9.451ms            48            --  
                           Memcpy HtoD (Host -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us     444.208ms         2.55%     444.208ms       7.737us         57411            --  
                                aten::miopen_batch_norm         0.15%      43.517ms         0.23%      65.422ms      31.453us     441.671ms         2.53%     441.671ms     212.342us          2080            --  
                      MIOpenBatchNormFwdInferSpatialEst         0.00%       0.000us         0.00%       0.000us       0.000us     441.671ms         2.53%     441.671ms     212.342us          2080            --  
                           Memcpy DtoH (Device -> Host)         0.00%       0.000us         0.00%       0.000us       0.000us     358.511ms         2.06%     358.511ms       5.638us         63593            --  
                              Optimizer.step#AdamW.step         0.00%       0.000us         0.00%       0.000us       0.000us     333.267ms         1.91%     333.267ms     166.634ms             2            --  
                              aten::_local_scalar_dense         0.38%     108.874ms         4.91%        1.399s      21.196us     298.462ms         1.71%     298.462ms       4.521us         66011            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x128x16_...         0.00%       0.000us         0.00%       0.000us       0.000us     255.672ms         1.47%     255.672ms     443.875us           576            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT256x240x16...         0.00%       0.000us         0.00%       0.000us       0.000us     241.960ms         1.39%     241.960ms     611.009us           396            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT128x64x32_...         0.00%       0.000us         0.00%       0.000us       0.000us     178.483ms         1.02%     178.483ms     417.016us           428            --  
                                              aten::add         0.14%      38.811ms         0.22%      63.998ms      12.456us     174.222ms         1.00%     174.222ms      33.909us          5138  16629086.422  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     164.968ms         0.95%     164.968ms      47.845us          3448            --  
                                              aten::div         0.08%      21.631ms         0.13%      37.703ms      11.302us     163.962ms         0.94%     163.962ms      49.149us          3336            --  
                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us     160.338ms         0.92%     160.338ms      12.045us         13312            --  
                                          aten::nonzero         0.20%      58.022ms        15.45%        4.403s       1.196ms     156.817ms         0.90%     156.817ms      42.590us          3682            --  
        miopenSp3AsmConv_v30_3_1_gfx9_fp32_f3x2_stride2         0.00%       0.000us         0.00%       0.000us       0.000us     139.544ms         0.80%     139.544ms       3.489ms            40            --  
                                aten::native_layer_norm         0.05%      12.996ms         0.10%      27.313ms      25.384us     138.506ms         0.79%     138.506ms     128.723us          1076            --  
void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us     138.506ms         0.79%     138.506ms     128.723us          1076            --  
                                            aten::fill_         0.08%      22.719ms         0.26%      73.519ms       5.419us     136.084ms         0.78%     136.084ms      10.030us         13568            --  
                                              aten::sum         0.15%      43.065ms         0.36%     102.466ms      20.115us     135.193ms         0.78%     150.760ms      29.596us          5094            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     134.265ms         0.77%     134.265ms      12.572us         10680            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     127.341ms         0.73%     127.341ms     187.267us           680            --  
Cijk_Ailk_Bljk_SB_MT64x128x16_MI16x16x4x1_SN_1LDSB1_...         0.00%       0.000us         0.00%       0.000us       0.000us     118.254ms         0.68%     118.254ms       1.408ms            84            --  
Cijk_Ailk_Bljk_SB_MT64x128x16_MI16x16x4x1_SN_1LDSB1_...         0.00%       0.000us         0.00%       0.000us       0.000us     113.092ms         0.65%     113.092ms       2.570ms            44            --  
                                              aten::cat         0.12%      34.107ms         0.24%      68.035ms      17.043us     107.513ms         0.62%     107.513ms      26.932us          3992            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT128x32x32_...         0.00%       0.000us         0.00%       0.000us       0.000us      98.274ms         0.56%      98.274ms     545.969us           180            --  
                                            aten::index         0.24%      68.076ms         1.04%     297.450ms      37.153us      96.046ms         0.55%     179.755ms      22.452us          8006            --  
                                             aten::mean         0.02%       5.740ms         0.03%       8.721ms      15.088us      95.434ms         0.55%      95.434ms     165.112us           578            --  
                                 aten::_index_put_impl_         0.12%      35.217ms        13.50%        3.846s       1.243ms      92.870ms         0.53%     132.416ms      42.798us          3094            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT128x48x32_...         0.00%       0.000us         0.00%       0.000us       0.000us      92.814ms         0.53%      92.814ms     703.133us           132            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      92.686ms         0.53%      92.686ms      22.662us          4090            --  
void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      92.677ms         0.53%      92.677ms     382.963us           242            --  
void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      90.050ms         0.52%      90.050ms      40.969us          2198            --  
void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      89.889ms         0.52%      89.889ms      14.314us          6280            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT256x64x16_...         0.00%       0.000us         0.00%       0.000us       0.000us      70.434ms         0.40%      70.434ms     533.592us           132            --  
Cijk_Ailk_Bljk_SB_MT64x64x32_MI16x16x4x1_SN_1LDSB1_A...         0.00%       0.000us         0.00%       0.000us       0.000us      67.674ms         0.39%      67.674ms       1.128ms            60            --  
                       aten::native_layer_norm_backward         0.03%       7.629ms         0.08%      23.023ms      35.640us      65.612ms         0.38%      65.612ms     101.566us           646            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us      63.863ms         0.37%      63.863ms     115.693us           552            --  
                                              aten::mul         0.16%      44.712ms         0.29%      83.327ms       8.885us      54.757ms         0.31%      54.757ms       5.839us          9378   2408866.765  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT48x128x32_...         0.00%       0.000us         0.00%       0.000us       0.000us      51.954ms         0.30%      51.954ms     721.589us            72            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT128x32x32_...         0.00%       0.000us         0.00%       0.000us       0.000us      51.208ms         0.29%      51.208ms     206.485us           248            --  
                          aten::max_pool2d_with_indices         0.00%     254.408us         0.00%     435.351us      21.768us      46.128ms         0.26%      46.128ms       2.306ms            20            --  
void at::native::(anonymous namespace)::max_pool_for...         0.00%       0.000us         0.00%       0.000us       0.000us      46.128ms         0.26%      46.128ms       2.306ms            20            --  
Cijk_Ailk_Bljk_SB_MT64x64x32_MI16x16x4x1_SN_1LDSB1_A...         0.00%       0.000us         0.00%       0.000us       0.000us      43.834ms         0.25%      43.834ms       1.096ms            40            --  
                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us      38.085ms         0.22%      38.085ms       7.111us          5356            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT128x64x16_...         0.00%       0.000us         0.00%       0.000us       0.000us      34.882ms         0.20%      34.882ms     484.477us            72            --  
                                    aten::_foreach_mul_         0.05%      13.597ms         0.13%      37.167ms       8.737us      34.789ms         0.20%      34.789ms       8.178us          4254            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      33.987ms         0.19%      33.987ms       7.993us          4252            --  
void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      33.515ms         0.19%      33.515ms      20.663us          1622            --  
               MultiScaleDeformableAttnFunctionBackward         0.01%       1.463ms         0.01%       2.693ms     112.192us      33.495ms         0.19%      34.716ms       1.447ms            24            --  
                                         aten::_softmax         0.01%       4.271ms         0.03%       7.978ms      13.523us      32.984ms         0.19%      32.984ms      55.904us           590            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x128x32_...         0.00%       0.000us         0.00%       0.000us       0.000us      31.378ms         0.18%      31.378ms     237.711us           132            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us      29.652ms         0.17%      29.652ms      60.269us           492            --  
void at::native::(anonymous namespace)::cuComputeGra...         0.00%       0.000us         0.00%       0.000us       0.000us      28.584ms         0.16%      28.584ms     140.119us           204            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x160x32_...         0.00%       0.000us         0.00%       0.000us       0.000us      28.467ms         0.16%      28.467ms     148.264us           192            --  
void at::native::(anonymous namespace)::cuComputePar...         0.00%       0.000us         0.00%       0.000us       0.000us      27.708ms         0.16%      27.708ms      51.312us           540            --  
Cijk_Alik_Bljk_SB_MT64x32x64_MI16x16x4x1_SN_1LDSB1_A...         0.00%       0.000us         0.00%       0.000us       0.000us      26.287ms         0.15%      26.287ms     219.060us           120            --  
void (anonymous namespace)::indexing_backward_kernel...         0.00%       0.000us         0.00%       0.000us       0.000us      25.798ms         0.15%      25.798ms      33.418us           772            --  
void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us      25.155ms         0.14%      25.155ms     130.337us           193            --  
                     transpose_NCHW2CNHW_V2_2D_WG_off64         0.00%       0.000us         0.00%       0.000us       0.000us      21.175ms         0.12%      21.175ms     176.459us           120            --  
Cijk_Ailk_Bljk_SB_MT64x64x32_MI16x16x4x1_SN_1LDSB1_A...         0.00%       0.000us         0.00%       0.000us       0.000us      20.327ms         0.12%      20.327ms       1.452ms            14            --  
                                    aten::_foreach_sqrt         0.03%       9.331ms         0.09%      25.305ms      11.903us      19.370ms         0.11%      19.370ms       9.111us          2126            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      19.370ms         0.11%      19.370ms       9.111us          2126            --  
                                aten::_foreach_addcdiv_         0.02%       7.023ms         0.07%      18.552ms       8.726us      19.101ms         0.11%      19.101ms       8.985us          2126            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      19.101ms         0.11%      19.101ms       8.985us          2126            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT80x128x16_...         0.00%       0.000us         0.00%       0.000us       0.000us      19.099ms         0.11%      19.099ms     318.310us            60            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      18.864ms         0.11%      18.864ms       4.998us          3774            --  
                                   aten::_foreach_lerp_         0.02%       5.018ms         0.06%      16.282ms       7.659us      18.409ms         0.11%      18.409ms       8.659us          2126            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      18.409ms         0.11%      18.409ms       8.659us          2126            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      17.885ms         0.10%      17.885ms      56.243us           318            --  
                                    aten::_foreach_div_         0.02%       5.849ms         0.06%      18.029ms       8.480us      17.547ms         0.10%      17.547ms       8.253us          2126            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      17.547ms         0.10%      17.547ms       8.253us          2126            --  
                                   aten::native_dropout         0.02%       6.530ms         0.05%      15.074ms      23.702us      17.408ms         0.10%      17.408ms      27.371us           636            --  
void at::native::(anonymous namespace)::fused_dropou...         0.00%       0.000us         0.00%       0.000us       0.000us      17.408ms         0.10%      17.408ms      27.371us           636            --  
void rocprim::detail::transform_kernel<rocprim::deta...         0.00%       0.000us         0.00%       0.000us       0.000us      16.872ms         0.10%      16.872ms       4.607us          3662            --  
void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      16.552ms         0.09%      16.552ms      10.776us          1536            --  
                          aten::native_dropout_backward         0.01%       2.767ms         0.03%       7.228ms      11.365us      15.533ms         0.09%      15.533ms      24.422us           636            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      15.533ms         0.09%      15.533ms      24.422us           636            --  
void rocprim::detail::init_lookback_scan_state_kerne...         0.00%       0.000us         0.00%       0.000us       0.000us      14.906ms         0.09%      14.906ms       4.042us          3688            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      14.723ms         0.08%      14.723ms      21.462us           686            --  
                                aten::_foreach_addcmul_         0.03%       7.590ms         0.07%      18.981ms       8.928us      14.709ms         0.08%      14.709ms       6.919us          2126            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      14.709ms         0.08%      14.709ms       6.919us          2126            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT32x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us      14.547ms         0.08%      14.547ms      17.339us           839            --  
void rocprim::detail::device_block_merge_oddeven_ker...         0.00%       0.000us         0.00%       0.000us       0.000us      13.393ms         0.08%      13.393ms       6.377us          2100            --  
                                    aten::_foreach_add_         0.03%       8.476ms         0.08%      22.732ms       5.346us      13.127ms         0.08%      13.127ms       3.087us          4252            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      13.127ms         0.08%      13.127ms       6.175us          2126            --  
void rocprim::detail::partition_kernel<(rocprim::det...         0.00%       0.000us         0.00%       0.000us       0.000us      12.047ms         0.07%      12.047ms       4.800us          2510            --  
Cijk_Ailk_Bljk_SB_MT32x32x64_MI16x16x4x1_SN_1LDSB0_A...         0.00%       0.000us         0.00%       0.000us       0.000us      11.983ms         0.07%      11.983ms     599.155us            20            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      11.503ms         0.07%      11.503ms      19.833us           580            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      11.455ms         0.07%      11.455ms       8.977us          1276            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      11.343ms         0.07%      11.343ms       9.846us          1152            --  
                                  aten::grid_sampler_2d         0.00%     190.925us         0.00%     429.563us      19.526us      11.062ms         0.06%      11.062ms     502.824us            22            --  
void at::native::(anonymous namespace)::grid_sampler...         0.00%       0.000us         0.00%       0.000us       0.000us      11.062ms         0.06%      11.062ms     502.824us            22            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us      10.778ms         0.06%      10.778ms      15.992us           674            --  
void rocprim::detail::radix_sort_block_sort_kernel<r...         0.00%       0.000us         0.00%       0.000us       0.000us      10.658ms         0.06%      10.658ms      10.209us          1044            --  
              transpose_CNHW2NCHW_V1_1D_WG_float4_off64         0.00%       0.000us         0.00%       0.000us       0.000us      10.282ms         0.06%      10.282ms     128.527us            80            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT80x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us      10.155ms         0.06%      10.155ms     169.251us            60            --  
                          batched_transpose_32x32_dword         0.00%       0.000us         0.00%       0.000us       0.000us       9.775ms         0.06%       9.775ms     244.387us            40            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       9.304ms         0.05%       9.304ms     930.425us            10            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT128x96x16_...         0.00%       0.000us         0.00%       0.000us       0.000us       9.141ms         0.05%       9.141ms     380.895us            24            --  
                           aten::_softmax_backward_data         0.01%       3.073ms         0.03%       9.080ms      28.198us       8.867ms         0.05%      18.057ms      56.078us           322            --  
                               aten::threshold_backward         0.01%       2.984ms         0.02%       5.563ms       8.665us       8.786ms         0.05%       8.786ms      13.685us           642            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       8.786ms         0.05%       8.786ms      13.685us           642            --  
void rocprim::detail::block_reduce_kernel<true, rocp...         0.00%       0.000us         0.00%       0.000us       0.000us       8.769ms         0.05%       8.769ms       3.494us          2510            --  
                                             aten::div_         0.02%       6.282ms         0.04%      12.761ms       8.330us       8.627ms         0.05%       8.627ms       5.631us          1532            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       7.748ms         0.04%       7.748ms      16.075us           482            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT96x128x32_...         0.00%       0.000us         0.00%       0.000us       0.000us       7.704ms         0.04%       7.704ms      64.202us           120            --  
                               aten::upsample_nearest2d         0.00%     430.613us         0.00%     727.074us      17.311us       7.613ms         0.04%       7.619ms     181.401us            42            --  
void at::native::(anonymous namespace)::upsample_nea...         0.00%       0.000us         0.00%       0.000us       0.000us       7.613ms         0.04%       7.613ms     190.334us            40            --  
void rocprim::detail::partition_kernel<(rocprim::det...         0.00%       0.000us         0.00%       0.000us       0.000us       7.569ms         0.04%       7.569ms       6.571us          1152            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT64x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       7.468ms         0.04%       7.468ms      51.859us           144            --  
Cijk_Ailk_Bljk_SB_MT64x256x16_MI16x16x4x1_SN_1LDSB1_...         0.00%       0.000us         0.00%       0.000us       0.000us       7.011ms         0.04%       7.011ms       1.753ms             4            --  
                                              aten::sub         0.04%      10.212ms         0.09%      24.938ms      14.185us       6.646ms         0.04%       6.646ms       3.780us          1758            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       6.399ms         0.04%       6.399ms       5.228us          1224            --  
                                        aten::remainder         0.03%       7.661ms         0.04%      12.634ms      10.670us       6.364ms         0.04%       6.364ms       5.375us          1184            --  
void rocprim::detail::block_reduce_kernel<false, roc...         0.00%       0.000us         0.00%       0.000us       0.000us       6.291ms         0.04%       6.291ms       5.461us          1152            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       6.287ms         0.04%       6.287ms       5.373us          1170            --  
                                   aten::_cdist_forward         0.01%       1.456ms         0.02%       4.505ms      60.884us       6.119ms         0.04%       6.545ms      88.448us            74            --  
void at::native::(anonymous namespace)::cdist_kernel...         0.00%       0.000us         0.00%       0.000us       0.000us       6.119ms         0.04%       6.119ms      82.690us            74            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       5.892ms         0.03%       5.892ms       9.323us           632            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.786ms         0.03%       5.786ms       5.542us          1044            --  
void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.668ms         0.03%       5.668ms       3.565us          1590            --  
                                          aten::sigmoid         0.02%       6.259ms         0.04%      10.425ms      12.038us       5.640ms         0.03%       5.640ms       6.513us           866            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT256x64x16_...         0.00%       0.000us         0.00%       0.000us       0.000us       5.590ms         0.03%       5.590ms     232.920us            24            --  
void rocprim::detail::block_reduce_kernel<true, rocp...         0.00%       0.000us         0.00%       0.000us       0.000us       5.517ms         0.03%       5.517ms       4.789us          1152            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.394ms         0.03%       5.394ms       4.143us          1302            --  
                                            aten::clamp         0.02%       6.635ms         0.05%      13.458ms      13.431us       5.309ms         0.03%       6.439ms       6.426us          1002            --  
                                           aten::arange         0.02%       6.976ms         0.09%      26.182ms      10.423us       5.246ms         0.03%      10.492ms       4.177us          2512            --  
void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us       5.241ms         0.03%       5.241ms       4.622us          1134            --  
                                            Im2d2Col_v2         0.00%       0.000us         0.00%       0.000us       0.000us       5.222ms         0.03%       5.222ms      43.515us           120            --  
void at::native::(anonymous namespace)::layer_norm_g...         0.00%       0.000us         0.00%       0.000us       0.000us       5.176ms         0.03%       5.176ms      11.711us           442            --  
Cijk_Alik_Bljk_SB_MT64x64x32_MI16x16x4x1_SN_1LDSB0_A...         0.00%       0.000us         0.00%       0.000us       0.000us       5.047ms         0.03%       5.047ms      84.124us            60            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT64x16x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       4.978ms         0.03%       4.978ms      19.993us           249            --  
                                               aten::gt         0.02%       4.731ms         0.03%       7.516ms      12.444us       4.897ms         0.03%       4.897ms       8.107us           604            --  
                                               aten::eq         0.02%       6.332ms         0.04%      10.949ms      10.798us       4.890ms         0.03%       4.890ms       4.823us          1014            --  
Cijk_Ailk_Bljk_SB_MT64x64x32_MI16x16x4x1_SN_1LDSB1_A...         0.00%       0.000us         0.00%       0.000us       0.000us       4.879ms         0.03%       4.879ms     348.487us            14            --  
void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us       4.766ms         0.03%       4.766ms      79.426us            60            --  
                     aten::upsample_bilinear2d_backward         0.00%     131.104us         0.00%     415.960us      17.332us       4.740ms         0.03%       4.847ms     201.976us            24            --  
void at::native::(anonymous namespace)::upsample_bil...         0.00%       0.000us         0.00%       0.000us       0.000us       4.740ms         0.03%       4.740ms     197.495us            24            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.680ms         0.03%       4.680ms       4.957us           944            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       4.653ms         0.03%       4.653ms       9.124us           510            --  
                       MultiScaleDeformableAttnFunction         0.00%     800.037us         0.01%       1.483ms      61.791us       4.596ms         0.03%       4.940ms     205.848us            24            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       4.456ms         0.03%       4.456ms      13.584us           328            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       4.367ms         0.03%       4.367ms       6.824us           640            --  
void at::native::elementwise_kernel<512, 1, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       4.258ms         0.02%       4.258ms       9.257us           460            --  
                                        hipEventDestroy         0.00%     293.785us         0.00%     293.785us       0.512us       4.150ms         0.02%       4.150ms       7.231us           574            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.068ms         0.02%       4.068ms       9.461us           430            --  
           Cijk_SS_BiasS_HAS_ScaleAlphaVec_PostGSU8_VW4         0.00%       0.000us         0.00%       0.000us       0.000us       4.048ms         0.02%       4.048ms       6.405us           632            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       3.977ms         0.02%       3.977ms      14.154us           281            --  
                                     aten::masked_fill_         0.00%     640.019us         0.01%       1.447ms       8.221us       3.900ms         0.02%       3.900ms      22.158us           176            --  
void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us       3.851ms         0.02%       3.851ms      14.811us           260            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.833ms         0.02%       3.833ms       5.755us           666            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x16x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       3.637ms         0.02%       3.637ms      10.987us           331            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x96x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       3.549ms         0.02%       3.549ms      26.885us           132            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT16x256x16_...         0.00%       0.000us         0.00%       0.000us       0.000us       3.475ms         0.02%       3.475ms      72.401us            48            --  
void rocprim::detail::transform_kernel<rocprim::deta...         0.00%       0.000us         0.00%       0.000us       0.000us       3.361ms         0.02%       3.361ms       6.224us           540            --  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       3.283ms         0.02%       3.283ms       7.427us           442            --  
void rocprim::detail::transform_kernel<rocprim::deta...         0.00%       0.000us         0.00%       0.000us       0.000us       3.273ms         0.02%       3.273ms       6.062us           540            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.271ms         0.02%       3.271ms       4.660us           702            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.230ms         0.02%       3.230ms      67.295us            48            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       3.111ms         0.02%       3.111ms       5.847us           532            --  
void at::native::(anonymous namespace)::cuComputeGra...         0.00%       0.000us         0.00%       0.000us       0.000us       3.087ms         0.02%       3.087ms       5.716us           540            --  
                                               aten::ge         0.01%       2.624ms         0.02%       4.404ms      12.032us       2.936ms         0.02%       2.936ms       8.021us           366            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.890ms         0.02%       2.890ms       6.783us           426            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x16x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       2.769ms         0.02%       2.769ms      11.985us           231            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       2.757ms         0.02%       2.757ms       8.206us           336            --  
                                               aten::ne         0.01%       3.613ms         0.02%       6.497ms       9.335us       2.746ms         0.02%       2.746ms       3.945us           696            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT32x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       2.684ms         0.02%       2.684ms      12.198us           220            --  
      miopenSp3AsmConv_v30_3_1_gfx9_fp32_f3x2_dilation2         0.00%       0.000us         0.00%       0.000us       0.000us       2.546ms         0.01%       2.546ms     254.588us            10            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       2.518ms         0.01%       2.518ms       4.433us           568            --  
                                              aten::neg         0.01%       2.086ms         0.01%       4.119ms       8.140us       2.483ms         0.01%       2.483ms       4.907us           506            --  
                                        aten::clamp_min         0.01%       2.147ms         0.01%       4.271ms       8.374us       2.409ms         0.01%       2.409ms       4.724us           510            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT48x128x16_...         0.00%       0.000us         0.00%       0.000us       0.000us       2.325ms         0.01%       2.325ms     193.734us            12            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.302ms         0.01%       2.302ms       4.940us           466            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       2.281ms         0.01%       2.281ms       4.618us           494            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT32x128x16_...         0.00%       0.000us         0.00%       0.000us       0.000us       2.279ms         0.01%       2.279ms     113.952us            20            --  
Cijk_Alik_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT32x16x8_MI...         0.00%       0.000us         0.00%       0.000us       0.000us       2.234ms         0.01%       2.234ms      93.068us            24            --  
              transpose_CNHW2NCHW_V1_1D_WG_float2_off64         0.00%       0.000us         0.00%       0.000us       0.000us       2.213ms         0.01%       2.213ms      55.323us            40            --  
                                              aten::abs         0.01%       3.924ms         0.04%      12.147ms      11.331us       2.157ms         0.01%       4.315ms       4.025us          1072            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.157ms         0.01%       2.157ms       4.025us           536            --  
void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us       2.126ms         0.01%       2.126ms      35.435us            60            --  
                                              aten::log         0.01%       2.141ms         0.01%       4.045ms       9.406us       2.114ms         0.01%       2.114ms       4.917us           430            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.040ms         0.01%       2.040ms       4.834us           422            --  
                      aten::upsample_nearest2d_backward         0.00%     107.123us         0.00%     243.371us      12.169us       2.016ms         0.01%       2.016ms     100.798us            20            --  
void at::native::(anonymous namespace)::upsample_nea...         0.00%       0.000us         0.00%       0.000us       0.000us       2.016ms         0.01%       2.016ms     100.798us            20            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT32x128x32_...         0.00%       0.000us         0.00%       0.000us       0.000us       2.010ms         0.01%       2.010ms      33.503us            60            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.941ms         0.01%       1.941ms       5.107us           380            --  
void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.889ms         0.01%       1.889ms       4.972us           380            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.860ms         0.01%       1.860ms       3.495us           532            --  
void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us       1.795ms         0.01%       1.795ms      29.910us            60            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT128x32x16_...         0.00%       0.000us         0.00%       0.000us       0.000us       1.790ms         0.01%       1.790ms       9.178us           195            --  
                                            aten::where         0.01%       2.286ms         0.02%       4.603ms      12.645us       1.790ms         0.01%       1.790ms       4.917us           364            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.762ms         0.01%       1.762ms      10.242us           172            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT48x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       1.730ms         0.01%       1.730ms      24.029us            72            --  
void at::native::vectorized_elementwise_kernel<16, a...         0.00%       0.000us         0.00%       0.000us       0.000us       1.723ms         0.01%       1.723ms       7.240us           238            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT16x128x16_...         0.00%       0.000us         0.00%       0.000us       0.000us       1.695ms         0.01%       1.695ms      11.008us           154            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT80x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       1.655ms         0.01%       1.655ms     165.500us            10            --  
          Cijk_SS_BiasS_HAS_ScaleAlphaVec_PostGSU16_VW4         0.00%       0.000us         0.00%       0.000us       0.000us       1.643ms         0.01%       1.643ms       9.445us           174            --  
Cijk_Alik_Bljk_SB_MT64x64x32_MI16x16x4x1_SN_1LDSB0_A...         0.00%       0.000us         0.00%       0.000us       0.000us       1.638ms         0.01%       1.638ms      27.304us            60            --  
                                      aten::bitwise_and         0.00%       1.408ms         0.01%       2.495ms      11.444us       1.628ms         0.01%       1.628ms       7.468us           218            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.610ms         0.01%       1.610ms       4.066us           396            --  
                                          aten::maximum         0.01%       2.075ms         0.01%       3.591ms      12.468us       1.539ms         0.01%       1.539ms       5.343us           288            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.537ms         0.01%       1.537ms       2.254us           682            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.530ms         0.01%       1.530ms       9.564us           160            --  
                                         aten::_unique2         0.00%     501.511us         0.01%       2.668ms      95.302us       1.471ms         0.01%       1.776ms      63.420us            28            --  
void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.457ms         0.01%       1.457ms       3.624us           402            --  
                                       aten::nan_to_num         0.01%       1.920ms         0.03%       7.324ms       9.951us       1.444ms         0.01%       3.278ms       4.453us           736            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.444ms         0.01%       1.444ms       4.299us           336            --  
void at::native::elementwise_kernel<512, 1, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.443ms         0.01%       1.443ms       5.081us           284            --  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       1.433ms         0.01%       1.433ms       5.193us           276            --  
void at::native::reduce_kernel<256, 2, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       1.428ms         0.01%       1.428ms      10.058us           142            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us       1.345ms         0.01%       1.345ms       9.964us           135            --  
void (anonymous namespace)::indexing_backward_kernel...         0.00%       0.000us         0.00%       0.000us       0.000us       1.327ms         0.01%       1.327ms       4.877us           272            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.304ms         0.01%       1.304ms       5.017us           260            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT256x8x8_MI...         0.00%       0.000us         0.00%       0.000us       0.000us       1.260ms         0.01%       1.260ms      52.488us            24            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.212ms         0.01%       1.212ms       5.666us           214            --  
                                               aten::lt         0.00%     802.586us         0.01%       1.510ms       8.986us       1.171ms         0.01%       1.171ms       6.969us           168            --  
                                              aten::exp         0.01%       1.643ms         0.01%       3.291ms       7.835us       1.126ms         0.01%       1.126ms       2.682us           420            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       1.110ms         0.01%       1.110ms       5.781us           192            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT128x16x32_...         0.00%       0.000us         0.00%       0.000us       0.000us       1.088ms         0.01%       1.088ms      90.636us            12            --  
void at::native::(anonymous namespace)::cunn_SoftMax...         0.00%       0.000us         0.00%       0.000us       0.000us       1.087ms         0.01%       1.087ms      54.365us            20            --  
void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us       1.079ms         0.01%       1.079ms       8.563us           126            --  
void at::native::(anonymous namespace)::GammaBetaBac...         0.00%       0.000us         0.00%       0.000us       0.000us       1.056ms         0.01%       1.056ms       9.962us           106            --  
                                 aten::sigmoid_backward         0.00%     716.340us         0.01%       1.426ms       8.389us       1.041ms         0.01%       1.041ms       6.124us           170            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.041ms         0.01%       1.041ms       6.124us           170            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.003ms         0.01%       1.003ms       2.572us           390            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     991.936us         0.01%     991.936us       8.857us           112            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     970.082us         0.01%     970.082us       3.976us           244            --  
void at::native::vectorized_elementwise_kernel<16, a...         0.00%       0.000us         0.00%       0.000us       0.000us     955.088us         0.01%     955.088us       3.460us           276            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     876.047us         0.01%     876.047us       3.174us           276            --  
                                              aten::max         0.01%       1.903ms         0.02%       5.987ms      15.755us     836.520us         0.00%       1.970ms       5.183us           380            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     819.565us         0.00%     819.565us       6.830us           120            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us     801.825us         0.00%     801.825us      40.091us            20            --  
void rocprim::detail::radix_sort_block_sort_kernel<r...         0.00%       0.000us         0.00%       0.000us       0.000us     758.777us         0.00%     758.777us      29.184us            26            --  
                                              aten::pow         0.00%       1.416ms         0.01%       2.266ms      14.910us     742.975us         0.00%     758.612us       4.991us           152            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     731.776us         0.00%     731.776us       4.944us           148            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     722.384us         0.00%     722.384us       5.160us           140            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT128x32x16_...         0.00%       0.000us         0.00%       0.000us       0.000us     719.088us         0.00%     719.088us      19.975us            36            --  
                                              aten::sgn         0.00%     645.882us         0.00%       1.261ms       9.007us     714.226us         0.00%     714.226us       5.102us           140            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     714.226us         0.00%     714.226us       5.102us           140            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     701.384us         0.00%     701.384us       3.812us           184            --  
void at::native::elementwise_kernel<512, 1, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     678.124us         0.00%     678.124us       2.422us           280            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     676.732us         0.00%     676.732us       3.525us           192            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     669.557us         0.00%     669.557us       5.231us           128            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x32x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us     666.492us         0.00%     666.492us      18.514us            36            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     612.493us         0.00%     612.493us       8.750us            70            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     610.844us         0.00%     610.844us       2.545us           240            --  
                                          aten::minimum         0.00%     879.639us         0.01%       1.464ms      11.441us     596.281us         0.00%     596.281us       4.658us           128            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     595.924us         0.00%     595.924us       4.966us           120            --  
void at::native::(anonymous namespace)::cunn_SoftMax...         0.00%       0.000us         0.00%       0.000us       0.000us     574.984us         0.00%     574.984us      28.749us            20            --  
                                             aten::sort         0.00%     199.323us         0.00%     674.435us      67.444us     568.472us         0.00%     677.194us      67.719us            10            --  
void at::native::radixSortKVInPlace<-2, -1, 32, 32, ...         0.00%       0.000us         0.00%       0.000us       0.000us     568.472us         0.00%     568.472us      56.847us            10            --  
void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us     561.977us         0.00%     561.977us      20.814us            27            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT64x64x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us     540.617us         0.00%     540.617us      22.526us            24            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     529.030us         0.00%     529.030us       5.750us            92            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     527.776us         0.00%     527.776us       3.566us           148            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x16x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us     504.765us         0.00%     504.765us       6.232us            81            --  
                                         aten::linspace         0.00%       1.019ms         0.02%       6.631ms      15.788us     499.840us         0.00%       1.030ms       2.453us           420            --  
void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us     499.840us         0.00%     499.840us       2.403us           208            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us     492.586us         0.00%     492.586us       8.493us            58            --  
void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     489.464us         0.00%     489.464us       5.099us            96            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     472.481us         0.00%     472.481us       3.937us           120            --  
                                            aten::floor         0.00%     569.611us         0.00%       1.114ms       9.284us     470.843us         0.00%     470.843us       3.924us           120            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     470.843us         0.00%     470.843us       3.924us           120            --  
                       SigmoidFocalLossFunctionBackward         0.01%       4.261ms         0.02%       6.847ms      74.423us     456.551us         0.00%       1.160ms      12.611us            92            --  
void sigmoid_focal_loss_backward_cuda_kernel<float>(...         0.00%       0.000us         0.00%       0.000us       0.000us     456.551us         0.00%     456.551us       4.963us            92            --  
                                            aten::atan2         0.00%     834.575us         0.01%       1.505ms      10.750us     453.260us         0.00%     453.260us       3.238us           140            --  
void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us     451.335us         0.00%     451.335us      16.716us            27            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x48x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us     450.018us         0.00%     450.018us      18.751us            24            --  
                                             aten::mul_         0.00%     304.365us         0.00%     682.215us       7.415us     447.789us         0.00%     447.789us       4.867us            92            --  
                               SigmoidFocalLossFunction         0.01%       4.212ms         0.04%      12.443ms     135.251us     445.630us         0.00%       2.704ms      29.397us            92            --  
void sigmoid_focal_loss_forward_cuda_kernel<float>(i...         0.00%       0.000us         0.00%       0.000us       0.000us     445.630us         0.00%     445.630us       4.844us            92            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x96x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us     428.538us         0.00%     428.538us      17.856us            24            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x48x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us     418.780us         0.00%     418.780us      17.449us            24            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     413.922us         0.00%     413.922us       3.449us           120            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     409.990us         0.00%     409.990us       3.154us           130            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT128x16x16_...         0.00%       0.000us         0.00%       0.000us       0.000us     393.402us         0.00%     393.402us       9.367us            42            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     389.392us         0.00%     389.392us       4.327us            90            --  
                                    aten::_foreach_norm         0.01%       3.277ms         0.01%       3.601ms       1.801ms     383.577us         0.00%     388.935us     194.468us             2            --  
                         aten::embedding_dense_backward         0.00%     106.816us         0.00%     488.826us      24.441us     372.663us         0.00%     493.243us      24.662us            20            --  
void at::native::(anonymous namespace)::embedding_ba...         0.00%       0.000us         0.00%       0.000us       0.000us     372.663us         0.00%     372.663us      18.633us            20            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x64x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us     372.261us         0.00%     372.261us      15.511us            24            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     364.466us         0.00%     364.466us       3.645us           100            --  
                                     aten::index_select         0.00%     515.157us         0.00%       1.134ms      17.724us     363.776us         0.00%     363.776us       5.684us            64            --  
void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us     363.776us         0.00%     363.776us       5.684us            64            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     360.376us         0.00%     360.376us       3.465us           104            --  
                              aten::upsample_bilinear2d         0.00%     205.086us         0.00%     334.641us      11.951us     356.575us         0.00%     356.575us      12.735us            28            --  
void at::native::(anonymous namespace)::upsample_bil...         0.00%       0.000us         0.00%       0.000us       0.000us     356.575us         0.00%     356.575us      12.735us            28            --  
                                               aten::le         0.00%     232.302us         0.00%     424.642us       8.847us     352.474us         0.00%     352.474us       7.343us            48            --  
void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us     351.142us         0.00%     351.142us      17.557us            20            --  
                                             aten::topk         0.00%     268.513us         0.00%     478.585us      23.929us     330.211us         0.00%     330.211us      16.511us            20            --  
                                           aten::cumsum         0.00%     502.360us         0.00%     905.160us      23.820us     318.484us         0.00%     336.480us       8.855us            38            --  
                                      aten::logical_and         0.00%     100.698us         0.00%     243.694us       8.703us     301.532us         0.00%     301.532us      10.769us            28            --  
void at::native::vectorized_elementwise_kernel<16, a...         0.00%       0.000us         0.00%       0.000us       0.000us     301.532us         0.00%     301.532us      10.769us            28            --  
          Cijk_SS_BiasS_HAS_ScaleAlphaVec_PostGSU16_VW1         0.00%       0.000us         0.00%       0.000us       0.000us     299.671us         0.00%     299.671us       5.993us            50            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     292.812us         0.00%     292.812us       9.760us            30            --  
                                              aten::all         0.00%     311.395us         0.00%     526.086us      13.152us     269.922us         0.00%     269.922us       6.748us            40            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     269.922us         0.00%     269.922us       6.748us            40            --  
                                SubTensorOpWithScalar1d         0.00%       0.000us         0.00%       0.000us       0.000us     254.841us         0.00%     254.841us       6.371us            40            --  
                                             aten::prod         0.00%     680.377us         0.01%       1.803ms      53.036us     245.368us         0.00%     245.368us       7.217us            34            --  
                                  reduction_prod_kernel         0.00%       0.000us         0.00%       0.000us       0.000us     245.368us         0.00%     245.368us       7.217us            34            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     234.376us         0.00%     234.376us       8.371us            28            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT16x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us     234.096us         0.00%     234.096us       9.364us            25            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     231.815us         0.00%     231.815us       8.279us            28            --  
void at::native::sbtopk::gatherTopK<float, unsigned ...         0.00%       0.000us         0.00%       0.000us       0.000us     207.421us         0.00%     207.421us      10.371us            20            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT32x96x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us     195.108us         0.00%     195.108us      16.259us            12            --  
void at::native::elementwise_kernel<512, 1, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     193.541us         0.00%     193.541us       3.024us            64            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT96x32x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us     189.549us         0.00%     189.549us      15.796us            12            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     180.881us         0.00%     180.881us       4.522us            40            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT128x16x32_...         0.00%       0.000us         0.00%       0.000us       0.000us     168.467us         0.00%     168.467us      12.959us            13            --  
                                              aten::sin         0.00%     105.337us         0.00%     215.019us       8.959us     162.496us         0.00%     162.496us       6.771us            24            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     158.581us         0.00%     158.581us       2.643us            60            --  
                                              aten::cos         0.00%      97.472us         0.00%     213.838us       8.910us     155.777us         0.00%     155.777us       6.491us            24            --  
void rocprim::detail::single_scan_kernel<false, rocp...         0.00%       0.000us         0.00%       0.000us       0.000us     154.327us         0.00%     154.327us       4.539us            34            --  
void rocprim::detail::partition_kernel<(rocprim::det...         0.00%       0.000us         0.00%       0.000us       0.000us     144.455us         0.00%     144.455us       5.556us            26            --  
                                     hipStreamWaitEvent         0.02%       5.312ms         0.02%       5.312ms       5.228us     143.901us         0.00%     143.901us       0.142us          1016            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     135.370us         0.00%     135.370us       4.512us            30            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     132.906us         0.00%     132.906us       9.493us            14            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT16x64x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us     130.789us         0.00%     130.789us      10.899us            12            --  
void at::native::tensor_kernel_scan_outer_dim<float,...         0.00%       0.000us         0.00%       0.000us       0.000us     128.879us         0.00%     128.879us      64.440us             2            --  
void rocprim::detail::transform_kernel<rocprim::deta...         0.00%       0.000us         0.00%       0.000us       0.000us     127.334us         0.00%     127.334us       4.897us            26            --  
                                              aten::any         0.00%     242.110us         0.00%     562.338us      20.084us     127.140us         0.00%     171.364us       6.120us            28            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     127.140us         0.00%     127.140us       6.357us            20            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     120.106us         0.00%     120.106us       8.579us            14            --  
                                    aten::gelu_backward         0.00%     121.889us         0.00%     215.471us      10.774us     119.700us         0.00%     119.700us       5.985us            20            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     119.700us         0.00%     119.700us       5.985us            20            --  
                                             aten::gelu         0.00%     160.965us         0.00%     263.950us      13.198us     119.420us         0.00%     119.420us       5.971us            20            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     119.420us         0.00%     119.420us       5.971us            20            --  
void at::native::vectorized_elementwise_kernel<16, a...         0.00%       0.000us         0.00%       0.000us       0.000us     119.168us         0.00%     119.168us       3.724us            32            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT16x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us     115.904us         0.00%     115.904us       7.244us            16            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     114.387us         0.00%     114.387us       8.171us            14            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT64x128x16_...         0.00%       0.000us         0.00%       0.000us       0.000us     107.473us         0.00%     107.473us      13.434us             8            --  
void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us     106.390us         0.00%     106.390us       8.866us            12            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT64x64x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us     104.070us         0.00%     104.070us       8.673us            12            --  
void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us     103.229us         0.00%     103.229us       8.602us            12            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT128x64x32_...         0.00%       0.000us         0.00%       0.000us       0.000us     102.753us         0.00%     102.753us      12.844us             8            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      99.951us         0.00%      99.951us       9.995us            10            --  
void at::native::elementwise_kernel<512, 1, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      97.776us         0.00%      97.776us       4.074us            24            --  
                                     aten::bitwise_and_         0.00%     138.357us         0.00%     228.242us      11.412us      95.103us         0.00%      95.103us       4.755us            20            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      93.815us         0.00%      93.815us       3.608us            26            --  
void at::native::radixSortKVInPlace<-2, -1, 32, 4, f...         0.00%       0.000us         0.00%       0.000us       0.000us      92.875us         0.00%      92.875us      18.575us             5            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      89.891us         0.00%      89.891us       2.996us            30            --  
void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      88.308us         0.00%      88.308us       7.359us            12            --  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      83.700us         0.00%      83.700us       4.185us            20            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      81.290us         0.00%      81.290us       2.710us            30            --  
                          batched_transpose_16x32_dword         0.00%       0.000us         0.00%       0.000us       0.000us      80.431us         0.00%      80.431us       8.043us            10            --  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      79.980us         0.00%      79.980us       3.999us            20            --  
                                  aten::linalg_lu_solve         0.00%     244.016us         0.00%     694.438us      86.805us      78.736us         0.00%     112.640us      14.080us             8            --  
                          batched_transpose_32x16_dword         0.00%       0.000us         0.00%       0.000us       0.000us      77.311us         0.00%      77.311us       7.731us            10            --  
                                          aten::baddbmm         0.00%     413.671us         0.00%     575.590us      71.949us      76.272us         0.00%      92.824us      11.603us             8       491.520  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      75.749us         0.00%      75.749us       6.312us            12            --  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      74.532us         0.00%      74.532us       2.662us            28            --  
void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us      71.868us         0.00%      71.868us       5.989us            12            --  
void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us      67.868us         0.00%      67.868us       5.656us            12            --  
                          batched_transpose_4x256_dword         0.00%       0.000us         0.00%       0.000us       0.000us      63.750us         0.00%      63.750us       6.375us            10            --  
void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us      60.388us         0.00%      60.388us       5.032us            12            --  
                          batched_transpose_256x4_dword         0.00%       0.000us         0.00%       0.000us       0.000us      60.150us         0.00%      60.150us       6.015us            10            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      58.466us         0.00%      58.466us       4.176us            14            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      55.910us         0.00%      55.910us       5.591us            10            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT256x16x16_...         0.00%       0.000us         0.00%       0.000us       0.000us      55.037us         0.00%      55.037us      18.346us             3            --  
void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us      54.231us         0.00%      54.231us       5.423us            10            --  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      52.030us         0.00%      52.030us       5.203us            10            --  
                              aten::linalg_lu_factor_ex         0.00%     171.102us         0.00%     370.782us      46.348us      51.304us         0.00%      74.536us       9.317us             8            --  
Cijk_Ailk_Bljk_SB_Bias_HAS_SAV_UserArgs_MT256x16x16_...         0.00%       0.000us         0.00%       0.000us       0.000us      50.238us         0.00%      50.238us      16.746us             3            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT16x16x4_MI...         0.00%       0.000us         0.00%       0.000us       0.000us      47.153us         0.00%      47.153us       6.736us             7            --  
                                       aten::bernoulli_         0.00%     130.029us         0.00%     214.694us      21.469us      46.270us         0.00%      46.270us       4.627us            10            --  
void at::cuda::(anonymous namespace)::kernelPointwis...         0.00%       0.000us         0.00%       0.000us       0.000us      46.270us         0.00%      46.270us       4.627us            10            --  
                                         aten::uniform_         0.00%     110.111us         0.00%     203.814us      20.381us      45.790us         0.00%      45.790us       4.579us            10            --  
void at::native::(anonymous namespace)::distribution...         0.00%       0.000us         0.00%       0.000us       0.000us      45.790us         0.00%      45.790us       4.579us            10            --  
void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us      43.518us         0.00%      43.518us      21.759us             2            --  
void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us      43.350us         0.00%      43.350us       4.335us            10            --  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      43.270us         0.00%      43.270us       4.327us            10            --  
void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us      42.390us         0.00%      42.390us       4.239us            10            --  
void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us      41.390us         0.00%      41.390us       4.139us            10            --  
void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us      39.033us         0.00%      39.033us       5.576us             7            --  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      38.953us         0.00%      38.953us       5.565us             7            --  
void at::native::elementwise_kernel<512, 1, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      37.270us         0.00%      37.270us       3.727us            10            --  
void at::native::vectorized_elementwise_kernel<16, a...         0.00%       0.000us         0.00%       0.000us       0.000us      37.227us         0.00%      37.227us       2.659us            14            --  
void rocsolver::v32700::getf2_small_kernel<3, float,...         0.00%       0.000us         0.00%       0.000us       0.000us      35.512us         0.00%      35.512us       4.439us             8            --  
void at::native::tensor_kernel_scan_innermost_dim<fl...         0.00%       0.000us         0.00%       0.000us       0.000us      35.278us         0.00%      35.278us      17.639us             2            --  
void at::native::lpnorm_cleanup<float, (at::native::...         0.00%       0.000us         0.00%       0.000us       0.000us      32.435us         0.00%      32.435us       5.406us             6            --  
void rocsolver::v32700::nonunit_forward_substitution...         0.00%       0.000us         0.00%       0.000us       0.000us      31.752us         0.00%      31.752us       3.969us             8            --  
void at::native::bitonicSortKVInPlace<-2, -1, 16, 16...         0.00%       0.000us         0.00%       0.000us       0.000us      29.915us         0.00%      29.915us       5.983us             5            --  
void rocsolver::v32700::laswp_kernel<float, int, flo...         0.00%       0.000us         0.00%       0.000us       0.000us      25.592us         0.00%      25.592us       3.199us             8            --  
void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us      24.596us         0.00%      24.596us       6.149us             4            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT16x64x32_M...         0.00%       0.000us         0.00%       0.000us       0.000us      22.637us         0.00%      22.637us       7.546us             3            --  
void rocsolver::v32700::unit_backward_substitution_k...         0.00%       0.000us         0.00%       0.000us       0.000us      21.392us         0.00%      21.392us       2.674us             8            --  
void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us      19.996us         0.00%      19.996us       3.999us             5            --  
                                   hipDeviceSynchronize         0.00%      88.536us         0.00%      88.536us      17.707us      17.699us         0.00%      17.699us       3.540us             5            --  
                                      aten::bitwise_not         0.00%      24.197us         0.00%      51.780us      12.945us      17.076us         0.00%      17.076us       4.269us             4            --  
void rocsolver::v32700::reset_info<int, int, int>(in...         0.00%       0.000us         0.00%       0.000us       0.000us      15.792us         0.00%      15.792us       1.974us             8            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      14.678us         0.00%      14.678us       7.339us             2            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT32x32x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us      13.918us         0.00%      13.918us       6.959us             2            --  
Cijk_Ailk_Bjlk_SB_Bias_HAS_SAV_UserArgs_MT64x16x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us      13.838us         0.00%      13.838us       6.919us             2            --  
                               aten::linalg_vector_norm         0.00%      53.050us         0.00%      72.442us      36.221us      13.798us         0.00%      13.798us       6.899us             2            --  
void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      13.798us         0.00%      13.798us       6.899us             2            --  
Cijk_Alik_Bljk_SB_Bias_HAS_SAV_UserArgs_MT16x64x16_M...         0.00%       0.000us         0.00%       0.000us       0.000us      13.718us         0.00%      13.718us       6.859us             2            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      11.199us         0.00%      11.199us       5.600us             2            --  
                                     aten::floor_divide         0.00%      19.519us         0.00%      38.880us      19.440us      11.198us         0.00%      11.198us       5.599us             2            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      11.198us         0.00%      11.198us       5.599us             2            --  
void at::native::vectorized_elementwise_kernel<16, a...         0.00%       0.000us         0.00%       0.000us       0.000us      10.198us         0.00%      10.198us       5.099us             2            --  
                                       aten::reciprocal         0.00%      17.383us         0.00%      29.501us      14.751us       9.718us         0.00%       9.718us       4.859us             2            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       9.718us         0.00%       9.718us       4.859us             2            --  
void at::native::vectorized_elementwise_kernel<16, a...         0.00%       0.000us         0.00%       0.000us       0.000us       9.438us         0.00%       9.438us       4.719us             2            --  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       8.598us         0.00%       8.598us       4.299us             2            --  
void at::native::elementwise_kernel<512, 1, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       7.918us         0.00%       7.918us       3.959us             2            --  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       7.638us         0.00%       7.638us       3.819us             2            --  
void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us       5.959us         0.00%       5.959us       5.959us             1            --  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       5.958us         0.00%       5.958us       2.979us             2            --  
void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us       4.718us         0.00%       4.718us       2.359us             2            --  
void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us       3.959us         0.00%       3.959us       3.959us             1            --  
                                          ProfilerStep*        26.95%        7.679s        80.39%       22.902s       11.451s       0.000us         0.00%       12.071s        6.036s             2            --  
                                            aten::empty         0.31%      87.363ms         0.31%      87.363ms       1.660us       0.000us         0.00%       0.000us       0.000us         52641            --  
                                               aten::to         0.03%       8.226ms        30.94%        8.816s     581.799us       0.000us         0.00%     126.368ms       8.339us         15153            --  
                                         aten::_to_copy         0.05%      14.347ms        30.92%        8.808s       2.127ms       0.000us         0.00%     126.368ms      30.516us          4141            --  
                                    aten::empty_strided         0.09%      26.875ms         0.10%      27.078ms       2.203us       0.000us         0.00%       0.000us       0.000us         12289            --  
                                    hipMemcpyWithStream        56.95%       16.224s        56.95%       16.224s     134.237us       0.000us         0.00%       0.000us       0.000us        120864            --  
                                       aten::lift_fresh         0.02%       4.505ms         0.02%       4.505ms       0.076us       0.000us         0.00%       0.000us       0.000us         59159            --  
                                          aten::detach_         0.01%       3.139ms         0.01%       4.121ms       1.357us       0.000us         0.00%       0.000us       0.000us          3037            --  
                                                detach_         0.00%     981.402us         0.00%     981.402us       0.323us       0.000us         0.00%       0.000us       0.000us          3037            --  
                                             aten::item         0.25%      72.566ms         5.17%        1.472s      22.295us       0.000us         0.00%     298.462ms       4.521us         66011            --  
enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         0.00%     385.044us         0.00%     385.044us     192.522us       0.000us         0.00%       0.000us       0.000us             2            --  
                                         hipMemcpyAsync         0.58%     164.945ms         0.58%     164.945ms      12.262us       0.000us         0.00%       0.000us       0.000us         13452            --  
                                    aten::record_stream         0.00%     101.544us         0.00%     101.544us       0.769us       0.000us         0.00%       0.000us       0.000us           132            --  
                                                Scatter         0.01%       1.737ms         0.02%       6.418ms     200.553us       0.000us         0.00%     710.372us      22.199us            32            --  
                                            aten::chunk         0.01%       1.683ms         0.06%      15.858ms      21.663us       0.000us         0.00%       0.000us       0.000us           732            --  
                                            aten::split         0.02%       5.227ms         0.05%      14.416ms      19.324us       0.000us         0.00%       0.000us       0.000us           746            --  
                                           aten::narrow         0.02%       6.565ms         0.06%      16.633ms       4.196us       0.000us         0.00%       0.000us       0.000us          3964            --  
                                            aten::slice         0.18%      50.311ms         0.21%      60.585ms       2.873us       0.000us         0.00%       0.000us       0.000us         21090            --  
                                       aten::as_strided         0.57%     161.386ms         0.57%     161.386ms       0.578us       0.000us         0.00%       0.000us       0.000us        279392            --  
                                           aten::linear         0.09%      24.557ms         0.82%     234.005ms      58.414us       0.000us         0.00%     954.189ms     238.190us          4006            --  
                                                aten::t         0.09%      25.973ms         0.20%      58.379ms       3.386us       0.000us         0.00%       0.000us       0.000us         17242            --  
                                        aten::transpose         0.10%      27.398ms         0.13%      36.716ms       1.952us       0.000us         0.00%       0.000us       0.000us         18810            --  
                            hipGetDevicePropertiesR0600         0.10%      27.423ms         0.10%      27.423ms       0.437us       0.000us         0.00%       0.000us       0.000us         62780            --  
                               hipExtModuleLaunchKernel         0.37%     105.188ms         0.37%     105.188ms       5.131us       0.000us         0.00%       0.000us       0.000us         20500            --  
                                            aten::zeros         0.05%      13.279ms         0.22%      63.980ms      11.578us       0.000us         0.00%      71.011ms      12.850us          5526            --  
                                            aten::zero_         0.05%      13.863ms         0.26%      73.972ms       7.322us       0.000us         0.00%     130.642ms      12.932us         10102            --  
                                        hipLaunchKernel         2.18%     620.050ms         2.18%     620.050ms       4.703us       0.000us         0.00%       0.000us       0.000us        131850            --  
                                             aten::full         0.00%     339.270us         0.00%       1.077ms      12.822us       0.000us         0.00%     197.197us       2.348us            84            --  
                                             aten::ones         0.01%       1.898ms         0.03%       8.823ms      16.584us       0.000us         0.00%       3.071ms       5.772us           532            --  
                                           aten::unbind         0.01%       2.822ms         0.03%       7.797ms      18.744us       0.000us         0.00%       0.000us       0.000us           416            --  
                                           aten::select         1.60%     455.069ms         1.98%     563.780ms       2.783us       0.000us         0.00%       0.000us       0.000us        202556            --  
                                            aten::stack         0.03%       7.798ms         0.10%      27.757ms      32.887us       0.000us         0.00%      13.136ms      15.564us           844            --  
                                             aten::view         0.21%      59.282ms         0.21%      59.282ms       0.790us       0.000us         0.00%       0.000us       0.000us         75018            --  
                                          aten::reshape         0.10%      27.897ms         0.19%      53.351ms       2.241us       0.000us         0.00%       6.225ms       0.261us         23810            --  
                                           aten::conv2d         0.02%       6.179ms         1.10%     312.759ms     140.882us       0.000us         0.00%        2.947s       1.327ms          2220  64263359692.800  
                                      aten::convolution         0.03%       8.414ms         1.08%     306.580ms     138.099us       0.000us         0.00%        2.947s       1.327ms          2220            --  
                                     aten::_convolution         0.04%      10.378ms         1.05%     298.166ms     134.309us       0.000us         0.00%        2.947s       1.327ms          2220            --  
                                          aten::resize_         0.04%      11.350ms         0.04%      11.350ms       1.009us       0.000us         0.00%       0.000us       0.000us         11244            --  
                                  hipDeviceGetAttribute         0.01%       2.051ms         0.01%       2.051ms       0.440us       0.000us         0.00%       0.000us       0.000us          4660            --  
                                       aten::batch_norm         0.02%       4.721ms         0.29%      82.361ms      39.597us       0.000us         0.00%     441.671ms     212.342us          2080            --  
                           aten::_batch_norm_impl_index         0.03%       9.224ms         0.27%      77.640ms      37.327us       0.000us         0.00%     441.671ms     212.342us          2080            --  
                                            aten::relu_         0.03%       7.528ms         0.09%      26.817ms      10.901us       0.000us         0.00%     690.697ms     280.771us          2460            --  
                                       aten::max_pool2d         0.00%     108.026us         0.00%     543.377us      27.169us       0.000us         0.00%      46.128ms       2.306ms            20            --  
                                        aten::new_empty         0.03%       7.251ms         0.06%      16.915ms       3.458us       0.000us         0.00%       0.000us       0.000us          4892            --  
                                          aten::type_as         0.01%       2.525ms         0.01%       2.969ms       1.427us       0.000us         0.00%       0.000us       0.000us          2080            --  
                                          aten::flatten         0.04%      10.994ms         0.06%      17.807ms       1.719us       0.000us         0.00%       0.000us       0.000us         10362            --  
                                          aten::view_as         0.02%       4.377ms         0.03%       7.841ms       1.568us       0.000us         0.00%       0.000us       0.000us          5000            --  
                                        aten::embedding         0.00%     301.634us         0.01%       1.436ms      22.437us       0.000us         0.00%     363.776us       5.684us            64            --  
                                        aten::unsqueeze         0.06%      17.258ms         0.08%      21.524ms       2.368us       0.000us         0.00%       0.000us       0.000us          9090            --  
                                           aten::repeat         0.01%       2.512ms         0.04%      12.151ms      45.002us       0.000us         0.00%      23.301ms      86.300us           270            --  
                                           aten::expand         0.01%       4.236ms         0.02%       5.426ms       2.746us       0.000us         0.00%       0.000us       0.000us          1976            --  
                                            aten::alias         0.00%     258.803us         0.00%     258.803us       0.959us       0.000us         0.00%       0.000us       0.000us           270            --  
                                           aten::unfold         0.01%       1.809ms         0.01%       2.654ms       2.602us       0.000us         0.00%       0.000us       0.000us          1020            --  
                                        aten::expand_as         0.00%     442.049us         0.00%       1.293ms       4.199us       0.000us         0.00%       0.000us       0.000us           308            --  
                                          aten::permute         0.04%      10.333ms         0.04%      12.466ms       3.595us       0.000us         0.00%       0.000us       0.000us          3468            --  
                                       aten::layer_norm         0.01%       2.905ms         0.11%      30.219ms      28.084us       0.000us         0.00%     138.506ms     128.723us          1076            --  
                                        aten::new_zeros         0.02%       6.304ms         0.11%      32.182ms      13.824us       0.000us         0.00%      25.122ms      10.791us          2328            --  
                                       hipCtxGetCurrent         0.00%       8.070us         0.00%       8.070us       0.237us       0.000us         0.00%       0.000us       0.000us            34            --  
                                  hipModuleLaunchKernel         0.00%       1.090ms         0.00%       1.090ms      32.070us       0.000us         0.00%       0.000us       0.000us            34            --  
                                   aten::_reshape_alias         0.01%       1.704ms         0.01%       1.704ms       1.572us       0.000us         0.00%       0.000us       0.000us          1084            --  
                                         aten::meshgrid         0.00%     257.766us         0.00%     564.518us      16.603us       0.000us         0.00%       0.000us       0.000us            34            --  
                                            aten::clone         0.03%       9.867ms         0.16%      45.091ms      12.766us       0.000us         0.00%      82.489ms      23.355us          3532            --  
                                       aten::empty_like         0.05%      13.375ms         0.11%      31.848ms       3.462us       0.000us         0.00%       0.000us       0.000us          9200            --  
                                     aten::_unsafe_view         0.00%     684.414us         0.00%     684.414us       1.347us       0.000us         0.00%       0.000us       0.000us           508            --  
                                        aten::ones_like         0.00%     625.315us         0.01%       3.599ms      13.530us       0.000us         0.00%     736.656us       2.769us           266            --  
                                           aten::matmul         0.00%       1.291ms         0.04%      12.296ms      72.328us       0.000us         0.00%     816.151ms       4.801ms           170            --  
                                          aten::squeeze         0.02%       6.213ms         0.03%       7.312ms       2.680us       0.000us         0.00%       0.000us       0.000us          2728            --  
                                          aten::__and__         0.00%     342.457us         0.01%       2.837ms      13.015us       0.000us         0.00%       1.628ms       7.468us           218            --  
                                       aten::is_nonzero         0.00%     903.592us         0.27%      77.717ms     154.199us       0.000us         0.00%       7.404ms      14.691us           504            --  
                                          aten::softmax         0.00%       1.087ms         0.03%       9.066ms      15.366us       0.000us         0.00%      32.984ms      55.904us           590            --  
                                       aten::contiguous         0.00%       1.086ms         0.04%      11.823ms      18.302us       0.000us         0.00%      44.595ms      69.033us           646            --  
                                          aten::dropout         0.01%       1.482ms         0.06%      16.556ms      11.742us       0.000us         0.00%      17.408ms      12.346us          1410            --  
                                       aten::zeros_like         0.01%       3.612ms         0.08%      22.375ms      13.208us       0.000us         0.00%      22.202ms      13.106us          1694            --  
                                         hipMemsetAsync         0.17%      47.793ms         0.17%      47.793ms       8.923us       0.000us         0.00%       0.000us       0.000us          5356            --  
                                             aten::set_         0.03%       8.255ms         0.03%       8.255ms       1.937us       0.000us         0.00%       0.000us       0.000us          4262            --  
                                       aten::index_put_         0.02%       4.894ms         0.17%      48.371ms      23.596us       0.000us         0.00%      41.731ms      20.357us          2050            --  
                                             aten::rsub         0.01%       1.726ms         0.05%      13.343ms      31.322us       0.000us         0.00%       2.049ms       4.809us           426            --  
                                       aten::unsqueeze_         0.00%     110.697us         0.00%     183.611us       8.346us       0.000us         0.00%       0.000us       0.000us            22            --  
                                      aten::as_strided_         0.00%     148.404us         0.00%     148.404us       2.559us       0.000us         0.00%       0.000us       0.000us            58            --  
                                     aten::grid_sampler         0.00%      85.114us         0.00%     514.677us      23.394us       0.000us         0.00%      11.062ms     502.824us            22            --  
                                   hipStreamIsCapturing         0.00%     577.082us         0.00%     577.082us       0.327us       0.000us         0.00%       0.000us       0.000us          1763            --  
                                             aten::relu         0.01%       1.668ms         0.02%       5.939ms      11.644us       0.000us         0.00%       2.409ms       4.724us           510            --  
                                           aten::detach         0.01%       2.411ms         0.02%       5.388ms       2.167us       0.000us         0.00%       0.000us       0.000us          2486            --  
                                                 detach         0.01%       2.978ms         0.01%       2.978ms       1.198us       0.000us         0.00%       0.000us       0.000us          2486            --  
                                       aten::linalg_inv         0.00%      63.425us         0.01%       2.412ms     301.545us       0.000us         0.00%     421.388us      52.674us             8            --  
                                    aten::linalg_inv_ex         0.00%     131.262us         0.01%       1.681ms     210.071us       0.000us         0.00%     219.201us      27.400us             8            --  
                                         aten::diagonal         0.00%      21.919us         0.00%      27.144us       3.393us       0.000us         0.00%       0.000us       0.000us             8            --  
                                  aten::linalg_solve_ex         0.00%      55.827us         0.00%       1.397ms     174.630us       0.000us         0.00%     187.176us      23.397us             8            --  
                                 aten::_linalg_solve_ex         0.00%     149.580us         0.00%       1.308ms     163.511us       0.000us         0.00%     187.176us      23.397us             8            --  
                                               aten::mT         0.00%      20.528us         0.00%      55.017us       3.439us       0.000us         0.00%       0.000us       0.000us            16            --  
                             aten::_linalg_check_errors         0.00%      45.904us         0.00%     668.368us      83.546us       0.000us         0.00%     202.187us      25.273us             8            --  
                                     aten::resolve_conj         0.00%      40.391us         0.00%      40.391us       0.301us       0.000us         0.00%       0.000us       0.000us           134            --  
                                      aten::resolve_neg         0.00%      25.999us         0.00%      25.999us       0.194us       0.000us         0.00%       0.000us       0.000us           134            --  
                                         aten::new_full         0.00%     496.438us         0.01%       2.345ms      14.473us       0.000us         0.00%     404.763us       2.499us           162            --  
                                      aten::result_type         0.00%       1.275ms         0.00%       1.275ms       0.099us       0.000us         0.00%       0.000us       0.000us         12906            --  
                                            aten::cdist         0.00%     231.049us         0.02%       4.736ms      64.006us       0.000us         0.00%       6.545ms      88.448us            74            --  
                                              aten::min         0.00%     225.408us         0.01%       1.690ms      13.202us       0.000us         0.00%     596.281us       4.658us           128            --  
                                        aten::full_like         0.00%     513.108us         0.01%       2.632ms      14.620us       0.000us         0.00%     369.061us       2.050us           180            --  
                                       c10d::allreduce_         0.02%       5.758ms         0.09%      24.313ms      55.006us       0.000us         0.00%       0.000us       0.000us           442            --  
                                     record_param_comms         0.05%      15.075ms         0.07%      19.331ms      22.220us       0.000us         0.00%       0.000us       0.000us           870            --  
                                        nccl:all_reduce         0.00%       0.000us             0       9.530ms      21.560us       0.000us         0.00%       0.000us       0.000us           442            --  
                      hipOccupancyMaxPotentialBlockSize         0.00%      11.430us         0.00%      11.430us       2.286us       0.000us         0.00%       0.000us       0.000us             5            --  
                                         aten::__iand__         0.00%      35.820us         0.00%     264.062us      13.203us       0.000us         0.00%      95.103us       4.755us            20            --  
                                        aten::rand_like         0.00%      40.173us         0.00%     302.615us      30.261us       0.000us         0.00%      45.790us       4.579us            10            --  
                                        aten::bernoulli         0.00%      54.483us         0.00%     303.944us      30.394us       0.000us         0.00%      46.270us       4.627us            10            --  
                                          aten::argsort         0.00%      28.941us         0.00%     703.376us      70.338us       0.000us         0.00%     677.194us      67.719us            10            --  
                                    aten::scalar_tensor         0.00%     270.645us         0.00%       1.248ms       9.905us       0.000us         0.00%     385.800us       3.062us           126            --  
                                      aten::masked_fill         0.00%     376.367us         0.01%       1.976ms      41.160us       0.000us         0.00%       4.714ms      98.211us            48            --  
                                 aten::split_with_sizes         0.00%     673.306us         0.00%     799.669us      10.522us       0.000us         0.00%       0.000us       0.000us            76            --  
                                         aten::new_ones         0.00%      44.909us         0.00%     160.107us      11.436us       0.000us         0.00%      29.746us       2.125us            14            --  
torch.distributed.ddp.reducer::search_unused_paramet...         0.03%       8.128ms         0.03%       8.128ms       4.064ms       0.000us         0.00%       0.000us       0.000us             2            --  
                    Optimizer.zero_grad#AdamW.zero_grad         0.02%       5.532ms         0.02%       5.532ms       2.766ms       0.000us         0.00%       0.000us       0.000us             2            --  
      autograd::engine::evaluate_function: AddBackward0         0.03%       9.562ms         0.06%      17.225ms       7.989us       0.000us         0.00%      23.178ms      10.751us          2156            --  
                                           AddBackward0         0.00%       1.026ms         0.00%       1.026ms       0.447us       0.000us         0.00%       0.000us       0.000us          2296            --  
     autograd::engine::evaluate_function: MeanBackward0         0.00%     689.837us         0.02%       4.452ms      16.132us       0.000us         0.00%       1.015ms       3.676us           276            --  
                                          MeanBackward0         0.00%     566.380us         0.01%       3.763ms      13.632us       0.000us         0.00%       1.015ms       3.676us           276            --  
autograd::engine::evaluate_function: NanToNumBackwar...         0.00%       1.297ms         0.05%      14.192ms      51.421us       0.000us         0.00%       4.611ms      16.706us           276            --  
                                      NanToNumBackward0         0.00%     739.270us         0.05%      12.896ms      46.724us       0.000us         0.00%       4.611ms      16.706us           276            --  
                                         aten::isfinite         0.01%       1.536ms         0.04%      10.324ms      37.406us       0.000us         0.00%       3.947ms      14.301us           276            --  
      autograd::engine::evaluate_function: MulBackward0         0.02%       6.667ms         0.08%      23.937ms      15.404us       0.000us         0.00%      10.086ms       6.491us          1554            --  
                                           MulBackward0         0.01%       3.461ms         0.06%      16.767ms      10.790us       0.000us         0.00%       9.091ms       5.850us          1554            --  
      autograd::engine::evaluate_function: DivBackward0         0.01%       3.861ms         0.06%      16.438ms      25.057us       0.000us         0.00%      39.755ms      60.603us           656            --  
                                           DivBackward0         0.01%       1.995ms         0.04%      11.274ms      17.186us       0.000us         0.00%      39.296ms      59.902us           656            --  
      autograd::engine::evaluate_function: SumBackward0         0.00%     830.417us         0.01%       2.026ms       7.340us       0.000us         0.00%       0.000us       0.000us           276            --  
                                           SumBackward0         0.00%     387.422us         0.00%       1.195ms       4.331us       0.000us         0.00%       0.000us       0.000us           276            --  
autograd::engine::evaluate_function: SigmoidFocalLos...         0.00%     888.964us         0.03%       7.736ms      84.086us       0.000us         0.00%       1.160ms      12.611us            92            --  
     autograd::engine::evaluate_function: RsubBackward1         0.00%     211.627us         0.00%     802.627us      11.148us       0.000us         0.00%     356.449us       4.951us            72            --  
                                          RsubBackward1         0.00%      86.593us         0.00%     591.000us       8.208us       0.000us         0.00%     356.449us       4.951us            72            --  
      autograd::engine::evaluate_function: SumBackward1         0.00%     130.726us         0.00%     458.591us       9.554us       0.000us         0.00%       0.000us       0.000us            48            --  
                                           SumBackward1         0.00%     106.765us         0.00%     327.865us       6.831us       0.000us         0.00%       0.000us       0.000us            48            --  
     autograd::engine::evaluate_function: ViewBackward0         0.07%      19.276ms         0.17%      47.888ms       7.731us       0.000us         0.00%      32.616ms       5.266us          6194            --  
                                          ViewBackward0         0.03%       7.360ms         0.09%      24.549ms       3.963us       0.000us         0.00%       5.876ms       0.949us          6194            --  
autograd::engine::evaluate_function: SqueezeBackward...         0.00%      93.044us         0.00%     224.262us       7.008us       0.000us         0.00%       0.000us       0.000us            32            --  
                                       SqueezeBackward1         0.00%      36.929us         0.00%     131.218us       4.101us       0.000us         0.00%       0.000us       0.000us            32            --  
autograd::engine::evaluate_function: UpsampleBilinea...         0.00%      94.749us         0.00%     554.371us      23.099us       0.000us         0.00%       4.847ms     201.976us            24            --  
                            UpsampleBilinear2DBackward0         0.00%      43.662us         0.00%     459.622us      19.151us       0.000us         0.00%       4.847ms     201.976us            24            --  
autograd::engine::evaluate_function: UnsqueezeBackwa...         0.01%       2.082ms         0.02%       5.084ms       7.894us       0.000us         0.00%     828.942us       1.287us           644            --  
                                     UnsqueezeBackward0         0.00%     793.813us         0.01%       2.624ms       4.074us       0.000us         0.00%       0.000us       0.000us           644            --  
      autograd::engine::evaluate_function: AbsBackward0         0.00%     823.629us         0.01%       3.806ms      27.186us       0.000us         0.00%       1.313ms       9.381us           140            --  
                                           AbsBackward0         0.00%     617.203us         0.01%       2.982ms      21.303us       0.000us         0.00%       1.313ms       9.381us           140            --  
      autograd::engine::evaluate_function: SubBackward0         0.00%       1.307ms         0.01%       3.367ms       9.565us       0.000us         0.00%       1.331ms       3.780us           352            --  
                                           SubBackward0         0.00%     308.129us         0.01%       1.535ms       4.361us       0.000us         0.00%     926.185us       2.631us           352            --  
autograd::engine::evaluate_function: MaximumBackward...         0.00%     420.684us         0.02%       4.280ms      53.496us       0.000us         0.00%       2.260ms      28.244us            80            --  
                                       MaximumBackward0         0.00%     601.587us         0.01%       3.859ms      48.237us       0.000us         0.00%       2.260ms      28.244us            80            --  
autograd::engine::evaluate_function: SelectBackward0...         0.04%       9.987ms         0.26%      74.535ms      32.294us       0.000us         0.00%     170.607ms      73.920us          2308            --  
                                        SelectBackward0         0.01%       3.649ms         0.20%      55.603ms      24.091us       0.000us         0.00%      77.417ms      33.543us          2308            --  
                                  aten::select_backward         0.03%       7.415ms         0.18%      51.954ms      22.510us       0.000us         0.00%      77.417ms      33.543us          2308            --  
    autograd::engine::evaluate_function: ClampBackward1         0.00%     669.765us         0.02%       6.077ms      49.004us       0.000us         0.00%       2.909ms      23.460us           124            --  
                                         ClampBackward1         0.00%     776.128us         0.02%       5.240ms      42.261us       0.000us         0.00%       2.772ms      22.358us           124            --  
    autograd::engine::evaluate_function: SliceBackward0         0.02%       5.159ms         0.15%      41.748ms      30.607us       0.000us         0.00%      30.692ms      22.502us          1364            --  
                                         SliceBackward0         0.01%       2.398ms         0.12%      33.897ms      24.851us       0.000us         0.00%      19.800ms      14.516us          1364            --  
                                   aten::slice_backward         0.02%       5.380ms         0.11%      31.499ms      23.093us       0.000us         0.00%      19.800ms      14.516us          1364            --  
autograd::engine::evaluate_function: MinimumBackward...         0.00%     157.045us         0.01%       2.071ms      51.766us       0.000us         0.00%       1.121ms      28.015us            40            --  
                                       MinimumBackward0         0.00%     357.069us         0.01%       1.914ms      47.840us       0.000us         0.00%       1.121ms      28.015us            40            --  
      autograd::engine::evaluate_function: CatBackward0         0.01%       1.608ms         0.02%       6.066ms      17.736us       0.000us         0.00%      46.314us       0.135us           342            --  
                                           CatBackward0         0.00%       1.023ms         0.02%       4.415ms      12.910us       0.000us         0.00%       0.000us       0.000us           342            --  
autograd::engine::evaluate_function: SplitWithSizesB...         0.00%     117.260us         0.00%     590.639us      29.532us       0.000us         0.00%     204.363us      10.218us            20            --  
                                SplitWithSizesBackward0         0.00%      49.166us         0.00%     357.250us      17.862us       0.000us         0.00%     101.583us       5.079us            20            --  
    autograd::engine::evaluate_function: AddmmBackward0         0.09%      26.876ms         1.01%     287.593ms     123.114us       0.000us         0.00%     818.435ms     350.357us          2336            --  
                                         AddmmBackward0         0.07%      20.371ms         0.75%     212.585ms      91.004us       0.000us         0.00%     718.072ms     307.394us          2336            --  
autograd::engine::evaluate_function: torch::autograd...         0.06%      15.784ms         0.17%      48.356ms      22.745us       0.000us         0.00%      12.310ms       5.790us          2126            --  
                        torch::autograd::AccumulateGrad         0.01%       2.693ms         0.02%       6.572ms       3.091us       0.000us         0.00%       0.000us       0.000us          2126            --  
                   torch::distributed::reducer::mul_out         0.01%       3.438ms         0.07%      19.058ms       8.964us       0.000us         0.00%      12.253ms       5.763us          2126            --  
        autograd::engine::evaluate_function: TBackward0         0.03%       9.900ms         0.10%      27.348ms      11.462us       0.000us         0.00%       6.255ms       2.621us          2386            --  
                                             TBackward0         0.01%       2.464ms         0.03%       9.196ms       3.854us       0.000us         0.00%       0.000us       0.000us          2386            --  
autograd::engine::evaluate_function: torch::autograd...         0.03%       9.934ms         0.34%      95.900ms      63.594us       0.000us         0.00%     110.759ms      73.448us          1508            --  
                            torch::autograd::CopySlices         0.04%      12.542ms         0.30%      85.745ms      56.860us       0.000us         0.00%     110.638ms      73.367us          1508            --  
                                aten::new_empty_strided         0.01%       2.378ms         0.02%       5.205ms       3.452us       0.000us         0.00%       0.000us       0.000us          1508            --  
                         torch::autograd::CopyBackwards         0.01%       2.060ms         0.04%      11.248ms      13.018us       0.000us         0.00%       3.520ms       4.074us           864            --  
autograd::engine::evaluate_function: SigmoidBackward...         0.00%     832.106us         0.01%       2.683ms      15.784us       0.000us         0.00%       1.041ms       6.124us           170            --  
                                       SigmoidBackward0         0.00%     425.094us         0.01%       1.851ms      10.890us       0.000us         0.00%       1.041ms       6.124us           170            --  
autograd::engine::evaluate_function: AsStridedBackwa...         0.01%       2.951ms         0.09%      25.930ms      39.648us       0.000us         0.00%      13.130ms      20.077us           654            --  
                                     AsStridedBackward0         0.02%       5.262ms         0.07%      20.610ms      31.513us       0.000us         0.00%      10.931ms      16.713us           654            --  
     autograd::engine::evaluate_function: ReluBackward0         0.01%       2.407ms         0.03%       7.501ms      15.063us       0.000us         0.00%       2.974ms       5.971us           498            --  
                                          ReluBackward0         0.01%       1.526ms         0.02%       7.089ms      11.042us       0.000us         0.00%       8.786ms      13.685us           642            --  
    autograd::engine::evaluate_function: StackBackward0         0.00%     518.468us         0.01%       1.539ms      25.646us       0.000us         0.00%     799.554us      13.326us            60            --  
                                         StackBackward0         0.00%     251.010us         0.00%     962.757us      16.046us       0.000us         0.00%       0.000us       0.000us            60            --  
autograd::engine::evaluate_function: UnsafeViewBackw...         0.00%     408.194us         0.00%       1.072ms       8.246us       0.000us         0.00%      22.874us       0.176us           130            --  
                                    UnsafeViewBackward0         0.00%     207.504us         0.00%     663.742us       5.106us       0.000us         0.00%      22.874us       0.176us           130            --  
       autograd::engine::evaluate_function: MmBackward0         0.00%     545.590us         0.02%       6.284ms      95.208us       0.000us         0.00%     452.364ms       6.854ms            66            --  
                                            MmBackward0         0.00%     499.169us         0.02%       5.738ms      86.941us       0.000us         0.00%     452.364ms       6.854ms            66            --  
autograd::engine::evaluate_function: ReshapeAliasBac...         0.00%     660.342us         0.01%       1.704ms      10.651us       0.000us         0.00%     433.093us       2.707us           160            --  
                                  ReshapeAliasBackward0         0.00%     257.665us         0.00%     717.126us       4.482us       0.000us         0.00%       0.000us       0.000us           160            --  
autograd::engine::evaluate_function: PermuteBackward...         0.01%       3.269ms         0.03%       8.661ms       8.929us       0.000us         0.00%      20.354ms      20.984us           970            --  
                                       PermuteBackward0         0.01%       1.514ms         0.02%       4.561ms       4.702us       0.000us         0.00%       0.000us       0.000us           970            --  
      autograd::engine::evaluate_function: BmmBackward0         0.01%       1.886ms         0.07%      20.820ms      88.972us       0.000us         0.00%      22.485ms      96.091us           234            --  
                                           BmmBackward0         0.01%       1.690ms         0.07%      18.933ms      80.911us       0.000us         0.00%      22.485ms      96.091us           234            --  
autograd::engine::evaluate_function: ExpandBackward0...         0.00%     462.705us         0.00%     542.757us       3.119us       0.000us         0.00%       0.000us       0.000us           174            --  
                                        ExpandBackward0         0.00%      80.052us         0.00%      80.052us       0.460us       0.000us         0.00%       0.000us       0.000us           174            --  
    autograd::engine::evaluate_function: CloneBackward0         0.00%     707.621us         0.00%     798.454us       3.119us       0.000us         0.00%       0.000us       0.000us           256            --  
                                         CloneBackward0         0.00%      90.833us         0.00%      90.833us       0.355us       0.000us         0.00%       0.000us       0.000us           256            --  
autograd::engine::evaluate_function: TransposeBackwa...         0.01%       1.564ms         0.01%       3.425ms       6.689us       0.000us         0.00%      17.354us       0.034us           512            --  
                                     TransposeBackward0         0.00%     545.985us         0.01%       1.798ms       3.513us       0.000us         0.00%       0.000us       0.000us           512            --  
autograd::engine::evaluate_function: NativeLayerNorm...         0.03%       8.743ms         0.14%      39.653ms      61.383us       0.000us         0.00%      69.566ms     107.688us           646            --  
                               NativeLayerNormBackward0         0.01%       3.072ms         0.09%      26.096ms      40.396us       0.000us         0.00%      65.612ms     101.566us           646            --  
     autograd::engine::evaluate_function: GeluBackward0         0.00%     109.923us         0.00%     376.113us      18.806us       0.000us         0.00%     119.700us       5.985us            20            --  
                                          GeluBackward0         0.00%      50.719us         0.00%     266.190us      13.310us       0.000us         0.00%     119.700us       5.985us            20            --  
autograd::engine::evaluate_function: SoftmaxBackward...         0.01%       1.828ms         0.04%      12.095ms      37.561us       0.000us         0.00%      18.057ms      56.078us           322            --  
                                       SoftmaxBackward0         0.00%       1.187ms         0.04%      10.267ms      31.884us       0.000us         0.00%      18.057ms      56.078us           322            --  
    autograd::engine::evaluate_function: IndexBackward0         0.02%       6.185ms        13.43%        3.826s       3.665ms       0.000us         0.00%     104.593ms     100.185us          1044            --  
                                         IndexBackward0         0.01%       4.118ms        13.41%        3.820s       3.659ms       0.000us         0.00%     104.267ms      99.872us          1044            --  
                                          aten::divide_         0.00%       1.087ms         0.04%      10.019ms       9.597us       0.000us         0.00%       5.786ms       5.542us          1044            --  
    autograd::engine::evaluate_function: SplitBackward0         0.00%       1.193ms         0.02%       5.128ms      27.571us       0.000us         0.00%       1.628ms       8.753us           186            --  
                                         SplitBackward0         0.00%     508.790us         0.01%       3.158ms      16.977us       0.000us         0.00%     986.425us       5.303us           186            --  
autograd::engine::evaluate_function: UnbindBackward0...         0.00%      31.559us         0.00%     112.631us      28.158us       0.000us         0.00%      27.276us       6.819us             4            --  
                                        UnbindBackward0         0.00%       9.749us         0.00%      81.072us      20.268us       0.000us         0.00%      27.276us       6.819us             4            --  
      autograd::engine::evaluate_function: LogBackward0         0.00%     171.619us         0.00%     520.246us      18.580us       0.000us         0.00%     160.052us       5.716us            28            --  
                                           LogBackward0         0.00%      74.342us         0.00%     348.627us      12.451us       0.000us         0.00%     160.052us       5.716us            28            --  
                                     aten::logical_and_         0.00%      67.968us         0.00%     311.662us      11.131us       0.000us         0.00%     301.532us      10.769us            28            --  
autograd::engine::evaluate_function: NativeDropoutBa...         0.01%       3.124ms         0.04%      11.650ms      18.317us       0.000us         0.00%      15.533ms      24.422us           636            --  
                                 NativeDropoutBackward0         0.00%       1.298ms         0.03%       8.525ms      13.405us       0.000us         0.00%      15.533ms      24.422us           636            --  
autograd::engine::evaluate_function: MultiScaleDefor...         0.00%     289.786us         0.01%       2.982ms     124.266us       0.000us         0.00%      34.716ms       1.447ms            24            --  
autograd::engine::evaluate_function: MaskedFillBackw...         0.00%     121.813us         0.00%       1.098ms      45.769us       0.000us         0.00%       2.425ms     101.039us            24            --  
                                    MaskedFillBackward0         0.00%      50.207us         0.00%     976.632us      40.693us       0.000us         0.00%       2.425ms     101.039us            24            --  
autograd::engine::evaluate_function: MultiScaleDefor...         0.01%       3.127ms         0.11%      30.910ms     171.723us       0.000us         0.00%        2.533s      14.071ms           180            --  
                                      IndexPutBackward0         0.01%       2.085ms         0.08%      21.786ms      58.564us       0.000us         0.00%      28.210ms      75.834us           372            --  
                                        aten::index_put         0.00%     975.610us         0.03%       9.780ms      31.548us       0.000us         0.00%      15.906ms      51.310us           310            --  
     autograd::engine::evaluate_function: MeanBackward1         0.00%     275.962us         0.01%       2.149ms      35.823us       0.000us         0.00%       8.821ms     147.021us            60            --  
                                          MeanBackward1         0.00%     345.784us         0.01%       1.873ms      31.224us       0.000us         0.00%       8.821ms     147.021us            60            --  
autograd::engine::evaluate_function: RepeatBackward0...         0.00%     132.955us         0.00%     510.307us      12.758us       0.000us         0.00%     471.861us      11.797us            40            --  
                                        RepeatBackward0         0.00%      67.252us         0.00%     377.352us       9.434us       0.000us         0.00%     471.861us      11.797us            40            --  
autograd::engine::evaluate_function: EmbeddingBackwa...         0.00%     148.085us         0.00%     823.779us      41.189us       0.000us         0.00%     590.388us      29.519us            20            --  
                                     EmbeddingBackward0         0.00%      44.635us         0.00%     571.442us      28.572us       0.000us         0.00%     493.243us      24.662us            20            --  
                               aten::embedding_backward         0.00%      37.981us         0.00%     526.807us      26.340us       0.000us         0.00%     493.243us      24.662us            20            --  
autograd::engine::evaluate_function: ConvolutionBack...         0.00%     996.013us         0.09%      25.946ms     370.662us       0.000us         0.00%     774.455ms      11.064ms            70            --  
                                   ConvolutionBackward0         0.00%     364.747us         0.08%      24.084ms     344.052us       0.000us         0.00%     773.213ms      11.046ms            70            --  
autograd::engine::evaluate_function: UpsampleNearest...         0.00%     125.460us         0.00%     548.933us      27.447us       0.000us         0.00%       2.937ms     146.829us            20            --  
                             UpsampleNearest2DBackward0         0.00%      44.861us         0.00%     288.232us      14.412us       0.000us         0.00%       2.016ms     100.798us            20            --  
autograd::engine::evaluate_function: IndexPutBackwar...         0.00%      90.160us         0.01%       3.186ms     265.464us       0.000us         0.00%       1.087ms      90.563us            12            --  
autograd::engine::evaluate_function: BaddbmmBackward...         0.00%      75.500us         0.00%     721.978us     120.330us       0.000us         0.00%     113.189us      18.865us             6            --  
                                       BaddbmmBackward0         0.00%      54.233us         0.00%     646.478us     107.746us       0.000us         0.00%     113.189us      18.865us             6            --  
                                        aten::is_pinned         0.00%      11.864us         0.00%      15.674us       7.837us       0.000us         0.00%       0.000us       0.000us             2            --  
                                hipPointerGetAttributes         0.00%       3.810us         0.00%       3.810us       1.905us       0.000us         0.00%       0.000us       0.000us             2            --  
     torch.distributed.ddp.reducer::copy_bucket_to_grad         0.01%       3.249ms         0.06%      18.097ms       8.504us       0.000us         0.00%       8.952ms       4.207us          2128            --  
                              Optimizer.step#AdamW.step         0.61%     173.772ms         1.19%     339.161ms     169.581ms       0.000us         0.00%     136.251ms      68.126ms             2            --  
                                              hipMalloc         0.00%     974.358us         0.00%     974.358us     139.194us       0.000us         0.00%       0.000us       0.000us             7            --  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
Self CPU time total: 28.490s
Self CUDA time total: 17.434s

2025-05-12 07:56:53,632 - mmdet - INFO - [MyProfilerHook] runner.iter=22, end profiling
2025-05-12 07:56:53,632 - mmdet - INFO - [MyProfilerHook] runner.iter=22, end profiling
[rank0]:[W512 07:57:27.793762306 ProcessGroupNCCL.cpp:1487] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
